{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Flair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsigit/oss-saki-ss19-exercises/blob/master/NER_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i2ZcgcwiptR",
        "colab_type": "code",
        "outputId": "a0ecc37f-1faa-4fb2-be06-624c69a02492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB19k89PDfEz",
        "colab_type": "code",
        "outputId": "3cef96e3-d2e5-41d3-b7f9-62f693cbe84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        }
      },
      "source": [
        "! pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.6MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
            "Collecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 45.7MB/s \n",
            "\u001b[?25hCollecting regex (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (1.16.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.165)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.165 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.165)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "Building wheels for collected packages: sqlitedict, mpld3, regex, segtok\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "Successfully built sqlitedict mpld3 regex segtok\n",
            "Installing collected packages: deprecated, sentencepiece, bpemb, sqlitedict, mpld3, regex, segtok, pytorch-pretrained-bert, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI53Gmli268N",
        "colab_type": "code",
        "outputId": "7d41d263-5b8e-43b5-8360-c33d9e966095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# imports \n",
        "from flair.datasets import Corpus\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "\n",
        "# file structure\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# folder where training and test data are stored\n",
        "data_folder = '/content/gdrive/My Drive'\n",
        "\n",
        "# 1.0 is full data\n",
        "downsample = 1.0\n",
        "\n",
        "# train file name\n",
        "train_file = 'train_res_bilou_sentences.txt'\n",
        "\n",
        "# test file name\n",
        "test_file = 'test_res_bilou_sentences.txt'\n",
        "\n",
        "# get the corpus\n",
        "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
        "                                                             train_file=train_file,\n",
        "                                                             test_file=test_file,\n",
        "                                                             dev_file=None).downsample(downsample)\n",
        "print(corpus)\n",
        "\n",
        "# make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:21:26,552 Reading data from /content/gdrive/My Drive\n",
            "2019-06-17 06:21:26,558 Train: /content/gdrive/My Drive/train_res_bilou_sentences.txt\n",
            "2019-06-17 06:21:26,560 Dev: None\n",
            "2019-06-17 06:21:26,564 Test: /content/gdrive/My Drive/test_res_bilou_sentences.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated function (or staticmethod) load_column_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:312: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  train_file, column_format\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:318: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  test_file, column_format\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Corpus: 10713 train + 1190 dev + 4399 test sentences\n",
            "[b'<unk>', b'O', b'\"B-Companies', b'\"L-Companies', b'B-Designation', b'I-Designation', b'L-Designation', b'\"I-Companies', b'B-Degree', b'I-Degree', b'L-Degree', b'U-Designation', b'U-Degree', b'-', b'\"U-Companies', b'ner', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6twFKXGFzb9",
        "colab_type": "code",
        "outputId": "e6677e53-7fd0-4db2-815d-ad04a7ba0ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings,FlairEmbeddings\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "# used embeddings\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type='ner',\n",
        "                                        use_crf=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:22:08,987 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmp2yqa5j1k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:10<00:00, 6954937.66B/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:22:20,012 copying /tmp/tmp2yqa5j1k to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:22:20,096 removing temp file /tmp/tmp2yqa5j1k\n",
            "2019-06-17 06:22:27,634 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmp9lzi_ks8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:04<00:00, 17056648.90B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:22:32,472 copying /tmp/tmp9lzi_ks8 to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:22:32,552 removing temp file /tmp/tmp9lzi_ks8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEgX66HhGE1d",
        "colab_type": "code",
        "outputId": "7b2445ba-3b55-4572-8ce1-60ed0d1a10c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 21661
        }
      },
      "source": [
        "# initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "model_name = 'resources/taggers/resume-ner-2f_100_ts'\n",
        "\n",
        "# actual training of the model\n",
        "trainer.train(model_name,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              #anneal_with_restarts=True,\n",
        "              max_epochs=150)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 06:23:14,017 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:23:14,020 Evaluation method: MICRO_F1_SCORE\n",
            "2019-06-17 06:23:14,321 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:23:15,209 epoch 1 - iter 0/335 - loss 45.43640137\n",
            "2019-06-17 06:23:35,661 epoch 1 - iter 33/335 - loss 7.17236656\n",
            "2019-06-17 06:23:56,687 epoch 1 - iter 66/335 - loss 5.69326781\n",
            "2019-06-17 06:24:20,536 epoch 1 - iter 99/335 - loss 4.98563991\n",
            "2019-06-17 06:24:41,198 epoch 1 - iter 132/335 - loss 4.50315747\n",
            "2019-06-17 06:25:07,118 epoch 1 - iter 165/335 - loss 4.21615085\n",
            "2019-06-17 06:25:25,762 epoch 1 - iter 198/335 - loss 3.91208668\n",
            "2019-06-17 06:25:49,072 epoch 1 - iter 231/335 - loss 3.71061208\n",
            "2019-06-17 06:26:12,382 epoch 1 - iter 264/335 - loss 3.54476160\n",
            "2019-06-17 06:26:35,961 epoch 1 - iter 297/335 - loss 3.37963618\n",
            "2019-06-17 06:26:57,396 epoch 1 - iter 330/335 - loss 3.23544791\n",
            "2019-06-17 06:26:59,723 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:26:59,726 EPOCH 1 done: loss 3.2151 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:27:28,213 DEV : loss 1.9915589094161987 - score 0.2995\n",
            "2019-06-17 06:29:04,909 TEST : loss 1.9045976400375366 - score 0.2587\n",
            "2019-06-17 06:29:05,375 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:29:06,573 epoch 2 - iter 0/335 - loss 2.09354687\n",
            "2019-06-17 06:29:28,427 epoch 2 - iter 33/335 - loss 1.84148741\n",
            "2019-06-17 06:29:50,490 epoch 2 - iter 66/335 - loss 1.81415726\n",
            "2019-06-17 06:30:14,304 epoch 2 - iter 99/335 - loss 1.73746009\n",
            "2019-06-17 06:30:39,150 epoch 2 - iter 132/335 - loss 1.74091388\n",
            "2019-06-17 06:31:00,326 epoch 2 - iter 165/335 - loss 1.70119050\n",
            "2019-06-17 06:31:23,534 epoch 2 - iter 198/335 - loss 1.68505544\n",
            "2019-06-17 06:31:45,350 epoch 2 - iter 231/335 - loss 1.65613615\n",
            "2019-06-17 06:32:04,605 epoch 2 - iter 264/335 - loss 1.63149250\n",
            "2019-06-17 06:32:22,396 epoch 2 - iter 297/335 - loss 1.59796998\n",
            "2019-06-17 06:32:47,845 epoch 2 - iter 330/335 - loss 1.56913828\n",
            "2019-06-17 06:32:50,547 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:32:50,549 EPOCH 2 done: loss 1.5648 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:33:17,490 DEV : loss 1.2112665176391602 - score 0.5468\n",
            "2019-06-17 06:34:54,652 TEST : loss 1.2434762716293335 - score 0.5409\n",
            "2019-06-17 06:34:55,178 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:34:56,515 epoch 3 - iter 0/335 - loss 1.54229414\n",
            "2019-06-17 06:35:17,558 epoch 3 - iter 33/335 - loss 1.37069097\n",
            "2019-06-17 06:35:39,137 epoch 3 - iter 66/335 - loss 1.35960041\n",
            "2019-06-17 06:36:01,959 epoch 3 - iter 99/335 - loss 1.24834384\n",
            "2019-06-17 06:36:26,153 epoch 3 - iter 132/335 - loss 1.25229386\n",
            "2019-06-17 06:36:45,912 epoch 3 - iter 165/335 - loss 1.24813557\n",
            "2019-06-17 06:37:09,390 epoch 3 - iter 198/335 - loss 1.23822225\n",
            "2019-06-17 06:37:31,558 epoch 3 - iter 231/335 - loss 1.23298821\n",
            "2019-06-17 06:37:51,403 epoch 3 - iter 264/335 - loss 1.23739602\n",
            "2019-06-17 06:38:13,711 epoch 3 - iter 297/335 - loss 1.21004550\n",
            "2019-06-17 06:38:37,355 epoch 3 - iter 330/335 - loss 1.21775610\n",
            "2019-06-17 06:38:40,630 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:38:40,632 EPOCH 3 done: loss 1.2200 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:39:07,493 DEV : loss 0.9336798787117004 - score 0.6423\n",
            "2019-06-17 06:40:44,636 TEST : loss 0.9871547818183899 - score 0.6049\n",
            "2019-06-17 06:40:45,107 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:40:46,472 epoch 4 - iter 0/335 - loss 1.19514704\n",
            "2019-06-17 06:41:11,673 epoch 4 - iter 33/335 - loss 1.02244371\n",
            "2019-06-17 06:41:35,465 epoch 4 - iter 66/335 - loss 1.03421179\n",
            "2019-06-17 06:41:57,374 epoch 4 - iter 99/335 - loss 1.05132774\n",
            "2019-06-17 06:42:22,620 epoch 4 - iter 132/335 - loss 1.09628963\n",
            "2019-06-17 06:42:44,434 epoch 4 - iter 165/335 - loss 1.11067275\n",
            "2019-06-17 06:43:02,109 epoch 4 - iter 198/335 - loss 1.07610268\n",
            "2019-06-17 06:43:23,059 epoch 4 - iter 231/335 - loss 1.08314351\n",
            "2019-06-17 06:43:44,790 epoch 4 - iter 264/335 - loss 1.09080479\n",
            "2019-06-17 06:44:06,367 epoch 4 - iter 297/335 - loss 1.06406692\n",
            "2019-06-17 06:44:27,230 epoch 4 - iter 330/335 - loss 1.05965608\n",
            "2019-06-17 06:44:30,323 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:44:30,325 EPOCH 4 done: loss 1.0638 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:44:57,263 DEV : loss 0.8505699038505554 - score 0.6562\n",
            "2019-06-17 06:46:34,469 TEST : loss 0.9013921618461609 - score 0.6127\n",
            "2019-06-17 06:46:34,975 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:46:36,012 epoch 5 - iter 0/335 - loss 2.30997038\n",
            "2019-06-17 06:46:57,403 epoch 5 - iter 33/335 - loss 0.99908675\n",
            "2019-06-17 06:47:20,356 epoch 5 - iter 66/335 - loss 0.95404902\n",
            "2019-06-17 06:47:43,228 epoch 5 - iter 99/335 - loss 0.99594208\n",
            "2019-06-17 06:48:06,893 epoch 5 - iter 132/335 - loss 0.97815114\n",
            "2019-06-17 06:48:27,367 epoch 5 - iter 165/335 - loss 0.97758661\n",
            "2019-06-17 06:48:48,719 epoch 5 - iter 198/335 - loss 0.95059602\n",
            "2019-06-17 06:49:08,937 epoch 5 - iter 231/335 - loss 0.97156933\n",
            "2019-06-17 06:49:33,227 epoch 5 - iter 264/335 - loss 0.97891728\n",
            "2019-06-17 06:49:58,066 epoch 5 - iter 297/335 - loss 0.95369636\n",
            "2019-06-17 06:50:17,159 epoch 5 - iter 330/335 - loss 0.94418981\n",
            "2019-06-17 06:50:19,934 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:50:19,935 EPOCH 5 done: loss 0.9421 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:50:46,904 DEV : loss 0.8018030524253845 - score 0.6701\n",
            "2019-06-17 06:52:24,138 TEST : loss 0.8651852011680603 - score 0.6272\n",
            "2019-06-17 06:52:24,719 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:52:25,788 epoch 6 - iter 0/335 - loss 0.60419446\n",
            "2019-06-17 06:52:50,798 epoch 6 - iter 33/335 - loss 0.88494230\n",
            "2019-06-17 06:53:13,213 epoch 6 - iter 66/335 - loss 0.91126385\n",
            "2019-06-17 06:53:36,457 epoch 6 - iter 99/335 - loss 0.94092171\n",
            "2019-06-17 06:53:57,984 epoch 6 - iter 132/335 - loss 0.90545804\n",
            "2019-06-17 06:54:21,338 epoch 6 - iter 165/335 - loss 0.90950130\n",
            "2019-06-17 06:54:41,571 epoch 6 - iter 198/335 - loss 0.90075560\n",
            "2019-06-17 06:55:03,354 epoch 6 - iter 231/335 - loss 0.88131802\n",
            "2019-06-17 06:55:25,180 epoch 6 - iter 264/335 - loss 0.87542067\n",
            "2019-06-17 06:55:44,526 epoch 6 - iter 297/335 - loss 0.87759660\n",
            "2019-06-17 06:56:04,610 epoch 6 - iter 330/335 - loss 0.87456461\n",
            "2019-06-17 06:56:07,861 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:56:07,863 EPOCH 6 done: loss 0.8737 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 06:56:36,069 DEV : loss 0.7567595839500427 - score 0.681\n",
            "2019-06-17 06:58:13,231 TEST : loss 0.8607591986656189 - score 0.6338\n",
            "2019-06-17 06:58:13,752 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 06:58:14,819 epoch 7 - iter 0/335 - loss 0.25628901\n",
            "2019-06-17 06:58:35,688 epoch 7 - iter 33/335 - loss 0.88949063\n",
            "2019-06-17 06:58:59,455 epoch 7 - iter 66/335 - loss 0.81825377\n",
            "2019-06-17 06:59:21,396 epoch 7 - iter 99/335 - loss 0.80087669\n",
            "2019-06-17 06:59:43,179 epoch 7 - iter 132/335 - loss 0.79757469\n",
            "2019-06-17 07:00:03,705 epoch 7 - iter 165/335 - loss 0.80492636\n",
            "2019-06-17 07:00:25,172 epoch 7 - iter 198/335 - loss 0.80065773\n",
            "2019-06-17 07:00:50,178 epoch 7 - iter 231/335 - loss 0.80303687\n",
            "2019-06-17 07:01:12,453 epoch 7 - iter 264/335 - loss 0.79800636\n",
            "2019-06-17 07:01:35,213 epoch 7 - iter 297/335 - loss 0.81907741\n",
            "2019-06-17 07:01:55,316 epoch 7 - iter 330/335 - loss 0.81191255\n",
            "2019-06-17 07:01:57,405 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:01:57,406 EPOCH 7 done: loss 0.8153 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 07:02:24,353 DEV : loss 0.7505383491516113 - score 0.6449\n",
            "2019-06-17 07:04:01,249 TEST : loss 0.8209409713745117 - score 0.6243\n",
            "2019-06-17 07:04:01,251 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:04:02,135 epoch 8 - iter 0/335 - loss 0.11134750\n",
            "2019-06-17 07:04:26,342 epoch 8 - iter 33/335 - loss 0.84732448\n",
            "2019-06-17 07:04:50,808 epoch 8 - iter 66/335 - loss 0.80549958\n",
            "2019-06-17 07:05:12,732 epoch 8 - iter 99/335 - loss 0.75802766\n",
            "2019-06-17 07:05:35,090 epoch 8 - iter 132/335 - loss 0.75629492\n",
            "2019-06-17 07:05:57,795 epoch 8 - iter 165/335 - loss 0.78485839\n",
            "2019-06-17 07:06:21,496 epoch 8 - iter 198/335 - loss 0.80111531\n",
            "2019-06-17 07:06:43,186 epoch 8 - iter 231/335 - loss 0.80001595\n",
            "2019-06-17 07:07:03,356 epoch 8 - iter 264/335 - loss 0.80492950\n",
            "2019-06-17 07:07:23,118 epoch 8 - iter 297/335 - loss 0.78461588\n",
            "2019-06-17 07:07:43,583 epoch 8 - iter 330/335 - loss 0.77773080\n",
            "2019-06-17 07:07:47,439 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:07:47,440 EPOCH 8 done: loss 0.7828 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 07:08:15,682 DEV : loss 0.6977480053901672 - score 0.6868\n",
            "2019-06-17 07:09:52,530 TEST : loss 0.809789776802063 - score 0.642\n",
            "2019-06-17 07:09:52,981 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:09:54,721 epoch 9 - iter 0/335 - loss 0.56765246\n",
            "2019-06-17 07:10:15,810 epoch 9 - iter 33/335 - loss 0.67274961\n",
            "2019-06-17 07:10:37,449 epoch 9 - iter 66/335 - loss 0.69039038\n",
            "2019-06-17 07:11:00,267 epoch 9 - iter 99/335 - loss 0.72678256\n",
            "2019-06-17 07:11:19,780 epoch 9 - iter 132/335 - loss 0.71058967\n",
            "2019-06-17 07:11:41,897 epoch 9 - iter 165/335 - loss 0.71347940\n",
            "2019-06-17 07:12:02,891 epoch 9 - iter 198/335 - loss 0.72538428\n",
            "2019-06-17 07:12:25,059 epoch 9 - iter 231/335 - loss 0.70868040\n",
            "2019-06-17 07:12:45,871 epoch 9 - iter 264/335 - loss 0.71651814\n",
            "2019-06-17 07:13:06,751 epoch 9 - iter 297/335 - loss 0.72374108\n",
            "2019-06-17 07:13:32,062 epoch 9 - iter 330/335 - loss 0.73187001\n",
            "2019-06-17 07:13:36,910 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:13:36,912 EPOCH 9 done: loss 0.7317 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 07:14:03,689 DEV : loss 0.6989521980285645 - score 0.6768\n",
            "2019-06-17 07:15:40,637 TEST : loss 0.7755651473999023 - score 0.6441\n",
            "2019-06-17 07:15:40,639 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:15:41,784 epoch 10 - iter 0/335 - loss 1.01774192\n",
            "2019-06-17 07:16:07,602 epoch 10 - iter 33/335 - loss 0.62932518\n",
            "2019-06-17 07:16:31,460 epoch 10 - iter 66/335 - loss 0.63536297\n",
            "2019-06-17 07:16:49,910 epoch 10 - iter 99/335 - loss 0.67326262\n",
            "2019-06-17 07:17:13,340 epoch 10 - iter 132/335 - loss 0.69253888\n",
            "2019-06-17 07:17:35,727 epoch 10 - iter 165/335 - loss 0.72386365\n",
            "2019-06-17 07:17:55,167 epoch 10 - iter 198/335 - loss 0.71445336\n",
            "2019-06-17 07:18:17,580 epoch 10 - iter 231/335 - loss 0.72016726\n",
            "2019-06-17 07:18:39,378 epoch 10 - iter 264/335 - loss 0.71787043\n",
            "2019-06-17 07:19:02,523 epoch 10 - iter 297/335 - loss 0.71263067\n",
            "2019-06-17 07:19:22,716 epoch 10 - iter 330/335 - loss 0.71145748\n",
            "2019-06-17 07:19:25,656 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:19:25,657 EPOCH 10 done: loss 0.7169 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 07:19:54,033 DEV : loss 0.6974056363105774 - score 0.6951\n",
            "2019-06-17 07:21:30,060 TEST : loss 0.7762027978897095 - score 0.6437\n",
            "2019-06-17 07:21:30,535 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:21:31,905 epoch 11 - iter 0/335 - loss 0.08492674\n",
            "2019-06-17 07:21:56,620 epoch 11 - iter 33/335 - loss 0.69398948\n",
            "2019-06-17 07:22:16,114 epoch 11 - iter 66/335 - loss 0.67411289\n",
            "2019-06-17 07:22:35,079 epoch 11 - iter 99/335 - loss 0.67092160\n",
            "2019-06-17 07:22:58,711 epoch 11 - iter 132/335 - loss 0.66589058\n",
            "2019-06-17 07:23:18,305 epoch 11 - iter 165/335 - loss 0.67006360\n",
            "2019-06-17 07:23:40,534 epoch 11 - iter 198/335 - loss 0.67188670\n",
            "2019-06-17 07:24:03,806 epoch 11 - iter 231/335 - loss 0.67740791\n",
            "2019-06-17 07:24:31,892 epoch 11 - iter 264/335 - loss 0.67257262\n",
            "2019-06-17 07:24:53,852 epoch 11 - iter 297/335 - loss 0.68425012\n",
            "2019-06-17 07:25:15,472 epoch 11 - iter 330/335 - loss 0.68228366\n",
            "2019-06-17 07:25:18,371 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:25:18,374 EPOCH 11 done: loss 0.6834 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 07:25:45,312 DEV : loss 0.6288965940475464 - score 0.693\n",
            "2019-06-17 07:27:22,266 TEST : loss 0.7370880842208862 - score 0.6589\n",
            "2019-06-17 07:27:22,267 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:27:23,420 epoch 12 - iter 0/335 - loss 0.59155190\n",
            "2019-06-17 07:27:44,720 epoch 12 - iter 33/335 - loss 0.70582108\n",
            "2019-06-17 07:28:10,205 epoch 12 - iter 66/335 - loss 0.66626945\n",
            "2019-06-17 07:28:31,134 epoch 12 - iter 99/335 - loss 0.64140347\n",
            "2019-06-17 07:28:55,303 epoch 12 - iter 132/335 - loss 0.63577854\n",
            "2019-06-17 07:29:17,816 epoch 12 - iter 165/335 - loss 0.65749064\n",
            "2019-06-17 07:29:39,707 epoch 12 - iter 198/335 - loss 0.65609691\n",
            "2019-06-17 07:29:59,864 epoch 12 - iter 231/335 - loss 0.65058000\n",
            "2019-06-17 07:30:21,770 epoch 12 - iter 264/335 - loss 0.66222732\n",
            "2019-06-17 07:30:44,396 epoch 12 - iter 297/335 - loss 0.66294888\n",
            "2019-06-17 07:31:04,027 epoch 12 - iter 330/335 - loss 0.67523864\n",
            "2019-06-17 07:31:06,853 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:31:06,854 EPOCH 12 done: loss 0.6761 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 07:31:35,079 DEV : loss 0.682861864566803 - score 0.6728\n",
            "2019-06-17 07:33:10,581 TEST : loss 0.7772727608680725 - score 0.639\n",
            "2019-06-17 07:33:10,582 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:33:11,570 epoch 13 - iter 0/335 - loss 0.36318934\n",
            "2019-06-17 07:33:31,733 epoch 13 - iter 33/335 - loss 0.67787486\n",
            "2019-06-17 07:33:55,522 epoch 13 - iter 66/335 - loss 0.69988854\n",
            "2019-06-17 07:34:17,103 epoch 13 - iter 99/335 - loss 0.66220007\n",
            "2019-06-17 07:34:39,837 epoch 13 - iter 132/335 - loss 0.66748871\n",
            "2019-06-17 07:35:02,509 epoch 13 - iter 165/335 - loss 0.64126315\n",
            "2019-06-17 07:35:24,460 epoch 13 - iter 198/335 - loss 0.65319918\n",
            "2019-06-17 07:35:46,348 epoch 13 - iter 231/335 - loss 0.65096650\n",
            "2019-06-17 07:36:06,082 epoch 13 - iter 264/335 - loss 0.64657094\n",
            "2019-06-17 07:36:27,694 epoch 13 - iter 297/335 - loss 0.65252295\n",
            "2019-06-17 07:36:51,586 epoch 13 - iter 330/335 - loss 0.64873598\n",
            "2019-06-17 07:36:54,563 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:36:54,565 EPOCH 13 done: loss 0.6518 - lr 0.1000 - bad epochs 2\n",
            "2019-06-17 07:37:21,420 DEV : loss 0.6282797455787659 - score 0.6717\n",
            "2019-06-17 07:38:58,001 TEST : loss 0.7424177527427673 - score 0.619\n",
            "2019-06-17 07:38:58,003 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:38:58,794 epoch 14 - iter 0/335 - loss 0.20089638\n",
            "2019-06-17 07:39:19,144 epoch 14 - iter 33/335 - loss 0.52950451\n",
            "2019-06-17 07:39:43,766 epoch 14 - iter 66/335 - loss 0.58491755\n",
            "2019-06-17 07:40:09,293 epoch 14 - iter 99/335 - loss 0.59241028\n",
            "2019-06-17 07:40:28,828 epoch 14 - iter 132/335 - loss 0.62506340\n",
            "2019-06-17 07:40:52,552 epoch 14 - iter 165/335 - loss 0.61366237\n",
            "2019-06-17 07:41:13,353 epoch 14 - iter 198/335 - loss 0.61563979\n",
            "2019-06-17 07:41:32,936 epoch 14 - iter 231/335 - loss 0.60546617\n",
            "2019-06-17 07:41:55,415 epoch 14 - iter 264/335 - loss 0.61211682\n",
            "2019-06-17 07:42:14,693 epoch 14 - iter 297/335 - loss 0.62751958\n",
            "2019-06-17 07:42:36,934 epoch 14 - iter 330/335 - loss 0.62750237\n",
            "2019-06-17 07:42:39,765 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:42:39,766 EPOCH 14 done: loss 0.6266 - lr 0.1000 - bad epochs 3\n",
            "2019-06-17 07:43:07,666 DEV : loss 0.6188886165618896 - score 0.6966\n",
            "2019-06-17 07:44:42,586 TEST : loss 0.730858564376831 - score 0.6669\n",
            "2019-06-17 07:44:43,185 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:44:44,538 epoch 15 - iter 0/335 - loss 0.90895855\n",
            "2019-06-17 07:45:06,823 epoch 15 - iter 33/335 - loss 0.56783384\n",
            "2019-06-17 07:45:30,106 epoch 15 - iter 66/335 - loss 0.59900289\n",
            "2019-06-17 07:45:53,351 epoch 15 - iter 99/335 - loss 0.61733938\n",
            "2019-06-17 07:46:16,572 epoch 15 - iter 132/335 - loss 0.62193156\n",
            "2019-06-17 07:46:39,192 epoch 15 - iter 165/335 - loss 0.61650227\n",
            "2019-06-17 07:46:59,178 epoch 15 - iter 198/335 - loss 0.60629885\n",
            "2019-06-17 07:47:19,630 epoch 15 - iter 231/335 - loss 0.58755229\n",
            "2019-06-17 07:47:40,269 epoch 15 - iter 264/335 - loss 0.60343331\n",
            "2019-06-17 07:48:01,651 epoch 15 - iter 297/335 - loss 0.59778948\n",
            "2019-06-17 07:48:24,351 epoch 15 - iter 330/335 - loss 0.61308321\n",
            "2019-06-17 07:48:26,676 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:48:26,677 EPOCH 15 done: loss 0.6146 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 07:48:53,139 DEV : loss 0.5982338786125183 - score 0.6953\n",
            "2019-06-17 07:50:28,874 TEST : loss 0.7082132697105408 - score 0.6557\n",
            "2019-06-17 07:50:28,878 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:50:30,219 epoch 16 - iter 0/335 - loss 0.73367226\n",
            "2019-06-17 07:50:51,714 epoch 16 - iter 33/335 - loss 0.55978767\n",
            "2019-06-17 07:51:14,207 epoch 16 - iter 66/335 - loss 0.55382458\n",
            "2019-06-17 07:51:36,514 epoch 16 - iter 99/335 - loss 0.54235543\n",
            "2019-06-17 07:51:59,222 epoch 16 - iter 132/335 - loss 0.54991261\n",
            "2019-06-17 07:52:19,735 epoch 16 - iter 165/335 - loss 0.59202357\n",
            "2019-06-17 07:52:41,573 epoch 16 - iter 198/335 - loss 0.57098042\n",
            "2019-06-17 07:53:01,438 epoch 16 - iter 231/335 - loss 0.57201598\n",
            "2019-06-17 07:53:22,210 epoch 16 - iter 264/335 - loss 0.57227439\n",
            "2019-06-17 07:53:45,493 epoch 16 - iter 297/335 - loss 0.57505358\n",
            "2019-06-17 07:54:09,092 epoch 16 - iter 330/335 - loss 0.56860727\n",
            "2019-06-17 07:54:11,569 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:54:11,570 EPOCH 16 done: loss 0.5681 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 07:54:39,479 DEV : loss 0.6102637648582458 - score 0.6761\n",
            "2019-06-17 07:56:14,336 TEST : loss 0.7133405208587646 - score 0.6478\n",
            "2019-06-17 07:56:14,338 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:56:15,416 epoch 17 - iter 0/335 - loss 0.53303564\n",
            "2019-06-17 07:56:36,380 epoch 17 - iter 33/335 - loss 0.54022910\n",
            "2019-06-17 07:56:58,342 epoch 17 - iter 66/335 - loss 0.49943366\n",
            "2019-06-17 07:57:24,819 epoch 17 - iter 99/335 - loss 0.53903118\n",
            "2019-06-17 07:57:46,990 epoch 17 - iter 132/335 - loss 0.52918034\n",
            "2019-06-17 07:58:09,543 epoch 17 - iter 165/335 - loss 0.52363221\n",
            "2019-06-17 07:58:29,623 epoch 17 - iter 198/335 - loss 0.54245873\n",
            "2019-06-17 07:58:51,083 epoch 17 - iter 231/335 - loss 0.55624114\n",
            "2019-06-17 07:59:11,082 epoch 17 - iter 264/335 - loss 0.57192813\n",
            "2019-06-17 07:59:31,323 epoch 17 - iter 297/335 - loss 0.56623085\n",
            "2019-06-17 07:59:50,519 epoch 17 - iter 330/335 - loss 0.56888671\n",
            "2019-06-17 07:59:56,144 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 07:59:56,146 EPOCH 17 done: loss 0.5694 - lr 0.1000 - bad epochs 2\n",
            "2019-06-17 08:00:22,669 DEV : loss 0.6469424962997437 - score 0.6908\n",
            "2019-06-17 08:01:58,782 TEST : loss 0.7646448612213135 - score 0.6579\n",
            "2019-06-17 08:01:58,783 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:01:59,944 epoch 18 - iter 0/335 - loss 0.37754667\n",
            "2019-06-17 08:02:21,923 epoch 18 - iter 33/335 - loss 0.48945202\n",
            "2019-06-17 08:02:45,209 epoch 18 - iter 66/335 - loss 0.54437754\n",
            "2019-06-17 08:03:04,697 epoch 18 - iter 99/335 - loss 0.53569950\n",
            "2019-06-17 08:03:28,638 epoch 18 - iter 132/335 - loss 0.57273959\n",
            "2019-06-17 08:03:50,158 epoch 18 - iter 165/335 - loss 0.56046000\n",
            "2019-06-17 08:04:11,857 epoch 18 - iter 198/335 - loss 0.56851463\n",
            "2019-06-17 08:04:35,412 epoch 18 - iter 231/335 - loss 0.58060943\n",
            "2019-06-17 08:04:56,705 epoch 18 - iter 264/335 - loss 0.57040102\n",
            "2019-06-17 08:05:17,408 epoch 18 - iter 297/335 - loss 0.56344510\n",
            "2019-06-17 08:05:37,778 epoch 18 - iter 330/335 - loss 0.56330612\n",
            "2019-06-17 08:05:40,377 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:05:40,378 EPOCH 18 done: loss 0.5616 - lr 0.1000 - bad epochs 3\n",
            "2019-06-17 08:06:07,091 DEV : loss 0.6260923743247986 - score 0.673\n",
            "2019-06-17 08:07:43,392 TEST : loss 0.7125750184059143 - score 0.6489\n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-06-17 08:07:43,393 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:07:44,498 epoch 19 - iter 0/335 - loss 0.42797238\n",
            "2019-06-17 08:08:05,633 epoch 19 - iter 33/335 - loss 0.49923203\n",
            "2019-06-17 08:08:29,962 epoch 19 - iter 66/335 - loss 0.48691688\n",
            "2019-06-17 08:08:48,377 epoch 19 - iter 99/335 - loss 0.50222343\n",
            "2019-06-17 08:09:13,000 epoch 19 - iter 132/335 - loss 0.51847371\n",
            "2019-06-17 08:09:36,130 epoch 19 - iter 165/335 - loss 0.51794642\n",
            "2019-06-17 08:09:57,882 epoch 19 - iter 198/335 - loss 0.51410247\n",
            "2019-06-17 08:10:18,609 epoch 19 - iter 231/335 - loss 0.51967712\n",
            "2019-06-17 08:10:42,884 epoch 19 - iter 264/335 - loss 0.51471783\n",
            "2019-06-17 08:11:04,553 epoch 19 - iter 297/335 - loss 0.50527832\n",
            "2019-06-17 08:11:25,363 epoch 19 - iter 330/335 - loss 0.51413485\n",
            "2019-06-17 08:11:29,049 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:11:29,050 EPOCH 19 done: loss 0.5142 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 08:11:57,055 DEV : loss 0.5791099071502686 - score 0.7041\n",
            "2019-06-17 08:13:32,487 TEST : loss 0.7087158560752869 - score 0.6554\n",
            "2019-06-17 08:13:32,965 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:13:34,038 epoch 20 - iter 0/335 - loss 1.72225666\n",
            "2019-06-17 08:13:59,632 epoch 20 - iter 33/335 - loss 0.52163716\n",
            "2019-06-17 08:14:19,278 epoch 20 - iter 66/335 - loss 0.49439679\n",
            "2019-06-17 08:14:37,659 epoch 20 - iter 99/335 - loss 0.51748794\n",
            "2019-06-17 08:15:01,899 epoch 20 - iter 132/335 - loss 0.51513790\n",
            "2019-06-17 08:15:23,122 epoch 20 - iter 165/335 - loss 0.54108229\n",
            "2019-06-17 08:15:42,864 epoch 20 - iter 198/335 - loss 0.52568349\n",
            "2019-06-17 08:16:04,529 epoch 20 - iter 231/335 - loss 0.51981668\n",
            "2019-06-17 08:16:27,222 epoch 20 - iter 264/335 - loss 0.49706933\n",
            "2019-06-17 08:16:49,287 epoch 20 - iter 297/335 - loss 0.50350210\n",
            "2019-06-17 08:17:13,956 epoch 20 - iter 330/335 - loss 0.50454428\n",
            "2019-06-17 08:17:16,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:17:16,410 EPOCH 20 done: loss 0.5058 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 08:17:43,386 DEV : loss 0.5864577889442444 - score 0.719\n",
            "2019-06-17 08:19:20,766 TEST : loss 0.7196382284164429 - score 0.667\n",
            "2019-06-17 08:19:21,293 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:19:22,353 epoch 21 - iter 0/335 - loss 0.82157761\n",
            "2019-06-17 08:19:45,339 epoch 21 - iter 33/335 - loss 0.51629933\n",
            "2019-06-17 08:20:06,966 epoch 21 - iter 66/335 - loss 0.50560125\n",
            "2019-06-17 08:20:32,448 epoch 21 - iter 99/335 - loss 0.50732974\n",
            "2019-06-17 08:20:53,246 epoch 21 - iter 132/335 - loss 0.49648291\n",
            "2019-06-17 08:21:14,642 epoch 21 - iter 165/335 - loss 0.48677117\n",
            "2019-06-17 08:21:35,599 epoch 21 - iter 198/335 - loss 0.47813923\n",
            "2019-06-17 08:21:55,433 epoch 21 - iter 231/335 - loss 0.47312004\n",
            "2019-06-17 08:22:18,491 epoch 21 - iter 264/335 - loss 0.48073634\n",
            "2019-06-17 08:22:40,574 epoch 21 - iter 297/335 - loss 0.48170970\n",
            "2019-06-17 08:23:02,937 epoch 21 - iter 330/335 - loss 0.47873245\n",
            "2019-06-17 08:23:05,891 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:23:05,892 EPOCH 21 done: loss 0.4799 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 08:23:33,713 DEV : loss 0.6024468541145325 - score 0.7192\n",
            "2019-06-17 08:25:08,841 TEST : loss 0.752614438533783 - score 0.6614\n",
            "2019-06-17 08:25:09,344 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:25:10,671 epoch 22 - iter 0/335 - loss 0.73871219\n",
            "2019-06-17 08:25:33,837 epoch 22 - iter 33/335 - loss 0.47382250\n",
            "2019-06-17 08:25:55,593 epoch 22 - iter 66/335 - loss 0.50878768\n",
            "2019-06-17 08:26:20,086 epoch 22 - iter 99/335 - loss 0.48744098\n",
            "2019-06-17 08:26:44,237 epoch 22 - iter 132/335 - loss 0.50056532\n",
            "2019-06-17 08:27:04,046 epoch 22 - iter 165/335 - loss 0.47442857\n",
            "2019-06-17 08:27:26,191 epoch 22 - iter 198/335 - loss 0.46777879\n",
            "2019-06-17 08:27:48,416 epoch 22 - iter 231/335 - loss 0.47691552\n",
            "2019-06-17 08:28:07,568 epoch 22 - iter 264/335 - loss 0.47950929\n",
            "2019-06-17 08:28:28,123 epoch 22 - iter 297/335 - loss 0.47076600\n",
            "2019-06-17 08:28:50,156 epoch 22 - iter 330/335 - loss 0.47084341\n",
            "2019-06-17 08:28:53,902 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:28:53,904 EPOCH 22 done: loss 0.4703 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 08:29:20,722 DEV : loss 0.5929629802703857 - score 0.7183\n",
            "2019-06-17 08:30:57,039 TEST : loss 0.7378250360488892 - score 0.667\n",
            "2019-06-17 08:30:57,041 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:30:58,168 epoch 23 - iter 0/335 - loss 0.55231780\n",
            "2019-06-17 08:31:21,709 epoch 23 - iter 33/335 - loss 0.49263810\n",
            "2019-06-17 08:31:43,281 epoch 23 - iter 66/335 - loss 0.46190593\n",
            "2019-06-17 08:32:06,827 epoch 23 - iter 99/335 - loss 0.46314266\n",
            "2019-06-17 08:32:28,707 epoch 23 - iter 132/335 - loss 0.46536244\n",
            "2019-06-17 08:32:50,231 epoch 23 - iter 165/335 - loss 0.46017296\n",
            "2019-06-17 08:33:12,958 epoch 23 - iter 198/335 - loss 0.47896237\n",
            "2019-06-17 08:33:30,673 epoch 23 - iter 231/335 - loss 0.46010879\n",
            "2019-06-17 08:33:52,103 epoch 23 - iter 264/335 - loss 0.46032211\n",
            "2019-06-17 08:34:13,340 epoch 23 - iter 297/335 - loss 0.46187671\n",
            "2019-06-17 08:34:38,682 epoch 23 - iter 330/335 - loss 0.46505001\n",
            "2019-06-17 08:34:41,187 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:34:41,188 EPOCH 23 done: loss 0.4658 - lr 0.0500 - bad epochs 1\n",
            "2019-06-17 08:35:07,816 DEV : loss 0.56768798828125 - score 0.7084\n",
            "2019-06-17 08:36:44,296 TEST : loss 0.7073510885238647 - score 0.665\n",
            "2019-06-17 08:36:44,297 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:36:45,804 epoch 24 - iter 0/335 - loss 0.22883411\n",
            "2019-06-17 08:37:03,713 epoch 24 - iter 33/335 - loss 0.41487500\n",
            "2019-06-17 08:37:28,122 epoch 24 - iter 66/335 - loss 0.43583870\n",
            "2019-06-17 08:37:51,387 epoch 24 - iter 99/335 - loss 0.43758629\n",
            "2019-06-17 08:38:14,238 epoch 24 - iter 132/335 - loss 0.42499350\n",
            "2019-06-17 08:38:35,942 epoch 24 - iter 165/335 - loss 0.42483516\n",
            "2019-06-17 08:38:56,900 epoch 24 - iter 198/335 - loss 0.42478074\n",
            "2019-06-17 08:39:18,345 epoch 24 - iter 231/335 - loss 0.44664092\n",
            "2019-06-17 08:39:43,000 epoch 24 - iter 264/335 - loss 0.45464733\n",
            "2019-06-17 08:40:03,159 epoch 24 - iter 297/335 - loss 0.45617424\n",
            "2019-06-17 08:40:24,877 epoch 24 - iter 330/335 - loss 0.45811818\n",
            "2019-06-17 08:40:27,293 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:40:27,294 EPOCH 24 done: loss 0.4572 - lr 0.0500 - bad epochs 2\n",
            "2019-06-17 08:40:55,408 DEV : loss 0.6166293025016785 - score 0.722\n",
            "2019-06-17 08:42:31,749 TEST : loss 0.7311370372772217 - score 0.6669\n",
            "2019-06-17 08:42:32,248 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:42:33,405 epoch 25 - iter 0/335 - loss 0.90844244\n",
            "2019-06-17 08:42:55,419 epoch 25 - iter 33/335 - loss 0.45546421\n",
            "2019-06-17 08:43:16,977 epoch 25 - iter 66/335 - loss 0.44604400\n",
            "2019-06-17 08:43:40,210 epoch 25 - iter 99/335 - loss 0.44459143\n",
            "2019-06-17 08:44:00,485 epoch 25 - iter 132/335 - loss 0.42320641\n",
            "2019-06-17 08:44:19,867 epoch 25 - iter 165/335 - loss 0.43377947\n",
            "2019-06-17 08:44:42,170 epoch 25 - iter 198/335 - loss 0.44069028\n",
            "2019-06-17 08:45:06,812 epoch 25 - iter 231/335 - loss 0.44583388\n",
            "2019-06-17 08:45:25,799 epoch 25 - iter 264/335 - loss 0.44691854\n",
            "2019-06-17 08:45:48,665 epoch 25 - iter 297/335 - loss 0.44160733\n",
            "2019-06-17 08:46:10,892 epoch 25 - iter 330/335 - loss 0.45119181\n",
            "2019-06-17 08:46:14,767 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:46:14,769 EPOCH 25 done: loss 0.4524 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 08:46:41,355 DEV : loss 0.5939438939094543 - score 0.7035\n",
            "2019-06-17 08:48:17,966 TEST : loss 0.7285106182098389 - score 0.6504\n",
            "2019-06-17 08:48:17,968 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:48:19,228 epoch 26 - iter 0/335 - loss 0.29199070\n",
            "2019-06-17 08:48:42,745 epoch 26 - iter 33/335 - loss 0.53471473\n",
            "2019-06-17 08:49:05,536 epoch 26 - iter 66/335 - loss 0.54671951\n",
            "2019-06-17 08:49:28,103 epoch 26 - iter 99/335 - loss 0.49178969\n",
            "2019-06-17 08:49:47,174 epoch 26 - iter 132/335 - loss 0.48233095\n",
            "2019-06-17 08:50:09,126 epoch 26 - iter 165/335 - loss 0.46124079\n",
            "2019-06-17 08:50:30,600 epoch 26 - iter 198/335 - loss 0.45848412\n",
            "2019-06-17 08:50:54,518 epoch 26 - iter 231/335 - loss 0.46091270\n",
            "2019-06-17 08:51:14,805 epoch 26 - iter 264/335 - loss 0.45323033\n",
            "2019-06-17 08:51:34,725 epoch 26 - iter 297/335 - loss 0.44720031\n",
            "2019-06-17 08:51:58,075 epoch 26 - iter 330/335 - loss 0.44894419\n",
            "2019-06-17 08:52:00,764 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:52:00,766 EPOCH 26 done: loss 0.4510 - lr 0.0500 - bad epochs 1\n",
            "2019-06-17 08:52:28,983 DEV : loss 0.5684407353401184 - score 0.7031\n",
            "2019-06-17 08:54:04,367 TEST : loss 0.7145763039588928 - score 0.6513\n",
            "2019-06-17 08:54:04,368 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:54:05,535 epoch 27 - iter 0/335 - loss 0.37530586\n",
            "2019-06-17 08:54:29,691 epoch 27 - iter 33/335 - loss 0.41224375\n",
            "2019-06-17 08:54:50,277 epoch 27 - iter 66/335 - loss 0.42869039\n",
            "2019-06-17 08:55:09,747 epoch 27 - iter 99/335 - loss 0.39998894\n",
            "2019-06-17 08:55:33,386 epoch 27 - iter 132/335 - loss 0.41458896\n",
            "2019-06-17 08:55:53,957 epoch 27 - iter 165/335 - loss 0.40435885\n",
            "2019-06-17 08:56:15,849 epoch 27 - iter 198/335 - loss 0.43820601\n",
            "2019-06-17 08:56:40,954 epoch 27 - iter 231/335 - loss 0.43750469\n",
            "2019-06-17 08:57:01,481 epoch 27 - iter 264/335 - loss 0.43505763\n",
            "2019-06-17 08:57:23,978 epoch 27 - iter 297/335 - loss 0.43256150\n",
            "2019-06-17 08:57:45,053 epoch 27 - iter 330/335 - loss 0.43690487\n",
            "2019-06-17 08:57:47,720 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:57:47,722 EPOCH 27 done: loss 0.4368 - lr 0.0500 - bad epochs 2\n",
            "2019-06-17 08:58:14,466 DEV : loss 0.5928026437759399 - score 0.7209\n",
            "2019-06-17 08:59:50,903 TEST : loss 0.732322096824646 - score 0.6698\n",
            "2019-06-17 08:59:50,905 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 08:59:51,906 epoch 28 - iter 0/335 - loss 0.51377529\n",
            "2019-06-17 09:00:12,250 epoch 28 - iter 33/335 - loss 0.43527240\n",
            "2019-06-17 09:00:35,302 epoch 28 - iter 66/335 - loss 0.43224009\n",
            "2019-06-17 09:00:57,772 epoch 28 - iter 99/335 - loss 0.45500063\n",
            "2019-06-17 09:01:18,617 epoch 28 - iter 132/335 - loss 0.45459588\n",
            "2019-06-17 09:01:39,894 epoch 28 - iter 165/335 - loss 0.45938497\n",
            "2019-06-17 09:02:02,723 epoch 28 - iter 198/335 - loss 0.44625653\n",
            "2019-06-17 09:02:23,881 epoch 28 - iter 231/335 - loss 0.44664251\n",
            "2019-06-17 09:02:47,910 epoch 28 - iter 264/335 - loss 0.43553695\n",
            "2019-06-17 09:03:08,846 epoch 28 - iter 297/335 - loss 0.42475395\n",
            "2019-06-17 09:03:33,100 epoch 28 - iter 330/335 - loss 0.42643322\n",
            "2019-06-17 09:03:35,587 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:03:35,588 EPOCH 28 done: loss 0.4251 - lr 0.0500 - bad epochs 3\n",
            "2019-06-17 09:04:03,607 DEV : loss 0.58901447057724 - score 0.717\n",
            "2019-06-17 09:05:39,128 TEST : loss 0.7377119064331055 - score 0.6517\n",
            "Epoch    27: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-06-17 09:05:39,130 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:05:40,427 epoch 29 - iter 0/335 - loss 0.23896393\n",
            "2019-06-17 09:06:02,242 epoch 29 - iter 33/335 - loss 0.39301095\n",
            "2019-06-17 09:06:22,429 epoch 29 - iter 66/335 - loss 0.40612324\n",
            "2019-06-17 09:06:45,149 epoch 29 - iter 99/335 - loss 0.42186766\n",
            "2019-06-17 09:07:07,335 epoch 29 - iter 132/335 - loss 0.41694375\n",
            "2019-06-17 09:07:32,728 epoch 29 - iter 165/335 - loss 0.43183399\n",
            "2019-06-17 09:07:55,173 epoch 29 - iter 198/335 - loss 0.43132411\n",
            "2019-06-17 09:08:16,264 epoch 29 - iter 231/335 - loss 0.42368267\n",
            "2019-06-17 09:08:40,456 epoch 29 - iter 264/335 - loss 0.42380617\n",
            "2019-06-17 09:09:01,409 epoch 29 - iter 297/335 - loss 0.42022533\n",
            "2019-06-17 09:09:21,784 epoch 29 - iter 330/335 - loss 0.41991526\n",
            "2019-06-17 09:09:24,195 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:09:24,196 EPOCH 29 done: loss 0.4192 - lr 0.0250 - bad epochs 0\n",
            "2019-06-17 09:09:50,909 DEV : loss 0.5693241357803345 - score 0.7254\n",
            "2019-06-17 09:11:27,553 TEST : loss 0.7284093499183655 - score 0.6675\n",
            "2019-06-17 09:11:27,983 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:11:29,557 epoch 30 - iter 0/335 - loss 0.57730091\n",
            "2019-06-17 09:11:49,588 epoch 30 - iter 33/335 - loss 0.43559347\n",
            "2019-06-17 09:12:13,376 epoch 30 - iter 66/335 - loss 0.39622097\n",
            "2019-06-17 09:12:34,650 epoch 30 - iter 99/335 - loss 0.38558929\n",
            "2019-06-17 09:12:59,248 epoch 30 - iter 132/335 - loss 0.40169126\n",
            "2019-06-17 09:13:21,691 epoch 30 - iter 165/335 - loss 0.39875474\n",
            "2019-06-17 09:13:42,676 epoch 30 - iter 198/335 - loss 0.40214213\n",
            "2019-06-17 09:14:04,979 epoch 30 - iter 231/335 - loss 0.39656603\n",
            "2019-06-17 09:14:25,529 epoch 30 - iter 264/335 - loss 0.40667936\n",
            "2019-06-17 09:14:46,885 epoch 30 - iter 297/335 - loss 0.40744116\n",
            "2019-06-17 09:15:08,295 epoch 30 - iter 330/335 - loss 0.40136605\n",
            "2019-06-17 09:15:10,781 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:15:10,783 EPOCH 30 done: loss 0.3996 - lr 0.0250 - bad epochs 0\n",
            "2019-06-17 09:15:38,930 DEV : loss 0.5754075646400452 - score 0.7169\n",
            "2019-06-17 09:17:14,417 TEST : loss 0.7354598045349121 - score 0.653\n",
            "2019-06-17 09:17:14,418 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:17:15,825 epoch 31 - iter 0/335 - loss 0.71229684\n",
            "2019-06-17 09:17:38,948 epoch 31 - iter 33/335 - loss 0.30463484\n",
            "2019-06-17 09:18:05,144 epoch 31 - iter 66/335 - loss 0.35801681\n",
            "2019-06-17 09:18:27,442 epoch 31 - iter 99/335 - loss 0.37294793\n",
            "2019-06-17 09:18:47,864 epoch 31 - iter 132/335 - loss 0.37312371\n",
            "2019-06-17 09:19:08,748 epoch 31 - iter 165/335 - loss 0.38621504\n",
            "2019-06-17 09:19:28,988 epoch 31 - iter 198/335 - loss 0.38965615\n",
            "2019-06-17 09:19:49,258 epoch 31 - iter 231/335 - loss 0.40134246\n",
            "2019-06-17 09:20:09,716 epoch 31 - iter 264/335 - loss 0.39975779\n",
            "2019-06-17 09:20:31,566 epoch 31 - iter 297/335 - loss 0.39979561\n",
            "2019-06-17 09:20:54,106 epoch 31 - iter 330/335 - loss 0.40098356\n",
            "2019-06-17 09:20:57,322 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:20:57,324 EPOCH 31 done: loss 0.4023 - lr 0.0250 - bad epochs 1\n",
            "2019-06-17 09:21:23,956 DEV : loss 0.5775703191757202 - score 0.7076\n",
            "2019-06-17 09:23:00,277 TEST : loss 0.7287832498550415 - score 0.6539\n",
            "2019-06-17 09:23:00,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:23:02,409 epoch 32 - iter 0/335 - loss 0.19487366\n",
            "2019-06-17 09:23:27,268 epoch 32 - iter 33/335 - loss 0.42548743\n",
            "2019-06-17 09:23:52,145 epoch 32 - iter 66/335 - loss 0.39827483\n",
            "2019-06-17 09:24:13,654 epoch 32 - iter 99/335 - loss 0.39641241\n",
            "2019-06-17 09:24:33,314 epoch 32 - iter 132/335 - loss 0.40389410\n",
            "2019-06-17 09:24:55,730 epoch 32 - iter 165/335 - loss 0.40716854\n",
            "2019-06-17 09:25:18,094 epoch 32 - iter 198/335 - loss 0.40042226\n",
            "2019-06-17 09:25:39,007 epoch 32 - iter 231/335 - loss 0.39299704\n",
            "2019-06-17 09:26:00,671 epoch 32 - iter 264/335 - loss 0.39368996\n",
            "2019-06-17 09:26:23,539 epoch 32 - iter 297/335 - loss 0.39190448\n",
            "2019-06-17 09:26:43,594 epoch 32 - iter 330/335 - loss 0.39893784\n",
            "2019-06-17 09:26:46,622 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:26:46,624 EPOCH 32 done: loss 0.3999 - lr 0.0250 - bad epochs 2\n",
            "2019-06-17 09:27:14,797 DEV : loss 0.5662628412246704 - score 0.7216\n",
            "2019-06-17 09:28:50,304 TEST : loss 0.7267441749572754 - score 0.6634\n",
            "2019-06-17 09:28:50,306 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:28:51,387 epoch 33 - iter 0/335 - loss 0.43914032\n",
            "2019-06-17 09:29:13,689 epoch 33 - iter 33/335 - loss 0.35238876\n",
            "2019-06-17 09:29:37,054 epoch 33 - iter 66/335 - loss 0.36406847\n",
            "2019-06-17 09:29:59,248 epoch 33 - iter 99/335 - loss 0.38973571\n",
            "2019-06-17 09:30:22,000 epoch 33 - iter 132/335 - loss 0.39538396\n",
            "2019-06-17 09:30:42,265 epoch 33 - iter 165/335 - loss 0.38415739\n",
            "2019-06-17 09:31:03,956 epoch 33 - iter 198/335 - loss 0.38570520\n",
            "2019-06-17 09:31:26,194 epoch 33 - iter 231/335 - loss 0.38134599\n",
            "2019-06-17 09:31:48,336 epoch 33 - iter 264/335 - loss 0.37996719\n",
            "2019-06-17 09:32:09,184 epoch 33 - iter 297/335 - loss 0.38369378\n",
            "2019-06-17 09:32:31,842 epoch 33 - iter 330/335 - loss 0.39331214\n",
            "2019-06-17 09:32:34,287 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:32:34,289 EPOCH 33 done: loss 0.3926 - lr 0.0250 - bad epochs 3\n",
            "2019-06-17 09:33:02,386 DEV : loss 0.5656478404998779 - score 0.7229\n",
            "2019-06-17 09:34:38,560 TEST : loss 0.7370669841766357 - score 0.6621\n",
            "Epoch    32: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-06-17 09:34:38,562 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:34:39,661 epoch 34 - iter 0/335 - loss 0.26987225\n",
            "2019-06-17 09:35:03,633 epoch 34 - iter 33/335 - loss 0.32897056\n",
            "2019-06-17 09:35:27,547 epoch 34 - iter 66/335 - loss 0.37360526\n",
            "2019-06-17 09:35:52,289 epoch 34 - iter 99/335 - loss 0.37909843\n",
            "2019-06-17 09:36:15,157 epoch 34 - iter 132/335 - loss 0.39447318\n",
            "2019-06-17 09:36:37,131 epoch 34 - iter 165/335 - loss 0.38524475\n",
            "2019-06-17 09:36:58,922 epoch 34 - iter 198/335 - loss 0.38129856\n",
            "2019-06-17 09:37:19,951 epoch 34 - iter 231/335 - loss 0.39100067\n",
            "2019-06-17 09:37:40,980 epoch 34 - iter 264/335 - loss 0.38256643\n",
            "2019-06-17 09:38:00,581 epoch 34 - iter 297/335 - loss 0.37640000\n",
            "2019-06-17 09:38:19,429 epoch 34 - iter 330/335 - loss 0.38061216\n",
            "2019-06-17 09:38:22,388 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:38:22,390 EPOCH 34 done: loss 0.3821 - lr 0.0125 - bad epochs 0\n",
            "2019-06-17 09:38:49,152 DEV : loss 0.5656250715255737 - score 0.7276\n",
            "2019-06-17 09:40:25,324 TEST : loss 0.7354714274406433 - score 0.6556\n",
            "2019-06-17 09:40:25,889 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:40:27,218 epoch 35 - iter 0/335 - loss 0.63036287\n",
            "2019-06-17 09:40:48,915 epoch 35 - iter 33/335 - loss 0.42733468\n",
            "2019-06-17 09:41:12,225 epoch 35 - iter 66/335 - loss 0.43031290\n",
            "2019-06-17 09:41:33,833 epoch 35 - iter 99/335 - loss 0.40335906\n",
            "2019-06-17 09:41:56,852 epoch 35 - iter 132/335 - loss 0.39414988\n",
            "2019-06-17 09:42:21,365 epoch 35 - iter 165/335 - loss 0.39617516\n",
            "2019-06-17 09:42:44,185 epoch 35 - iter 198/335 - loss 0.39708151\n",
            "2019-06-17 09:43:05,325 epoch 35 - iter 231/335 - loss 0.38436308\n",
            "2019-06-17 09:43:28,900 epoch 35 - iter 264/335 - loss 0.38722978\n",
            "2019-06-17 09:43:48,931 epoch 35 - iter 297/335 - loss 0.38376107\n",
            "2019-06-17 09:44:06,733 epoch 35 - iter 330/335 - loss 0.37945537\n",
            "2019-06-17 09:44:10,847 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:44:10,848 EPOCH 35 done: loss 0.3788 - lr 0.0125 - bad epochs 0\n",
            "2019-06-17 09:44:38,939 DEV : loss 0.5677247047424316 - score 0.7284\n",
            "2019-06-17 09:46:13,858 TEST : loss 0.7350430488586426 - score 0.6622\n",
            "2019-06-17 09:46:14,325 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:46:16,943 epoch 36 - iter 0/335 - loss 0.24413866\n",
            "2019-06-17 09:46:38,334 epoch 36 - iter 33/335 - loss 0.38992442\n",
            "2019-06-17 09:47:01,722 epoch 36 - iter 66/335 - loss 0.35517845\n",
            "2019-06-17 09:47:23,860 epoch 36 - iter 99/335 - loss 0.38229478\n",
            "2019-06-17 09:47:44,914 epoch 36 - iter 132/335 - loss 0.36428206\n",
            "2019-06-17 09:48:05,109 epoch 36 - iter 165/335 - loss 0.35389868\n",
            "2019-06-17 09:48:25,918 epoch 36 - iter 198/335 - loss 0.34645942\n",
            "2019-06-17 09:48:47,377 epoch 36 - iter 231/335 - loss 0.35572206\n",
            "2019-06-17 09:49:08,546 epoch 36 - iter 264/335 - loss 0.36227220\n",
            "2019-06-17 09:49:31,280 epoch 36 - iter 297/335 - loss 0.37493529\n",
            "2019-06-17 09:49:55,146 epoch 36 - iter 330/335 - loss 0.37452252\n",
            "2019-06-17 09:49:57,288 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:49:57,290 EPOCH 36 done: loss 0.3737 - lr 0.0125 - bad epochs 0\n",
            "2019-06-17 09:50:23,979 DEV : loss 0.5707429647445679 - score 0.7259\n",
            "2019-06-17 09:52:00,385 TEST : loss 0.7378160357475281 - score 0.6587\n",
            "2019-06-17 09:52:00,387 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:52:01,244 epoch 37 - iter 0/335 - loss 0.05402055\n",
            "2019-06-17 09:52:20,965 epoch 37 - iter 33/335 - loss 0.33912988\n",
            "2019-06-17 09:52:44,773 epoch 37 - iter 66/335 - loss 0.36345277\n",
            "2019-06-17 09:53:04,448 epoch 37 - iter 99/335 - loss 0.36031435\n",
            "2019-06-17 09:53:26,843 epoch 37 - iter 132/335 - loss 0.35492673\n",
            "2019-06-17 09:53:49,962 epoch 37 - iter 165/335 - loss 0.36562076\n",
            "2019-06-17 09:54:12,455 epoch 37 - iter 198/335 - loss 0.36729838\n",
            "2019-06-17 09:54:37,399 epoch 37 - iter 231/335 - loss 0.36697113\n",
            "2019-06-17 09:54:58,639 epoch 37 - iter 264/335 - loss 0.37064640\n",
            "2019-06-17 09:55:19,161 epoch 37 - iter 297/335 - loss 0.36734439\n",
            "2019-06-17 09:55:41,923 epoch 37 - iter 330/335 - loss 0.37208362\n",
            "2019-06-17 09:55:44,480 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:55:44,482 EPOCH 37 done: loss 0.3728 - lr 0.0125 - bad epochs 1\n",
            "2019-06-17 09:56:12,579 DEV : loss 0.5735129117965698 - score 0.7328\n",
            "2019-06-17 09:57:48,251 TEST : loss 0.7394683361053467 - score 0.6635\n",
            "2019-06-17 09:57:48,723 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 09:57:50,175 epoch 38 - iter 0/335 - loss 0.20741370\n",
            "2019-06-17 09:58:13,116 epoch 38 - iter 33/335 - loss 0.39483680\n",
            "2019-06-17 09:58:37,617 epoch 38 - iter 66/335 - loss 0.36900863\n",
            "2019-06-17 09:59:00,323 epoch 38 - iter 99/335 - loss 0.36197003\n",
            "2019-06-17 09:59:20,201 epoch 38 - iter 132/335 - loss 0.34998547\n",
            "2019-06-17 09:59:39,830 epoch 38 - iter 165/335 - loss 0.34977076\n",
            "2019-06-17 10:00:00,852 epoch 38 - iter 198/335 - loss 0.35184905\n",
            "2019-06-17 10:00:22,093 epoch 38 - iter 231/335 - loss 0.35750459\n",
            "2019-06-17 10:00:44,273 epoch 38 - iter 264/335 - loss 0.35843459\n",
            "2019-06-17 10:01:04,502 epoch 38 - iter 297/335 - loss 0.36287703\n",
            "2019-06-17 10:01:27,417 epoch 38 - iter 330/335 - loss 0.36683147\n",
            "2019-06-17 10:01:31,655 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:01:31,657 EPOCH 38 done: loss 0.3660 - lr 0.0125 - bad epochs 0\n",
            "2019-06-17 10:01:58,309 DEV : loss 0.5694374442100525 - score 0.7257\n",
            "2019-06-17 10:03:34,575 TEST : loss 0.744394063949585 - score 0.6583\n",
            "2019-06-17 10:03:34,577 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:03:35,849 epoch 39 - iter 0/335 - loss 0.34129578\n",
            "2019-06-17 10:03:59,400 epoch 39 - iter 33/335 - loss 0.37217088\n",
            "2019-06-17 10:04:23,065 epoch 39 - iter 66/335 - loss 0.37455385\n",
            "2019-06-17 10:04:44,995 epoch 39 - iter 99/335 - loss 0.36971597\n",
            "2019-06-17 10:05:07,624 epoch 39 - iter 132/335 - loss 0.37374088\n",
            "2019-06-17 10:05:28,495 epoch 39 - iter 165/335 - loss 0.35620965\n",
            "2019-06-17 10:05:50,587 epoch 39 - iter 198/335 - loss 0.36137633\n",
            "2019-06-17 10:06:11,840 epoch 39 - iter 231/335 - loss 0.36378188\n",
            "2019-06-17 10:06:35,162 epoch 39 - iter 264/335 - loss 0.36452168\n",
            "2019-06-17 10:06:53,893 epoch 39 - iter 297/335 - loss 0.36604988\n",
            "2019-06-17 10:07:13,999 epoch 39 - iter 330/335 - loss 0.37407120\n",
            "2019-06-17 10:07:17,012 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:07:17,013 EPOCH 39 done: loss 0.3721 - lr 0.0125 - bad epochs 1\n",
            "2019-06-17 10:07:45,120 DEV : loss 0.5683445334434509 - score 0.7168\n",
            "2019-06-17 10:09:20,310 TEST : loss 0.7381222248077393 - score 0.6585\n",
            "2019-06-17 10:09:20,311 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:09:21,610 epoch 40 - iter 0/335 - loss 0.09068286\n",
            "2019-06-17 10:09:44,108 epoch 40 - iter 33/335 - loss 0.32918660\n",
            "2019-06-17 10:10:05,561 epoch 40 - iter 66/335 - loss 0.34141750\n",
            "2019-06-17 10:10:25,510 epoch 40 - iter 99/335 - loss 0.34345307\n",
            "2019-06-17 10:10:45,783 epoch 40 - iter 132/335 - loss 0.35589569\n",
            "2019-06-17 10:11:10,415 epoch 40 - iter 165/335 - loss 0.36241354\n",
            "2019-06-17 10:11:33,771 epoch 40 - iter 198/335 - loss 0.36035142\n",
            "2019-06-17 10:11:58,023 epoch 40 - iter 231/335 - loss 0.36800430\n",
            "2019-06-17 10:12:18,474 epoch 40 - iter 264/335 - loss 0.36791048\n",
            "2019-06-17 10:12:41,035 epoch 40 - iter 297/335 - loss 0.37374617\n",
            "2019-06-17 10:12:59,733 epoch 40 - iter 330/335 - loss 0.37070923\n",
            "2019-06-17 10:13:03,256 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:13:03,258 EPOCH 40 done: loss 0.3707 - lr 0.0125 - bad epochs 2\n",
            "2019-06-17 10:13:29,863 DEV : loss 0.5672335624694824 - score 0.7262\n",
            "2019-06-17 10:15:05,858 TEST : loss 0.7389358878135681 - score 0.6573\n",
            "2019-06-17 10:15:05,859 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:15:07,103 epoch 41 - iter 0/335 - loss 0.12173632\n",
            "2019-06-17 10:15:29,237 epoch 41 - iter 33/335 - loss 0.36123386\n",
            "2019-06-17 10:15:50,918 epoch 41 - iter 66/335 - loss 0.37131584\n",
            "2019-06-17 10:16:14,288 epoch 41 - iter 99/335 - loss 0.37429924\n",
            "2019-06-17 10:16:34,030 epoch 41 - iter 132/335 - loss 0.39107295\n",
            "2019-06-17 10:16:55,517 epoch 41 - iter 165/335 - loss 0.37040443\n",
            "2019-06-17 10:17:16,870 epoch 41 - iter 198/335 - loss 0.36698512\n",
            "2019-06-17 10:17:40,201 epoch 41 - iter 231/335 - loss 0.36303853\n",
            "2019-06-17 10:18:01,552 epoch 41 - iter 264/335 - loss 0.36183848\n",
            "2019-06-17 10:18:22,056 epoch 41 - iter 297/335 - loss 0.36675845\n",
            "2019-06-17 10:18:47,356 epoch 41 - iter 330/335 - loss 0.37045643\n",
            "2019-06-17 10:18:49,749 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:18:49,752 EPOCH 41 done: loss 0.3693 - lr 0.0125 - bad epochs 3\n",
            "2019-06-17 10:19:16,376 DEV : loss 0.568069338798523 - score 0.7279\n",
            "2019-06-17 10:20:52,956 TEST : loss 0.7453429102897644 - score 0.6576\n",
            "Epoch    40: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-06-17 10:20:52,957 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:20:54,532 epoch 42 - iter 0/335 - loss 0.32158160\n",
            "2019-06-17 10:21:16,689 epoch 42 - iter 33/335 - loss 0.24810840\n",
            "2019-06-17 10:21:37,019 epoch 42 - iter 66/335 - loss 0.29184429\n",
            "2019-06-17 10:21:58,055 epoch 42 - iter 99/335 - loss 0.31720615\n",
            "2019-06-17 10:22:17,355 epoch 42 - iter 132/335 - loss 0.31698119\n",
            "2019-06-17 10:22:40,087 epoch 42 - iter 165/335 - loss 0.31540957\n",
            "2019-06-17 10:23:03,582 epoch 42 - iter 198/335 - loss 0.34142745\n",
            "2019-06-17 10:23:24,757 epoch 42 - iter 231/335 - loss 0.35061790\n",
            "2019-06-17 10:23:46,118 epoch 42 - iter 264/335 - loss 0.34756693\n",
            "2019-06-17 10:24:07,544 epoch 42 - iter 297/335 - loss 0.34876932\n",
            "2019-06-17 10:24:33,257 epoch 42 - iter 330/335 - loss 0.35500561\n",
            "2019-06-17 10:24:36,771 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:24:36,773 EPOCH 42 done: loss 0.3564 - lr 0.0063 - bad epochs 0\n",
            "2019-06-17 10:25:05,044 DEV : loss 0.5653982758522034 - score 0.7238\n",
            "2019-06-17 10:26:41,763 TEST : loss 0.7360407710075378 - score 0.6637\n",
            "2019-06-17 10:26:41,764 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:26:43,055 epoch 43 - iter 0/335 - loss 0.28765747\n",
            "2019-06-17 10:27:03,616 epoch 43 - iter 33/335 - loss 0.33418301\n",
            "2019-06-17 10:27:25,340 epoch 43 - iter 66/335 - loss 0.34567544\n",
            "2019-06-17 10:27:47,667 epoch 43 - iter 99/335 - loss 0.33734267\n",
            "2019-06-17 10:28:10,443 epoch 43 - iter 132/335 - loss 0.33751931\n",
            "2019-06-17 10:28:29,175 epoch 43 - iter 165/335 - loss 0.33758703\n",
            "2019-06-17 10:28:50,341 epoch 43 - iter 198/335 - loss 0.34390062\n",
            "2019-06-17 10:29:14,564 epoch 43 - iter 231/335 - loss 0.35828927\n",
            "2019-06-17 10:29:36,898 epoch 43 - iter 264/335 - loss 0.35715622\n",
            "2019-06-17 10:29:58,934 epoch 43 - iter 297/335 - loss 0.35611236\n",
            "2019-06-17 10:30:20,985 epoch 43 - iter 330/335 - loss 0.35387667\n",
            "2019-06-17 10:30:24,067 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:30:24,069 EPOCH 43 done: loss 0.3542 - lr 0.0063 - bad epochs 1\n",
            "2019-06-17 10:30:50,884 DEV : loss 0.5660746693611145 - score 0.7157\n",
            "2019-06-17 10:32:27,789 TEST : loss 0.73614901304245 - score 0.6555\n",
            "2019-06-17 10:32:27,790 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:32:28,799 epoch 44 - iter 0/335 - loss 0.92360646\n",
            "2019-06-17 10:32:51,415 epoch 44 - iter 33/335 - loss 0.32078407\n",
            "2019-06-17 10:33:15,308 epoch 44 - iter 66/335 - loss 0.36353578\n",
            "2019-06-17 10:33:38,324 epoch 44 - iter 99/335 - loss 0.36040875\n",
            "2019-06-17 10:33:57,134 epoch 44 - iter 132/335 - loss 0.34950662\n",
            "2019-06-17 10:34:18,924 epoch 44 - iter 165/335 - loss 0.35779672\n",
            "2019-06-17 10:34:39,117 epoch 44 - iter 198/335 - loss 0.36144324\n",
            "2019-06-17 10:35:02,785 epoch 44 - iter 231/335 - loss 0.36039803\n",
            "2019-06-17 10:35:23,643 epoch 44 - iter 264/335 - loss 0.35757732\n",
            "2019-06-17 10:35:47,188 epoch 44 - iter 297/335 - loss 0.35468887\n",
            "2019-06-17 10:36:10,470 epoch 44 - iter 330/335 - loss 0.35567025\n",
            "2019-06-17 10:36:13,137 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:36:13,139 EPOCH 44 done: loss 0.3552 - lr 0.0063 - bad epochs 2\n",
            "2019-06-17 10:36:41,217 DEV : loss 0.5683419108390808 - score 0.7265\n",
            "2019-06-17 10:38:16,782 TEST : loss 0.7450754046440125 - score 0.66\n",
            "2019-06-17 10:38:16,783 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:38:19,381 epoch 45 - iter 0/335 - loss 0.12610269\n",
            "2019-06-17 10:38:42,464 epoch 45 - iter 33/335 - loss 0.34923984\n",
            "2019-06-17 10:39:03,724 epoch 45 - iter 66/335 - loss 0.35784838\n",
            "2019-06-17 10:39:27,355 epoch 45 - iter 99/335 - loss 0.36202275\n",
            "2019-06-17 10:39:48,580 epoch 45 - iter 132/335 - loss 0.35837586\n",
            "2019-06-17 10:40:12,223 epoch 45 - iter 165/335 - loss 0.35754234\n",
            "2019-06-17 10:40:33,916 epoch 45 - iter 198/335 - loss 0.35608546\n",
            "2019-06-17 10:40:56,140 epoch 45 - iter 231/335 - loss 0.35048682\n",
            "2019-06-17 10:41:16,116 epoch 45 - iter 264/335 - loss 0.35425248\n",
            "2019-06-17 10:41:36,477 epoch 45 - iter 297/335 - loss 0.34697608\n",
            "2019-06-17 10:41:58,668 epoch 45 - iter 330/335 - loss 0.34854058\n",
            "2019-06-17 10:42:01,458 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:42:01,460 EPOCH 45 done: loss 0.3480 - lr 0.0063 - bad epochs 3\n",
            "2019-06-17 10:42:28,288 DEV : loss 0.5697010159492493 - score 0.7277\n",
            "2019-06-17 10:44:05,139 TEST : loss 0.743369460105896 - score 0.6561\n",
            "Epoch    44: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-06-17 10:44:05,140 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:44:06,179 epoch 46 - iter 0/335 - loss 0.59921408\n",
            "2019-06-17 10:44:29,001 epoch 46 - iter 33/335 - loss 0.42649213\n",
            "2019-06-17 10:44:51,476 epoch 46 - iter 66/335 - loss 0.42365141\n",
            "2019-06-17 10:45:13,534 epoch 46 - iter 99/335 - loss 0.38837427\n",
            "2019-06-17 10:45:36,799 epoch 46 - iter 132/335 - loss 0.39257373\n",
            "2019-06-17 10:46:01,633 epoch 46 - iter 165/335 - loss 0.39142946\n",
            "2019-06-17 10:46:22,163 epoch 46 - iter 198/335 - loss 0.37253772\n",
            "2019-06-17 10:46:44,008 epoch 46 - iter 231/335 - loss 0.36750087\n",
            "2019-06-17 10:47:03,969 epoch 46 - iter 264/335 - loss 0.36841951\n",
            "2019-06-17 10:47:24,588 epoch 46 - iter 297/335 - loss 0.36497257\n",
            "2019-06-17 10:47:46,614 epoch 46 - iter 330/335 - loss 0.36104823\n",
            "2019-06-17 10:47:49,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:47:49,813 EPOCH 46 done: loss 0.3600 - lr 0.0031 - bad epochs 0\n",
            "2019-06-17 10:48:16,452 DEV : loss 0.5716579556465149 - score 0.7198\n",
            "2019-06-17 10:49:54,009 TEST : loss 0.7411671280860901 - score 0.6603\n",
            "2019-06-17 10:49:54,010 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:49:55,403 epoch 47 - iter 0/335 - loss 0.75082672\n",
            "2019-06-17 10:50:23,414 epoch 47 - iter 33/335 - loss 0.37914968\n",
            "2019-06-17 10:50:44,363 epoch 47 - iter 66/335 - loss 0.35507620\n",
            "2019-06-17 10:51:03,471 epoch 47 - iter 99/335 - loss 0.35314986\n",
            "2019-06-17 10:51:24,733 epoch 47 - iter 132/335 - loss 0.34000066\n",
            "2019-06-17 10:51:46,721 epoch 47 - iter 165/335 - loss 0.34314799\n",
            "2019-06-17 10:52:11,510 epoch 47 - iter 198/335 - loss 0.35215032\n",
            "2019-06-17 10:52:32,629 epoch 47 - iter 231/335 - loss 0.35807568\n",
            "2019-06-17 10:52:53,594 epoch 47 - iter 264/335 - loss 0.35504290\n",
            "2019-06-17 10:53:14,773 epoch 47 - iter 297/335 - loss 0.35311975\n",
            "2019-06-17 10:53:35,771 epoch 47 - iter 330/335 - loss 0.35491374\n",
            "2019-06-17 10:53:38,160 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:53:38,161 EPOCH 47 done: loss 0.3543 - lr 0.0031 - bad epochs 1\n",
            "2019-06-17 10:54:06,611 DEV : loss 0.5694164633750916 - score 0.729\n",
            "2019-06-17 10:55:43,666 TEST : loss 0.7442218661308289 - score 0.6586\n",
            "2019-06-17 10:55:43,668 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:55:44,859 epoch 48 - iter 0/335 - loss 0.05888402\n",
            "2019-06-17 10:56:08,950 epoch 48 - iter 33/335 - loss 0.34972651\n",
            "2019-06-17 10:56:32,495 epoch 48 - iter 66/335 - loss 0.34631853\n",
            "2019-06-17 10:56:55,619 epoch 48 - iter 99/335 - loss 0.35413808\n",
            "2019-06-17 10:57:16,769 epoch 48 - iter 132/335 - loss 0.35049559\n",
            "2019-06-17 10:57:37,400 epoch 48 - iter 165/335 - loss 0.34359730\n",
            "2019-06-17 10:57:58,476 epoch 48 - iter 198/335 - loss 0.34440279\n",
            "2019-06-17 10:58:19,797 epoch 48 - iter 231/335 - loss 0.35287665\n",
            "2019-06-17 10:58:40,785 epoch 48 - iter 264/335 - loss 0.34798814\n",
            "2019-06-17 10:59:04,532 epoch 48 - iter 297/335 - loss 0.35568614\n",
            "2019-06-17 10:59:26,031 epoch 48 - iter 330/335 - loss 0.35739978\n",
            "2019-06-17 10:59:28,297 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:59:28,299 EPOCH 48 done: loss 0.3568 - lr 0.0031 - bad epochs 2\n",
            "2019-06-17 10:59:55,036 DEV : loss 0.5699166059494019 - score 0.7264\n",
            "2019-06-17 11:01:31,434 TEST : loss 0.7438108921051025 - score 0.6602\n",
            "2019-06-17 11:01:31,436 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:01:32,349 epoch 49 - iter 0/335 - loss 0.19687939\n",
            "2019-06-17 11:01:52,331 epoch 49 - iter 33/335 - loss 0.32664717\n",
            "2019-06-17 11:02:15,854 epoch 49 - iter 66/335 - loss 0.32179862\n",
            "2019-06-17 11:02:38,231 epoch 49 - iter 99/335 - loss 0.33237672\n",
            "2019-06-17 11:03:01,900 epoch 49 - iter 132/335 - loss 0.34367053\n",
            "2019-06-17 11:03:24,298 epoch 49 - iter 165/335 - loss 0.35272735\n",
            "2019-06-17 11:03:45,572 epoch 49 - iter 198/335 - loss 0.35406287\n",
            "2019-06-17 11:04:07,319 epoch 49 - iter 231/335 - loss 0.34377741\n",
            "2019-06-17 11:04:29,805 epoch 49 - iter 264/335 - loss 0.34766660\n",
            "2019-06-17 11:04:50,913 epoch 49 - iter 297/335 - loss 0.34844188\n",
            "2019-06-17 11:05:12,447 epoch 49 - iter 330/335 - loss 0.34846108\n",
            "2019-06-17 11:05:14,938 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:05:14,940 EPOCH 49 done: loss 0.3501 - lr 0.0031 - bad epochs 3\n",
            "2019-06-17 11:05:43,124 DEV : loss 0.5715460777282715 - score 0.7256\n",
            "2019-06-17 11:07:18,599 TEST : loss 0.7463015913963318 - score 0.6583\n",
            "Epoch    48: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-06-17 11:07:18,601 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:07:21,400 epoch 50 - iter 0/335 - loss 0.78683501\n",
            "2019-06-17 11:07:43,461 epoch 50 - iter 33/335 - loss 0.41296484\n",
            "2019-06-17 11:08:02,390 epoch 50 - iter 66/335 - loss 0.40425299\n",
            "2019-06-17 11:08:26,173 epoch 50 - iter 99/335 - loss 0.38489270\n",
            "2019-06-17 11:08:49,203 epoch 50 - iter 132/335 - loss 0.36729173\n",
            "2019-06-17 11:09:12,956 epoch 50 - iter 165/335 - loss 0.36270776\n",
            "2019-06-17 11:09:33,562 epoch 50 - iter 198/335 - loss 0.36359428\n",
            "2019-06-17 11:09:57,939 epoch 50 - iter 231/335 - loss 0.36799581\n",
            "2019-06-17 11:10:19,173 epoch 50 - iter 264/335 - loss 0.36372826\n",
            "2019-06-17 11:10:40,971 epoch 50 - iter 297/335 - loss 0.35718685\n",
            "2019-06-17 11:11:00,383 epoch 50 - iter 330/335 - loss 0.35941965\n",
            "2019-06-17 11:11:02,871 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:11:02,873 EPOCH 50 done: loss 0.3573 - lr 0.0016 - bad epochs 0\n",
            "2019-06-17 11:11:29,613 DEV : loss 0.5709204077720642 - score 0.7247\n",
            "2019-06-17 11:13:06,333 TEST : loss 0.7461434006690979 - score 0.6575\n",
            "2019-06-17 11:13:06,335 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:13:07,546 epoch 51 - iter 0/335 - loss 0.44371489\n",
            "2019-06-17 11:13:29,453 epoch 51 - iter 33/335 - loss 0.42376955\n",
            "2019-06-17 11:13:51,657 epoch 51 - iter 66/335 - loss 0.39795231\n",
            "2019-06-17 11:14:14,796 epoch 51 - iter 99/335 - loss 0.39907257\n",
            "2019-06-17 11:14:38,216 epoch 51 - iter 132/335 - loss 0.37879927\n",
            "2019-06-17 11:14:58,346 epoch 51 - iter 165/335 - loss 0.37382543\n",
            "2019-06-17 11:15:20,195 epoch 51 - iter 198/335 - loss 0.37175470\n",
            "2019-06-17 11:15:41,379 epoch 51 - iter 231/335 - loss 0.36587839\n",
            "2019-06-17 11:16:02,054 epoch 51 - iter 264/335 - loss 0.35725525\n",
            "2019-06-17 11:16:20,911 epoch 51 - iter 297/335 - loss 0.34628671\n",
            "2019-06-17 11:16:45,178 epoch 51 - iter 330/335 - loss 0.35480648\n",
            "2019-06-17 11:16:48,052 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:16:48,054 EPOCH 51 done: loss 0.3548 - lr 0.0016 - bad epochs 1\n",
            "2019-06-17 11:17:16,090 DEV : loss 0.5701490640640259 - score 0.7247\n",
            "2019-06-17 11:18:51,310 TEST : loss 0.743357241153717 - score 0.6586\n",
            "2019-06-17 11:18:51,312 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:18:54,227 epoch 52 - iter 0/335 - loss 0.42311034\n",
            "2019-06-17 11:19:15,976 epoch 52 - iter 33/335 - loss 0.35885938\n",
            "2019-06-17 11:19:35,577 epoch 52 - iter 66/335 - loss 0.33587896\n",
            "2019-06-17 11:19:57,644 epoch 52 - iter 99/335 - loss 0.34537358\n",
            "2019-06-17 11:20:19,385 epoch 52 - iter 132/335 - loss 0.34460124\n",
            "2019-06-17 11:20:41,530 epoch 52 - iter 165/335 - loss 0.34920755\n",
            "2019-06-17 11:21:02,333 epoch 52 - iter 198/335 - loss 0.34868633\n",
            "2019-06-17 11:21:25,289 epoch 52 - iter 231/335 - loss 0.35348507\n",
            "2019-06-17 11:21:48,178 epoch 52 - iter 264/335 - loss 0.35040193\n",
            "2019-06-17 11:22:07,829 epoch 52 - iter 297/335 - loss 0.34420219\n",
            "2019-06-17 11:22:31,542 epoch 52 - iter 330/335 - loss 0.34591113\n",
            "2019-06-17 11:22:33,867 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:22:33,868 EPOCH 52 done: loss 0.3438 - lr 0.0016 - bad epochs 2\n",
            "2019-06-17 11:23:00,594 DEV : loss 0.568942129611969 - score 0.7284\n",
            "2019-06-17 11:24:36,894 TEST : loss 0.7460443377494812 - score 0.659\n",
            "2019-06-17 11:24:36,896 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:24:38,176 epoch 53 - iter 0/335 - loss 0.58617312\n",
            "2019-06-17 11:25:00,126 epoch 53 - iter 33/335 - loss 0.36375349\n",
            "2019-06-17 11:25:23,405 epoch 53 - iter 66/335 - loss 0.35988999\n",
            "2019-06-17 11:25:43,918 epoch 53 - iter 99/335 - loss 0.35907132\n",
            "2019-06-17 11:26:04,033 epoch 53 - iter 132/335 - loss 0.34076441\n",
            "2019-06-17 11:26:24,311 epoch 53 - iter 165/335 - loss 0.33799665\n",
            "2019-06-17 11:26:48,261 epoch 53 - iter 198/335 - loss 0.32451711\n",
            "2019-06-17 11:27:09,554 epoch 53 - iter 231/335 - loss 0.33175141\n",
            "2019-06-17 11:27:31,995 epoch 53 - iter 264/335 - loss 0.33447061\n",
            "2019-06-17 11:27:57,579 epoch 53 - iter 297/335 - loss 0.33869952\n",
            "2019-06-17 11:28:16,623 epoch 53 - iter 330/335 - loss 0.34189440\n",
            "2019-06-17 11:28:19,426 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:28:19,428 EPOCH 53 done: loss 0.3420 - lr 0.0016 - bad epochs 3\n",
            "2019-06-17 11:28:47,353 DEV : loss 0.5700103044509888 - score 0.7264\n",
            "2019-06-17 11:30:22,651 TEST : loss 0.7477179765701294 - score 0.6584\n",
            "Epoch    52: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-06-17 11:30:22,653 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:30:23,953 epoch 54 - iter 0/335 - loss 0.61736804\n",
            "2019-06-17 11:30:48,104 epoch 54 - iter 33/335 - loss 0.29814433\n",
            "2019-06-17 11:31:10,760 epoch 54 - iter 66/335 - loss 0.32043627\n",
            "2019-06-17 11:31:32,450 epoch 54 - iter 99/335 - loss 0.34515800\n",
            "2019-06-17 11:31:55,972 epoch 54 - iter 132/335 - loss 0.35522306\n",
            "2019-06-17 11:32:19,118 epoch 54 - iter 165/335 - loss 0.34519139\n",
            "2019-06-17 11:32:39,321 epoch 54 - iter 198/335 - loss 0.35354914\n",
            "2019-06-17 11:33:00,016 epoch 54 - iter 231/335 - loss 0.36067222\n",
            "2019-06-17 11:33:20,722 epoch 54 - iter 264/335 - loss 0.36808484\n",
            "2019-06-17 11:33:42,590 epoch 54 - iter 297/335 - loss 0.36234905\n",
            "2019-06-17 11:34:04,314 epoch 54 - iter 330/335 - loss 0.35306343\n",
            "2019-06-17 11:34:08,326 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:34:08,327 EPOCH 54 done: loss 0.3549 - lr 0.0008 - bad epochs 0\n",
            "2019-06-17 11:34:35,175 DEV : loss 0.5701141953468323 - score 0.7261\n",
            "2019-06-17 11:36:11,805 TEST : loss 0.748041570186615 - score 0.6585\n",
            "2019-06-17 11:36:11,807 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:36:13,466 epoch 55 - iter 0/335 - loss 0.45620480\n",
            "2019-06-17 11:36:35,473 epoch 55 - iter 33/335 - loss 0.34821206\n",
            "2019-06-17 11:36:56,533 epoch 55 - iter 66/335 - loss 0.35236102\n",
            "2019-06-17 11:37:18,099 epoch 55 - iter 99/335 - loss 0.35800321\n",
            "2019-06-17 11:37:39,753 epoch 55 - iter 132/335 - loss 0.33615993\n",
            "2019-06-17 11:38:01,429 epoch 55 - iter 165/335 - loss 0.34213638\n",
            "2019-06-17 11:38:23,634 epoch 55 - iter 198/335 - loss 0.34700223\n",
            "2019-06-17 11:38:42,361 epoch 55 - iter 231/335 - loss 0.34256919\n",
            "2019-06-17 11:39:03,967 epoch 55 - iter 264/335 - loss 0.34393394\n",
            "2019-06-17 11:39:27,556 epoch 55 - iter 297/335 - loss 0.35385324\n",
            "2019-06-17 11:39:47,309 epoch 55 - iter 330/335 - loss 0.34779747\n",
            "2019-06-17 11:39:52,043 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:39:52,046 EPOCH 55 done: loss 0.3497 - lr 0.0008 - bad epochs 1\n",
            "2019-06-17 11:40:18,930 DEV : loss 0.569986879825592 - score 0.7268\n",
            "2019-06-17 11:41:56,388 TEST : loss 0.7470417022705078 - score 0.6588\n",
            "2019-06-17 11:41:56,399 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:41:57,508 epoch 56 - iter 0/335 - loss 0.73971999\n",
            "2019-06-17 11:42:24,289 epoch 56 - iter 33/335 - loss 0.40947850\n",
            "2019-06-17 11:42:44,029 epoch 56 - iter 66/335 - loss 0.39097821\n",
            "2019-06-17 11:43:05,713 epoch 56 - iter 99/335 - loss 0.37382805\n",
            "2019-06-17 11:43:25,818 epoch 56 - iter 132/335 - loss 0.36440073\n",
            "2019-06-17 11:43:49,809 epoch 56 - iter 165/335 - loss 0.36299985\n",
            "2019-06-17 11:44:10,030 epoch 56 - iter 198/335 - loss 0.36029210\n",
            "2019-06-17 11:44:30,775 epoch 56 - iter 231/335 - loss 0.35936637\n",
            "2019-06-17 11:44:53,876 epoch 56 - iter 264/335 - loss 0.35341033\n",
            "2019-06-17 11:45:15,884 epoch 56 - iter 297/335 - loss 0.35436229\n",
            "2019-06-17 11:45:40,378 epoch 56 - iter 330/335 - loss 0.35706255\n",
            "2019-06-17 11:45:43,291 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:45:43,293 EPOCH 56 done: loss 0.3605 - lr 0.0008 - bad epochs 2\n",
            "2019-06-17 11:46:11,774 DEV : loss 0.569654107093811 - score 0.7292\n",
            "2019-06-17 11:47:48,640 TEST : loss 0.7470089793205261 - score 0.6588\n",
            "2019-06-17 11:47:48,641 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:47:49,577 epoch 57 - iter 0/335 - loss 0.42462444\n",
            "2019-06-17 11:48:14,301 epoch 57 - iter 33/335 - loss 0.32116344\n",
            "2019-06-17 11:48:35,408 epoch 57 - iter 66/335 - loss 0.33654856\n",
            "2019-06-17 11:49:00,087 epoch 57 - iter 99/335 - loss 0.34151752\n",
            "2019-06-17 11:49:23,681 epoch 57 - iter 132/335 - loss 0.35256091\n",
            "2019-06-17 11:49:44,496 epoch 57 - iter 165/335 - loss 0.35024188\n",
            "2019-06-17 11:50:07,259 epoch 57 - iter 198/335 - loss 0.33682032\n",
            "2019-06-17 11:50:27,779 epoch 57 - iter 231/335 - loss 0.33352787\n",
            "2019-06-17 11:50:47,486 epoch 57 - iter 264/335 - loss 0.33753222\n",
            "2019-06-17 11:51:09,636 epoch 57 - iter 297/335 - loss 0.33971775\n",
            "2019-06-17 11:51:29,721 epoch 57 - iter 330/335 - loss 0.34082215\n",
            "2019-06-17 11:51:31,572 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:51:31,573 EPOCH 57 done: loss 0.3407 - lr 0.0008 - bad epochs 3\n",
            "2019-06-17 11:51:58,164 DEV : loss 0.5693901777267456 - score 0.7268\n",
            "2019-06-17 11:53:34,356 TEST : loss 0.7459737658500671 - score 0.6596\n",
            "Epoch    56: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-06-17 11:53:34,358 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:53:35,348 epoch 58 - iter 0/335 - loss 0.25823429\n",
            "2019-06-17 11:53:56,959 epoch 58 - iter 33/335 - loss 0.36013505\n",
            "2019-06-17 11:54:19,276 epoch 58 - iter 66/335 - loss 0.36445062\n",
            "2019-06-17 11:54:39,620 epoch 58 - iter 99/335 - loss 0.34765261\n",
            "2019-06-17 11:54:59,433 epoch 58 - iter 132/335 - loss 0.35727782\n",
            "2019-06-17 11:55:23,732 epoch 58 - iter 165/335 - loss 0.36968964\n",
            "2019-06-17 11:55:49,289 epoch 58 - iter 198/335 - loss 0.36650223\n",
            "2019-06-17 11:56:10,446 epoch 58 - iter 231/335 - loss 0.36155808\n",
            "2019-06-17 11:56:34,688 epoch 58 - iter 264/335 - loss 0.35743294\n",
            "2019-06-17 11:56:57,615 epoch 58 - iter 297/335 - loss 0.35853165\n",
            "2019-06-17 11:57:17,188 epoch 58 - iter 330/335 - loss 0.35267224\n",
            "2019-06-17 11:57:18,987 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:57:18,988 EPOCH 58 done: loss 0.3518 - lr 0.0004 - bad epochs 0\n",
            "2019-06-17 11:57:47,206 DEV : loss 0.5697694420814514 - score 0.7268\n",
            "2019-06-17 11:59:22,563 TEST : loss 0.7465707659721375 - score 0.6586\n",
            "2019-06-17 11:59:22,565 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:59:23,440 epoch 59 - iter 0/335 - loss 0.05118349\n",
            "2019-06-17 11:59:45,486 epoch 59 - iter 33/335 - loss 0.41092778\n",
            "2019-06-17 12:00:08,097 epoch 59 - iter 66/335 - loss 0.36279088\n",
            "2019-06-17 12:00:27,581 epoch 59 - iter 99/335 - loss 0.35194645\n",
            "2019-06-17 12:00:50,411 epoch 59 - iter 132/335 - loss 0.34514773\n",
            "2019-06-17 12:01:10,314 epoch 59 - iter 165/335 - loss 0.34693973\n",
            "2019-06-17 12:01:33,907 epoch 59 - iter 198/335 - loss 0.35093526\n",
            "2019-06-17 12:01:55,570 epoch 59 - iter 231/335 - loss 0.34516488\n",
            "2019-06-17 12:02:21,686 epoch 59 - iter 264/335 - loss 0.35095747\n",
            "2019-06-17 12:02:40,828 epoch 59 - iter 297/335 - loss 0.34749902\n",
            "2019-06-17 12:03:01,420 epoch 59 - iter 330/335 - loss 0.35129599\n",
            "2019-06-17 12:03:04,475 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:03:04,476 EPOCH 59 done: loss 0.3523 - lr 0.0004 - bad epochs 1\n",
            "2019-06-17 12:03:31,099 DEV : loss 0.5693828463554382 - score 0.7268\n",
            "2019-06-17 12:05:07,498 TEST : loss 0.7466787695884705 - score 0.6581\n",
            "2019-06-17 12:05:07,499 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:05:08,747 epoch 60 - iter 0/335 - loss 0.21742296\n",
            "2019-06-17 12:05:33,128 epoch 60 - iter 33/335 - loss 0.28601318\n",
            "2019-06-17 12:05:59,961 epoch 60 - iter 66/335 - loss 0.34465702\n",
            "2019-06-17 12:06:20,438 epoch 60 - iter 99/335 - loss 0.34084320\n",
            "2019-06-17 12:06:39,706 epoch 60 - iter 132/335 - loss 0.35556071\n",
            "2019-06-17 12:07:00,155 epoch 60 - iter 165/335 - loss 0.35599402\n",
            "2019-06-17 12:07:21,173 epoch 60 - iter 198/335 - loss 0.35029810\n",
            "2019-06-17 12:07:43,556 epoch 60 - iter 231/335 - loss 0.36300427\n",
            "2019-06-17 12:08:05,177 epoch 60 - iter 264/335 - loss 0.35888375\n",
            "2019-06-17 12:08:26,916 epoch 60 - iter 297/335 - loss 0.35861060\n",
            "2019-06-17 12:08:47,211 epoch 60 - iter 330/335 - loss 0.35932259\n",
            "2019-06-17 12:08:50,902 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:08:50,904 EPOCH 60 done: loss 0.3585 - lr 0.0004 - bad epochs 2\n",
            "2019-06-17 12:09:18,860 DEV : loss 0.5691960453987122 - score 0.7268\n",
            "2019-06-17 12:10:54,149 TEST : loss 0.746526300907135 - score 0.6589\n",
            "2019-06-17 12:10:54,150 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:10:55,771 epoch 61 - iter 0/335 - loss 0.26041731\n",
            "2019-06-17 12:11:17,974 epoch 61 - iter 33/335 - loss 0.34155381\n",
            "2019-06-17 12:11:38,976 epoch 61 - iter 66/335 - loss 0.33056832\n",
            "2019-06-17 12:12:03,022 epoch 61 - iter 99/335 - loss 0.32651584\n",
            "2019-06-17 12:12:26,875 epoch 61 - iter 132/335 - loss 0.32501945\n",
            "2019-06-17 12:12:48,566 epoch 61 - iter 165/335 - loss 0.32155864\n",
            "2019-06-17 12:13:08,739 epoch 61 - iter 198/335 - loss 0.33009405\n",
            "2019-06-17 12:13:30,459 epoch 61 - iter 231/335 - loss 0.33570090\n",
            "2019-06-17 12:13:49,071 epoch 61 - iter 264/335 - loss 0.33265398\n",
            "2019-06-17 12:14:10,440 epoch 61 - iter 297/335 - loss 0.33969965\n",
            "2019-06-17 12:14:35,875 epoch 61 - iter 330/335 - loss 0.34136055\n",
            "2019-06-17 12:14:38,510 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:14:38,513 EPOCH 61 done: loss 0.3412 - lr 0.0004 - bad epochs 3\n",
            "2019-06-17 12:15:05,153 DEV : loss 0.5693322420120239 - score 0.7268\n",
            "2019-06-17 12:16:41,558 TEST : loss 0.746895432472229 - score 0.6594\n",
            "Epoch    60: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2019-06-17 12:16:41,565 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:16:42,630 epoch 62 - iter 0/335 - loss 0.10498728\n",
            "2019-06-17 12:17:05,068 epoch 62 - iter 33/335 - loss 0.29507800\n",
            "2019-06-17 12:17:28,836 epoch 62 - iter 66/335 - loss 0.31342820\n",
            "2019-06-17 12:17:49,918 epoch 62 - iter 99/335 - loss 0.33293617\n",
            "2019-06-17 12:18:12,722 epoch 62 - iter 132/335 - loss 0.33511592\n",
            "2019-06-17 12:18:35,372 epoch 62 - iter 165/335 - loss 0.33759736\n",
            "2019-06-17 12:18:58,596 epoch 62 - iter 198/335 - loss 0.33070027\n",
            "2019-06-17 12:19:17,481 epoch 62 - iter 231/335 - loss 0.33793666\n",
            "2019-06-17 12:19:38,707 epoch 62 - iter 264/335 - loss 0.33475457\n",
            "2019-06-17 12:19:59,497 epoch 62 - iter 297/335 - loss 0.34231430\n",
            "2019-06-17 12:20:22,958 epoch 62 - iter 330/335 - loss 0.35483187\n",
            "2019-06-17 12:20:25,743 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:20:25,745 EPOCH 62 done: loss 0.3544 - lr 0.0002 - bad epochs 0\n",
            "2019-06-17 12:20:53,892 DEV : loss 0.5694975852966309 - score 0.7268\n",
            "2019-06-17 12:22:29,695 TEST : loss 0.746776282787323 - score 0.6595\n",
            "2019-06-17 12:22:29,702 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:22:31,113 epoch 63 - iter 0/335 - loss 0.25227651\n",
            "2019-06-17 12:22:52,513 epoch 63 - iter 33/335 - loss 0.37491475\n",
            "2019-06-17 12:23:14,853 epoch 63 - iter 66/335 - loss 0.36359032\n",
            "2019-06-17 12:23:34,827 epoch 63 - iter 99/335 - loss 0.35974096\n",
            "2019-06-17 12:23:57,420 epoch 63 - iter 132/335 - loss 0.35332217\n",
            "2019-06-17 12:24:18,204 epoch 63 - iter 165/335 - loss 0.34717920\n",
            "2019-06-17 12:24:40,664 epoch 63 - iter 198/335 - loss 0.33940291\n",
            "2019-06-17 12:25:03,387 epoch 63 - iter 231/335 - loss 0.33867047\n",
            "2019-06-17 12:25:25,761 epoch 63 - iter 264/335 - loss 0.34550229\n",
            "2019-06-17 12:25:45,834 epoch 63 - iter 297/335 - loss 0.35024026\n",
            "2019-06-17 12:26:09,334 epoch 63 - iter 330/335 - loss 0.34858944\n",
            "2019-06-17 12:26:13,282 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:26:13,283 EPOCH 63 done: loss 0.3497 - lr 0.0002 - bad epochs 1\n",
            "2019-06-17 12:26:39,989 DEV : loss 0.569925844669342 - score 0.7268\n",
            "2019-06-17 12:28:16,318 TEST : loss 0.7471900582313538 - score 0.6595\n",
            "2019-06-17 12:28:16,319 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:28:17,438 epoch 64 - iter 0/335 - loss 0.25924715\n",
            "2019-06-17 12:28:39,474 epoch 64 - iter 33/335 - loss 0.33866724\n",
            "2019-06-17 12:29:03,097 epoch 64 - iter 66/335 - loss 0.36085396\n",
            "2019-06-17 12:29:27,133 epoch 64 - iter 99/335 - loss 0.35981541\n",
            "2019-06-17 12:29:48,283 epoch 64 - iter 132/335 - loss 0.34190706\n",
            "2019-06-17 12:30:10,492 epoch 64 - iter 165/335 - loss 0.35647411\n",
            "2019-06-17 12:30:32,455 epoch 64 - iter 198/335 - loss 0.34662842\n",
            "2019-06-17 12:30:51,228 epoch 64 - iter 231/335 - loss 0.34980924\n",
            "2019-06-17 12:31:12,336 epoch 64 - iter 264/335 - loss 0.35486092\n",
            "2019-06-17 12:31:35,453 epoch 64 - iter 297/335 - loss 0.35610193\n",
            "2019-06-17 12:31:56,938 epoch 64 - iter 330/335 - loss 0.35360360\n",
            "2019-06-17 12:31:59,207 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:31:59,210 EPOCH 64 done: loss 0.3549 - lr 0.0002 - bad epochs 2\n",
            "2019-06-17 12:32:25,959 DEV : loss 0.5701888799667358 - score 0.7268\n",
            "2019-06-17 12:34:02,031 TEST : loss 0.7471132278442383 - score 0.6597\n",
            "2019-06-17 12:34:02,032 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:34:03,604 epoch 65 - iter 0/335 - loss 0.08387282\n",
            "2019-06-17 12:34:25,146 epoch 65 - iter 33/335 - loss 0.28559349\n",
            "2019-06-17 12:34:46,917 epoch 65 - iter 66/335 - loss 0.31817230\n",
            "2019-06-17 12:35:08,359 epoch 65 - iter 99/335 - loss 0.32794563\n",
            "2019-06-17 12:35:32,099 epoch 65 - iter 132/335 - loss 0.32594981\n",
            "2019-06-17 12:35:52,522 epoch 65 - iter 165/335 - loss 0.32966427\n",
            "2019-06-17 12:36:12,844 epoch 65 - iter 198/335 - loss 0.33438953\n",
            "2019-06-17 12:36:34,762 epoch 65 - iter 231/335 - loss 0.33832974\n",
            "2019-06-17 12:36:56,666 epoch 65 - iter 264/335 - loss 0.34283574\n",
            "2019-06-17 12:37:16,989 epoch 65 - iter 297/335 - loss 0.34570043\n",
            "2019-06-17 12:37:41,308 epoch 65 - iter 330/335 - loss 0.35240609\n",
            "2019-06-17 12:37:43,896 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:37:43,899 EPOCH 65 done: loss 0.3525 - lr 0.0002 - bad epochs 3\n",
            "2019-06-17 12:38:12,224 DEV : loss 0.570403516292572 - score 0.7268\n",
            "2019-06-17 12:39:48,649 TEST : loss 0.7474004030227661 - score 0.6588\n",
            "Epoch    64: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2019-06-17 12:39:48,651 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:39:48,659 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:39:48,660 learning rate too small - quitting training!\n",
            "2019-06-17 12:39:48,661 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:39:49,088 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:39:49,089 Testing using best model ...\n",
            "2019-06-17 12:39:49,098 loading file resources/taggers/resume-ner-2f_100_ts/best-model.pt\n",
            "2019-06-17 12:41:24,797 0.7113\t0.6217\t0.6635\n",
            "2019-06-17 12:41:24,798 \n",
            "MICRO_AVG: acc 0.4965 - f1-score 0.6635\n",
            "MACRO_AVG: acc 0.4257 - f1-score 0.5559083333333333\n",
            "\"B-Companies tp: 254 - fp: 85 - fn: 103 - tn: 254 - precision: 0.7493 - recall: 0.7115 - accuracy: 0.5747 - f1-score: 0.7299\n",
            "\"I-Companies tp: 396 - fp: 84 - fn: 124 - tn: 396 - precision: 0.8250 - recall: 0.7615 - accuracy: 0.6556 - f1-score: 0.7920\n",
            "\"L-Companies tp: 265 - fp: 74 - fn: 96 - tn: 265 - precision: 0.7817 - recall: 0.7341 - accuracy: 0.6092 - f1-score: 0.7572\n",
            "\"U-Companies tp: 51 - fp: 100 - fn: 69 - tn: 51 - precision: 0.3377 - recall: 0.4250 - accuracy: 0.2318 - f1-score: 0.3764\n",
            "-          tp: 27 - fp: 32 - fn: 355 - tn: 27 - precision: 0.4576 - recall: 0.0707 - accuracy: 0.0652 - f1-score: 0.1225\n",
            "Degree     tp: 76 - fp: 34 - fn: 28 - tn: 76 - precision: 0.6909 - recall: 0.7308 - accuracy: 0.5507 - f1-score: 0.7103\n",
            "Designation tp: 278 - fp: 138 - fn: 129 - tn: 278 - precision: 0.6683 - recall: 0.6830 - accuracy: 0.5101 - f1-score: 0.6756\n",
            "L-Degree   tp: 77 - fp: 32 - fn: 23 - tn: 77 - precision: 0.7064 - recall: 0.7700 - accuracy: 0.5833 - f1-score: 0.7368\n",
            "L-Designation tp: 299 - fp: 117 - fn: 105 - tn: 299 - precision: 0.7188 - recall: 0.7401 - accuracy: 0.5739 - f1-score: 0.7293\n",
            "U-Degree   tp: 31 - fp: 11 - fn: 13 - tn: 31 - precision: 0.7381 - recall: 0.7045 - accuracy: 0.5636 - f1-score: 0.7209\n",
            "U-Designation tp: 8 - fp: 8 - fn: 26 - tn: 8 - precision: 0.5000 - recall: 0.2353 - accuracy: 0.1905 - f1-score: 0.3200\n",
            "ner        tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "2019-06-17 12:41:24,807 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(1.9916, device='cuda:0'),\n",
              "  tensor(1.2113, device='cuda:0'),\n",
              "  tensor(0.9337, device='cuda:0'),\n",
              "  tensor(0.8506, device='cuda:0'),\n",
              "  tensor(0.8018, device='cuda:0'),\n",
              "  tensor(0.7568, device='cuda:0'),\n",
              "  tensor(0.7505, device='cuda:0'),\n",
              "  tensor(0.6977, device='cuda:0'),\n",
              "  tensor(0.6990, device='cuda:0'),\n",
              "  tensor(0.6974, device='cuda:0'),\n",
              "  tensor(0.6289, device='cuda:0'),\n",
              "  tensor(0.6829, device='cuda:0'),\n",
              "  tensor(0.6283, device='cuda:0'),\n",
              "  tensor(0.6189, device='cuda:0'),\n",
              "  tensor(0.5982, device='cuda:0'),\n",
              "  tensor(0.6103, device='cuda:0'),\n",
              "  tensor(0.6469, device='cuda:0'),\n",
              "  tensor(0.6261, device='cuda:0'),\n",
              "  tensor(0.5791, device='cuda:0'),\n",
              "  tensor(0.5865, device='cuda:0'),\n",
              "  tensor(0.6024, device='cuda:0'),\n",
              "  tensor(0.5930, device='cuda:0'),\n",
              "  tensor(0.5677, device='cuda:0'),\n",
              "  tensor(0.6166, device='cuda:0'),\n",
              "  tensor(0.5939, device='cuda:0'),\n",
              "  tensor(0.5684, device='cuda:0'),\n",
              "  tensor(0.5928, device='cuda:0'),\n",
              "  tensor(0.5890, device='cuda:0'),\n",
              "  tensor(0.5693, device='cuda:0'),\n",
              "  tensor(0.5754, device='cuda:0'),\n",
              "  tensor(0.5776, device='cuda:0'),\n",
              "  tensor(0.5663, device='cuda:0'),\n",
              "  tensor(0.5656, device='cuda:0'),\n",
              "  tensor(0.5656, device='cuda:0'),\n",
              "  tensor(0.5677, device='cuda:0'),\n",
              "  tensor(0.5707, device='cuda:0'),\n",
              "  tensor(0.5735, device='cuda:0'),\n",
              "  tensor(0.5694, device='cuda:0'),\n",
              "  tensor(0.5683, device='cuda:0'),\n",
              "  tensor(0.5672, device='cuda:0'),\n",
              "  tensor(0.5681, device='cuda:0'),\n",
              "  tensor(0.5654, device='cuda:0'),\n",
              "  tensor(0.5661, device='cuda:0'),\n",
              "  tensor(0.5683, device='cuda:0'),\n",
              "  tensor(0.5697, device='cuda:0'),\n",
              "  tensor(0.5717, device='cuda:0'),\n",
              "  tensor(0.5694, device='cuda:0'),\n",
              "  tensor(0.5699, device='cuda:0'),\n",
              "  tensor(0.5715, device='cuda:0'),\n",
              "  tensor(0.5709, device='cuda:0'),\n",
              "  tensor(0.5701, device='cuda:0'),\n",
              "  tensor(0.5689, device='cuda:0'),\n",
              "  tensor(0.5700, device='cuda:0'),\n",
              "  tensor(0.5701, device='cuda:0'),\n",
              "  tensor(0.5700, device='cuda:0'),\n",
              "  tensor(0.5697, device='cuda:0'),\n",
              "  tensor(0.5694, device='cuda:0'),\n",
              "  tensor(0.5698, device='cuda:0'),\n",
              "  tensor(0.5694, device='cuda:0'),\n",
              "  tensor(0.5692, device='cuda:0'),\n",
              "  tensor(0.5693, device='cuda:0'),\n",
              "  tensor(0.5695, device='cuda:0'),\n",
              "  tensor(0.5699, device='cuda:0'),\n",
              "  tensor(0.5702, device='cuda:0'),\n",
              "  tensor(0.5704, device='cuda:0')],\n",
              " 'dev_score_history': [0.2995,\n",
              "  0.5468,\n",
              "  0.6423,\n",
              "  0.6562,\n",
              "  0.6701,\n",
              "  0.681,\n",
              "  0.6449,\n",
              "  0.6868,\n",
              "  0.6768,\n",
              "  0.6951,\n",
              "  0.693,\n",
              "  0.6728,\n",
              "  0.6717,\n",
              "  0.6966,\n",
              "  0.6953,\n",
              "  0.6761,\n",
              "  0.6908,\n",
              "  0.673,\n",
              "  0.7041,\n",
              "  0.719,\n",
              "  0.7192,\n",
              "  0.7183,\n",
              "  0.7084,\n",
              "  0.722,\n",
              "  0.7035,\n",
              "  0.7031,\n",
              "  0.7209,\n",
              "  0.717,\n",
              "  0.7254,\n",
              "  0.7169,\n",
              "  0.7076,\n",
              "  0.7216,\n",
              "  0.7229,\n",
              "  0.7276,\n",
              "  0.7284,\n",
              "  0.7259,\n",
              "  0.7328,\n",
              "  0.7257,\n",
              "  0.7168,\n",
              "  0.7262,\n",
              "  0.7279,\n",
              "  0.7238,\n",
              "  0.7157,\n",
              "  0.7265,\n",
              "  0.7277,\n",
              "  0.7198,\n",
              "  0.729,\n",
              "  0.7264,\n",
              "  0.7256,\n",
              "  0.7247,\n",
              "  0.7247,\n",
              "  0.7284,\n",
              "  0.7264,\n",
              "  0.7261,\n",
              "  0.7268,\n",
              "  0.7292,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268,\n",
              "  0.7268],\n",
              " 'test_score': 0.6635,\n",
              " 'train_loss_history': [3.2150696839414428,\n",
              "  1.5647823154036677,\n",
              "  1.2199548998430594,\n",
              "  1.0638119892842735,\n",
              "  0.9421208812229669,\n",
              "  0.8737381982714383,\n",
              "  0.8152821216120649,\n",
              "  0.7828217299794084,\n",
              "  0.7316549145908499,\n",
              "  0.7169227888335042,\n",
              "  0.6834224204963713,\n",
              "  0.6761300309825299,\n",
              "  0.6517513910781092,\n",
              "  0.626604288816452,\n",
              "  0.6145843394211868,\n",
              "  0.5681279077681143,\n",
              "  0.569352080083605,\n",
              "  0.5616130428972529,\n",
              "  0.5141610835915181,\n",
              "  0.5057983787646935,\n",
              "  0.47990922100508393,\n",
              "  0.4703064360725346,\n",
              "  0.46577229010525034,\n",
              "  0.45719214562159866,\n",
              "  0.45239527336697083,\n",
              "  0.45098185966263954,\n",
              "  0.43680824877610847,\n",
              "  0.42505365476679446,\n",
              "  0.4192421822405573,\n",
              "  0.39963998096202735,\n",
              "  0.40234148355562294,\n",
              "  0.39993475680030993,\n",
              "  0.3925883035606413,\n",
              "  0.38212372883042295,\n",
              "  0.3788193191165355,\n",
              "  0.37370529459483587,\n",
              "  0.3727932065725327,\n",
              "  0.36599705112514214,\n",
              "  0.37208495620471327,\n",
              "  0.3706505920348772,\n",
              "  0.3692534086641981,\n",
              "  0.35643968840143575,\n",
              "  0.3542491674645623,\n",
              "  0.3552152182406454,\n",
              "  0.34799115244132367,\n",
              "  0.3599933582010554,\n",
              "  0.3543242490113671,\n",
              "  0.3567545672406012,\n",
              "  0.350145961588888,\n",
              "  0.3572515268379183,\n",
              "  0.35475333039440327,\n",
              "  0.34378293777134883,\n",
              "  0.3420064298074637,\n",
              "  0.35490401400558985,\n",
              "  0.3497269505440299,\n",
              "  0.3604603634396596,\n",
              "  0.340701043338918,\n",
              "  0.35181349738320306,\n",
              "  0.35226576328277587,\n",
              "  0.35851922319896184,\n",
              "  0.34118022749673077,\n",
              "  0.3543759907359508,\n",
              "  0.3496772522356973,\n",
              "  0.3548817337893728,\n",
              "  0.352487186887371]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLu1-UNkwBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Bash commands can be run by prefixing the command with ‘!’.\n",
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOGC1kSYk1Xd",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}
