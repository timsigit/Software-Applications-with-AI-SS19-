{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Flair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsigit/oss-saki-ss19-exercises/blob/master/NER_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i2ZcgcwiptR",
        "colab_type": "code",
        "outputId": "33dd23f1-2445-4988-e0f5-f35cc0f51b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB19k89PDfEz",
        "colab_type": "code",
        "outputId": "9cfe2860-b6cb-4a44-c8c7-a587eb420441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "source": [
        "! pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 9.9MB/s \n",
            "\u001b[?25hCollecting regex (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 37.3MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
            "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Collecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.16.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.167)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.167 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.167)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "Building wheels for collected packages: regex, segtok, sqlitedict, mpld3\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "Successfully built regex segtok sqlitedict mpld3\n",
            "Installing collected packages: regex, deprecated, pytorch-pretrained-bert, sentencepiece, bpemb, segtok, sqlitedict, mpld3, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI53Gmli268N",
        "colab_type": "code",
        "outputId": "c31b54c6-5d59-4e2d-9e0b-88b32bc5623c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# imports \n",
        "from flair.datasets import Corpus\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "\n",
        "# file structure\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# folder where training and test data are stored\n",
        "data_folder = '/content/gdrive/My Drive'\n",
        "\n",
        "# 1.0 is full data\n",
        "downsample = 1.0\n",
        "\n",
        "# train file name\n",
        "train_file = 'train_res_bilou_sentences.txt'\n",
        "\n",
        "# test file name\n",
        "test_file = 'test_res_bilou_sentences.txt'\n",
        "\n",
        "# get the corpus\n",
        "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
        "                                                             train_file=train_file,\n",
        "                                                             test_file=test_file,\n",
        "                                                             dev_file=None).downsample(downsample)\n",
        "print(corpus)\n",
        "\n",
        "# make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:13,852 Reading data from /content/gdrive/My Drive\n",
            "2019-06-18 17:01:13,853 Train: /content/gdrive/My Drive/train_res_bilou_sentences.txt\n",
            "2019-06-18 17:01:13,854 Dev: None\n",
            "2019-06-18 17:01:13,855 Test: /content/gdrive/My Drive/test_res_bilou_sentences.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated function (or staticmethod) load_column_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:312: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  train_file, column_format\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:318: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  test_file, column_format\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Corpus: 10713 train + 1190 dev + 4399 test sentences\n",
            "[b'<unk>', b'O', b'B-Designation', b'I-Designation', b'L-Designation', b'\"B-Companies', b'\"I-Companies', b'\"L-Companies', b'-', b'\"U-Companies', b'B-Degree', b'I-Degree', b'L-Degree', b'U-Degree', b'U-Designation', b'ner', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6twFKXGFzb9",
        "colab_type": "code",
        "outputId": "41264337-2885-4146-a90a-75f923c9bc44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings,FlairEmbeddings\n",
        "from typing import List, Union, Dict\n",
        "\n",
        "# used embeddings\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type='ner',\n",
        "                                        use_crf=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:24,654 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpqe5p_i6r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:02<00:00, 65269467.45B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:27,317 copying /tmp/tmpqe5p_i6r to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:27,695 removing temp file /tmp/tmpqe5p_i6r\n",
            "2019-06-18 17:01:27,812 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpc4y7zrni\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:00<00:00, 51050721.76B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:28,439 copying /tmp/tmpc4y7zrni to cache at /root/.flair/embeddings/glove.gensim\n",
            "2019-06-18 17:01:28,469 removing temp file /tmp/tmpc4y7zrni\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:31,098 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpcp8ngvhf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:01<00:00, 67933727.97B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:32,372 copying /tmp/tmpcp8ngvhf to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:32,461 removing temp file /tmp/tmpcp8ngvhf\n",
            "2019-06-18 17:01:42,193 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpwyi5z8ej\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:01<00:00, 47545060.30B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:43,885 copying /tmp/tmpwyi5z8ej to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:01:44,013 removing temp file /tmp/tmpwyi5z8ej\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEgX66HhGE1d",
        "colab_type": "code",
        "outputId": "89de37bd-82c4-441c-ecab-d02dd2a566de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19723
        }
      },
      "source": [
        "# initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "model_name = 'resources/taggers/resume-ner-2f1w'\n",
        "\n",
        "# actual training of the model\n",
        "trainer.train(model_name,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              #anneal_with_restarts=True,\n",
        "              max_epochs=150)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-18 17:02:02,731 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:02:02,732 Evaluation method: MICRO_F1_SCORE\n",
            "2019-06-18 17:02:03,042 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:02:04,059 epoch 1 - iter 0/335 - loss 34.83150864\n",
            "2019-06-18 17:02:29,548 epoch 1 - iter 33/335 - loss 6.61275405\n",
            "2019-06-18 17:02:51,911 epoch 1 - iter 66/335 - loss 5.05210103\n",
            "2019-06-18 17:03:17,761 epoch 1 - iter 99/335 - loss 4.43548765\n",
            "2019-06-18 17:03:41,441 epoch 1 - iter 132/335 - loss 4.10072794\n",
            "2019-06-18 17:04:04,347 epoch 1 - iter 165/335 - loss 3.74861074\n",
            "2019-06-18 17:04:32,192 epoch 1 - iter 198/335 - loss 3.52344427\n",
            "2019-06-18 17:04:59,227 epoch 1 - iter 231/335 - loss 3.31547228\n",
            "2019-06-18 17:05:24,952 epoch 1 - iter 264/335 - loss 3.15698360\n",
            "2019-06-18 17:05:48,293 epoch 1 - iter 297/335 - loss 3.02494615\n",
            "2019-06-18 17:06:12,486 epoch 1 - iter 330/335 - loss 2.88309693\n",
            "2019-06-18 17:06:16,335 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:06:16,337 EPOCH 1 done: loss 2.8748 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 17:06:42,029 DEV : loss 1.3985285758972168 - score 0.525\n",
            "2019-06-18 17:08:29,790 TEST : loss 1.4702274799346924 - score 0.5244\n",
            "2019-06-18 17:08:35,132 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:08:37,584 epoch 2 - iter 0/335 - loss 0.60169160\n",
            "2019-06-18 17:09:03,083 epoch 2 - iter 33/335 - loss 1.49399413\n",
            "2019-06-18 17:09:26,974 epoch 2 - iter 66/335 - loss 1.53750518\n",
            "2019-06-18 17:09:51,304 epoch 2 - iter 99/335 - loss 1.60231549\n",
            "2019-06-18 17:10:15,757 epoch 2 - iter 132/335 - loss 1.63601141\n",
            "2019-06-18 17:10:39,151 epoch 2 - iter 165/335 - loss 1.56341891\n",
            "2019-06-18 17:11:06,925 epoch 2 - iter 198/335 - loss 1.54362960\n",
            "2019-06-18 17:11:31,098 epoch 2 - iter 231/335 - loss 1.51202462\n",
            "2019-06-18 17:11:56,851 epoch 2 - iter 264/335 - loss 1.50063895\n",
            "2019-06-18 17:12:21,772 epoch 2 - iter 297/335 - loss 1.47869724\n",
            "2019-06-18 17:12:44,402 epoch 2 - iter 330/335 - loss 1.47456830\n",
            "2019-06-18 17:12:47,150 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:12:47,152 EPOCH 2 done: loss 1.4701 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 17:13:15,307 DEV : loss 1.1084685325622559 - score 0.5693\n",
            "2019-06-18 17:15:02,848 TEST : loss 1.1502888202667236 - score 0.5765\n",
            "2019-06-18 17:15:07,933 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:15:09,633 epoch 3 - iter 0/335 - loss 2.08814883\n",
            "2019-06-18 17:15:32,759 epoch 3 - iter 33/335 - loss 1.20851526\n",
            "2019-06-18 17:16:01,328 epoch 3 - iter 66/335 - loss 1.23059254\n",
            "2019-06-18 17:16:25,619 epoch 3 - iter 99/335 - loss 1.23330282\n",
            "2019-06-18 17:16:47,828 epoch 3 - iter 132/335 - loss 1.19574247\n",
            "2019-06-18 17:17:12,657 epoch 3 - iter 165/335 - loss 1.19933418\n",
            "2019-06-18 17:17:36,719 epoch 3 - iter 198/335 - loss 1.20324813\n",
            "2019-06-18 17:17:58,907 epoch 3 - iter 231/335 - loss 1.19339042\n",
            "2019-06-18 17:18:24,425 epoch 3 - iter 264/335 - loss 1.18976975\n",
            "2019-06-18 17:18:51,478 epoch 3 - iter 297/335 - loss 1.19466623\n",
            "2019-06-18 17:19:15,116 epoch 3 - iter 330/335 - loss 1.18702739\n",
            "2019-06-18 17:19:18,130 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:19:18,131 EPOCH 3 done: loss 1.1863 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 17:19:43,824 DEV : loss 0.952561616897583 - score 0.5637\n",
            "2019-06-18 17:21:33,329 TEST : loss 0.9794526100158691 - score 0.5856\n",
            "2019-06-18 17:21:33,331 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:21:35,305 epoch 4 - iter 0/335 - loss 1.16916275\n",
            "2019-06-18 17:22:01,440 epoch 4 - iter 33/335 - loss 0.98888053\n",
            "2019-06-18 17:22:29,058 epoch 4 - iter 66/335 - loss 1.04987420\n",
            "2019-06-18 17:22:51,895 epoch 4 - iter 99/335 - loss 1.06066802\n",
            "2019-06-18 17:23:15,830 epoch 4 - iter 132/335 - loss 1.02908164\n",
            "2019-06-18 17:23:36,728 epoch 4 - iter 165/335 - loss 1.03904921\n",
            "2019-06-18 17:24:02,702 epoch 4 - iter 198/335 - loss 1.06051860\n",
            "2019-06-18 17:24:25,103 epoch 4 - iter 231/335 - loss 1.05071629\n",
            "2019-06-18 17:24:52,546 epoch 4 - iter 264/335 - loss 1.04670945\n",
            "2019-06-18 17:25:19,533 epoch 4 - iter 297/335 - loss 1.03719456\n",
            "2019-06-18 17:25:41,131 epoch 4 - iter 330/335 - loss 1.01741950\n",
            "2019-06-18 17:25:43,960 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:25:43,963 EPOCH 4 done: loss 1.0209 - lr 0.1000 - bad epochs 1\n",
            "2019-06-18 17:26:10,027 DEV : loss 0.8610001802444458 - score 0.6575\n",
            "2019-06-18 17:28:00,714 TEST : loss 0.9107930660247803 - score 0.624\n",
            "2019-06-18 17:28:06,833 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:28:09,305 epoch 5 - iter 0/335 - loss 0.91769230\n",
            "2019-06-18 17:28:32,159 epoch 5 - iter 33/335 - loss 0.96447962\n",
            "2019-06-18 17:28:56,780 epoch 5 - iter 66/335 - loss 0.97764451\n",
            "2019-06-18 17:29:24,325 epoch 5 - iter 99/335 - loss 0.97841399\n",
            "2019-06-18 17:29:47,436 epoch 5 - iter 132/335 - loss 0.97456390\n",
            "2019-06-18 17:30:09,663 epoch 5 - iter 165/335 - loss 0.91829950\n",
            "2019-06-18 17:30:38,771 epoch 5 - iter 198/335 - loss 0.91960170\n",
            "2019-06-18 17:31:03,556 epoch 5 - iter 231/335 - loss 0.91926167\n",
            "2019-06-18 17:31:28,233 epoch 5 - iter 264/335 - loss 0.91793090\n",
            "2019-06-18 17:31:51,347 epoch 5 - iter 297/335 - loss 0.91093042\n",
            "2019-06-18 17:32:16,106 epoch 5 - iter 330/335 - loss 0.91003717\n",
            "2019-06-18 17:32:18,917 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:32:18,919 EPOCH 5 done: loss 0.9099 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 17:32:44,722 DEV : loss 0.7791606187820435 - score 0.6712\n",
            "2019-06-18 17:34:32,748 TEST : loss 0.8152369856834412 - score 0.6399\n",
            "2019-06-18 17:34:38,170 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:34:40,876 epoch 6 - iter 0/335 - loss 0.57655275\n",
            "2019-06-18 17:35:09,395 epoch 6 - iter 33/335 - loss 0.70919827\n",
            "2019-06-18 17:35:36,497 epoch 6 - iter 66/335 - loss 0.82105635\n",
            "2019-06-18 17:35:59,660 epoch 6 - iter 99/335 - loss 0.82058542\n",
            "2019-06-18 17:36:24,022 epoch 6 - iter 132/335 - loss 0.82440258\n",
            "2019-06-18 17:36:49,030 epoch 6 - iter 165/335 - loss 0.84504651\n",
            "2019-06-18 17:37:12,094 epoch 6 - iter 198/335 - loss 0.83632896\n",
            "2019-06-18 17:37:36,698 epoch 6 - iter 231/335 - loss 0.81701847\n",
            "2019-06-18 17:38:00,437 epoch 6 - iter 264/335 - loss 0.84268832\n",
            "2019-06-18 17:38:26,186 epoch 6 - iter 297/335 - loss 0.84063551\n",
            "2019-06-18 17:38:48,067 epoch 6 - iter 330/335 - loss 0.85205618\n",
            "2019-06-18 17:38:52,492 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:38:52,494 EPOCH 6 done: loss 0.8499 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 17:39:21,156 DEV : loss 0.8186049461364746 - score 0.6636\n",
            "2019-06-18 17:41:09,825 TEST : loss 0.8663435578346252 - score 0.639\n",
            "2019-06-18 17:41:09,826 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:41:11,500 epoch 7 - iter 0/335 - loss 0.72940511\n",
            "2019-06-18 17:41:42,839 epoch 7 - iter 33/335 - loss 0.71007987\n",
            "2019-06-18 17:42:06,411 epoch 7 - iter 66/335 - loss 0.75907620\n",
            "2019-06-18 17:42:31,952 epoch 7 - iter 99/335 - loss 0.79902668\n",
            "2019-06-18 17:42:59,044 epoch 7 - iter 132/335 - loss 0.80045725\n",
            "2019-06-18 17:43:23,820 epoch 7 - iter 165/335 - loss 0.78218216\n",
            "2019-06-18 17:43:46,163 epoch 7 - iter 198/335 - loss 0.80985896\n",
            "2019-06-18 17:44:10,255 epoch 7 - iter 231/335 - loss 0.79690702\n",
            "2019-06-18 17:44:35,403 epoch 7 - iter 264/335 - loss 0.80137462\n",
            "2019-06-18 17:45:00,761 epoch 7 - iter 297/335 - loss 0.81538909\n",
            "2019-06-18 17:45:25,104 epoch 7 - iter 330/335 - loss 0.80818954\n",
            "2019-06-18 17:45:28,089 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:45:28,092 EPOCH 7 done: loss 0.8036 - lr 0.1000 - bad epochs 1\n",
            "2019-06-18 17:45:56,546 DEV : loss 0.7637713551521301 - score 0.6565\n",
            "2019-06-18 17:47:45,337 TEST : loss 0.8057857751846313 - score 0.6449\n",
            "2019-06-18 17:47:45,339 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:47:46,851 epoch 8 - iter 0/335 - loss 1.41271973\n",
            "2019-06-18 17:48:11,397 epoch 8 - iter 33/335 - loss 0.76226928\n",
            "2019-06-18 17:48:37,630 epoch 8 - iter 66/335 - loss 0.83339232\n",
            "2019-06-18 17:49:04,461 epoch 8 - iter 99/335 - loss 0.80580693\n",
            "2019-06-18 17:49:27,297 epoch 8 - iter 132/335 - loss 0.78195279\n",
            "2019-06-18 17:49:54,982 epoch 8 - iter 165/335 - loss 0.77241076\n",
            "2019-06-18 17:50:19,259 epoch 8 - iter 198/335 - loss 0.77557841\n",
            "2019-06-18 17:50:41,571 epoch 8 - iter 231/335 - loss 0.78827293\n",
            "2019-06-18 17:51:10,440 epoch 8 - iter 264/335 - loss 0.78633985\n",
            "2019-06-18 17:51:36,615 epoch 8 - iter 297/335 - loss 0.78255352\n",
            "2019-06-18 17:51:58,077 epoch 8 - iter 330/335 - loss 0.77296275\n",
            "2019-06-18 17:52:00,472 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:52:00,474 EPOCH 8 done: loss 0.7728 - lr 0.1000 - bad epochs 2\n",
            "2019-06-18 17:52:26,469 DEV : loss 0.7126798033714294 - score 0.6681\n",
            "2019-06-18 17:54:17,335 TEST : loss 0.7676154971122742 - score 0.6591\n",
            "2019-06-18 17:54:17,337 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:54:18,902 epoch 9 - iter 0/335 - loss 0.45949626\n",
            "2019-06-18 17:54:39,250 epoch 9 - iter 33/335 - loss 0.64802799\n",
            "2019-06-18 17:55:05,749 epoch 9 - iter 66/335 - loss 0.69568613\n",
            "2019-06-18 17:55:33,018 epoch 9 - iter 99/335 - loss 0.66140593\n",
            "2019-06-18 17:55:57,597 epoch 9 - iter 132/335 - loss 0.67380048\n",
            "2019-06-18 17:56:22,507 epoch 9 - iter 165/335 - loss 0.68329431\n",
            "2019-06-18 17:56:52,067 epoch 9 - iter 198/335 - loss 0.69999839\n",
            "2019-06-18 17:57:14,563 epoch 9 - iter 231/335 - loss 0.72463342\n",
            "2019-06-18 17:57:38,144 epoch 9 - iter 264/335 - loss 0.72331902\n",
            "2019-06-18 17:58:02,798 epoch 9 - iter 297/335 - loss 0.72750167\n",
            "2019-06-18 17:58:26,952 epoch 9 - iter 330/335 - loss 0.73119846\n",
            "2019-06-18 17:58:29,742 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 17:58:29,744 EPOCH 9 done: loss 0.7334 - lr 0.1000 - bad epochs 3\n",
            "2019-06-18 17:58:55,709 DEV : loss 0.7031493782997131 - score 0.6746\n",
            "2019-06-18 18:00:46,199 TEST : loss 0.7475816011428833 - score 0.6537\n",
            "2019-06-18 18:00:51,447 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:00:52,841 epoch 10 - iter 0/335 - loss 0.19501662\n",
            "2019-06-18 18:01:18,500 epoch 10 - iter 33/335 - loss 0.67199147\n",
            "2019-06-18 18:01:42,302 epoch 10 - iter 66/335 - loss 0.68126888\n",
            "2019-06-18 18:02:10,335 epoch 10 - iter 99/335 - loss 0.69113961\n",
            "2019-06-18 18:02:36,078 epoch 10 - iter 132/335 - loss 0.68025467\n",
            "2019-06-18 18:02:59,713 epoch 10 - iter 165/335 - loss 0.69691545\n",
            "2019-06-18 18:03:26,756 epoch 10 - iter 198/335 - loss 0.70722892\n",
            "2019-06-18 18:03:51,214 epoch 10 - iter 231/335 - loss 0.69011984\n",
            "2019-06-18 18:04:15,121 epoch 10 - iter 264/335 - loss 0.69677314\n",
            "2019-06-18 18:04:39,838 epoch 10 - iter 297/335 - loss 0.70915269\n",
            "2019-06-18 18:05:01,576 epoch 10 - iter 330/335 - loss 0.71109797\n",
            "2019-06-18 18:05:04,994 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:05:04,995 EPOCH 10 done: loss 0.7120 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 18:05:31,252 DEV : loss 0.6891710162162781 - score 0.6803\n",
            "2019-06-18 18:07:21,540 TEST : loss 0.7485301494598389 - score 0.6616\n",
            "2019-06-18 18:07:26,887 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:07:28,729 epoch 11 - iter 0/335 - loss 0.72174597\n",
            "2019-06-18 18:07:53,811 epoch 11 - iter 33/335 - loss 0.62158482\n",
            "2019-06-18 18:08:21,315 epoch 11 - iter 66/335 - loss 0.63628771\n",
            "2019-06-18 18:08:46,207 epoch 11 - iter 99/335 - loss 0.65301881\n",
            "2019-06-18 18:09:10,427 epoch 11 - iter 132/335 - loss 0.66391618\n",
            "2019-06-18 18:09:33,203 epoch 11 - iter 165/335 - loss 0.66858723\n",
            "2019-06-18 18:09:56,973 epoch 11 - iter 198/335 - loss 0.67167786\n",
            "2019-06-18 18:10:23,813 epoch 11 - iter 231/335 - loss 0.67038524\n",
            "2019-06-18 18:10:46,685 epoch 11 - iter 264/335 - loss 0.66473421\n",
            "2019-06-18 18:11:12,630 epoch 11 - iter 297/335 - loss 0.67257055\n",
            "2019-06-18 18:11:37,886 epoch 11 - iter 330/335 - loss 0.67932507\n",
            "2019-06-18 18:11:40,303 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:11:40,304 EPOCH 11 done: loss 0.6759 - lr 0.1000 - bad epochs 0\n",
            "2019-06-18 18:12:06,383 DEV : loss 0.6874988079071045 - score 0.6569\n",
            "2019-06-18 18:13:55,097 TEST : loss 0.7389366030693054 - score 0.6446\n",
            "2019-06-18 18:13:55,099 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:13:56,534 epoch 12 - iter 0/335 - loss 0.57037711\n",
            "2019-06-18 18:14:25,833 epoch 12 - iter 33/335 - loss 0.63780733\n",
            "2019-06-18 18:14:49,555 epoch 12 - iter 66/335 - loss 0.63776380\n",
            "2019-06-18 18:15:14,758 epoch 12 - iter 99/335 - loss 0.62830839\n",
            "2019-06-18 18:15:41,861 epoch 12 - iter 132/335 - loss 0.63075720\n",
            "2019-06-18 18:16:04,531 epoch 12 - iter 165/335 - loss 0.64514740\n",
            "2019-06-18 18:16:28,792 epoch 12 - iter 198/335 - loss 0.66148725\n",
            "2019-06-18 18:16:53,011 epoch 12 - iter 231/335 - loss 0.66721179\n",
            "2019-06-18 18:17:16,731 epoch 12 - iter 264/335 - loss 0.65227240\n",
            "2019-06-18 18:17:42,006 epoch 12 - iter 297/335 - loss 0.65348569\n",
            "2019-06-18 18:18:06,400 epoch 12 - iter 330/335 - loss 0.65141070\n",
            "2019-06-18 18:18:08,855 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:18:08,856 EPOCH 12 done: loss 0.6522 - lr 0.1000 - bad epochs 1\n",
            "2019-06-18 18:18:37,450 DEV : loss 0.6779047250747681 - score 0.6695\n",
            "2019-06-18 18:20:26,720 TEST : loss 0.7448037266731262 - score 0.6541\n",
            "2019-06-18 18:20:26,722 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:20:28,038 epoch 13 - iter 0/335 - loss 0.16684669\n",
            "2019-06-18 18:20:54,903 epoch 13 - iter 33/335 - loss 0.60381260\n",
            "2019-06-18 18:21:19,234 epoch 13 - iter 66/335 - loss 0.62308596\n",
            "2019-06-18 18:21:44,670 epoch 13 - iter 99/335 - loss 0.60982124\n",
            "2019-06-18 18:22:07,595 epoch 13 - iter 132/335 - loss 0.62133180\n",
            "2019-06-18 18:22:35,255 epoch 13 - iter 165/335 - loss 0.62939102\n",
            "2019-06-18 18:22:59,739 epoch 13 - iter 198/335 - loss 0.61848351\n",
            "2019-06-18 18:23:22,226 epoch 13 - iter 231/335 - loss 0.60689295\n",
            "2019-06-18 18:23:49,136 epoch 13 - iter 264/335 - loss 0.62949362\n",
            "2019-06-18 18:24:15,301 epoch 13 - iter 297/335 - loss 0.63167054\n",
            "2019-06-18 18:24:38,602 epoch 13 - iter 330/335 - loss 0.63666848\n",
            "2019-06-18 18:24:41,671 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:24:41,676 EPOCH 13 done: loss 0.6324 - lr 0.1000 - bad epochs 2\n",
            "2019-06-18 18:25:10,299 DEV : loss 0.6618306040763855 - score 0.652\n",
            "2019-06-18 18:26:59,110 TEST : loss 0.7291944622993469 - score 0.6655\n",
            "2019-06-18 18:26:59,112 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:27:00,593 epoch 14 - iter 0/335 - loss 0.42999229\n",
            "2019-06-18 18:27:24,675 epoch 14 - iter 33/335 - loss 0.67116217\n",
            "2019-06-18 18:27:52,618 epoch 14 - iter 66/335 - loss 0.66773107\n",
            "2019-06-18 18:28:14,979 epoch 14 - iter 99/335 - loss 0.60921049\n",
            "2019-06-18 18:28:39,303 epoch 14 - iter 132/335 - loss 0.59363138\n",
            "2019-06-18 18:29:00,957 epoch 14 - iter 165/335 - loss 0.58851032\n",
            "2019-06-18 18:29:26,635 epoch 14 - iter 198/335 - loss 0.57664916\n",
            "2019-06-18 18:29:55,076 epoch 14 - iter 231/335 - loss 0.58703492\n",
            "2019-06-18 18:30:21,533 epoch 14 - iter 264/335 - loss 0.60011275\n",
            "2019-06-18 18:30:45,071 epoch 14 - iter 297/335 - loss 0.61242684\n",
            "2019-06-18 18:31:08,557 epoch 14 - iter 330/335 - loss 0.61493444\n",
            "2019-06-18 18:31:12,854 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:31:12,856 EPOCH 14 done: loss 0.6154 - lr 0.1000 - bad epochs 3\n",
            "2019-06-18 18:31:38,863 DEV : loss 0.6534770131111145 - score 0.674\n",
            "2019-06-18 18:33:29,529 TEST : loss 0.738591194152832 - score 0.6621\n",
            "Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-06-18 18:33:29,530 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:33:31,240 epoch 15 - iter 0/335 - loss 1.45342517\n",
            "2019-06-18 18:33:54,659 epoch 15 - iter 33/335 - loss 0.61090660\n",
            "2019-06-18 18:34:22,909 epoch 15 - iter 66/335 - loss 0.60061260\n",
            "2019-06-18 18:34:45,091 epoch 15 - iter 99/335 - loss 0.60046874\n",
            "2019-06-18 18:35:09,115 epoch 15 - iter 132/335 - loss 0.60551445\n",
            "2019-06-18 18:35:34,241 epoch 15 - iter 165/335 - loss 0.60451302\n",
            "2019-06-18 18:36:04,017 epoch 15 - iter 198/335 - loss 0.59717668\n",
            "2019-06-18 18:36:25,852 epoch 15 - iter 231/335 - loss 0.59833531\n",
            "2019-06-18 18:36:49,768 epoch 15 - iter 264/335 - loss 0.59682467\n",
            "2019-06-18 18:37:17,741 epoch 15 - iter 297/335 - loss 0.59536492\n",
            "2019-06-18 18:37:39,242 epoch 15 - iter 330/335 - loss 0.58782066\n",
            "2019-06-18 18:37:43,010 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:37:43,013 EPOCH 15 done: loss 0.5855 - lr 0.0500 - bad epochs 0\n",
            "2019-06-18 18:38:09,096 DEV : loss 0.6242407560348511 - score 0.6936\n",
            "2019-06-18 18:39:59,514 TEST : loss 0.7062504291534424 - score 0.6743\n",
            "2019-06-18 18:40:04,797 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:40:06,469 epoch 16 - iter 0/335 - loss 0.46679199\n",
            "2019-06-18 18:40:32,997 epoch 16 - iter 33/335 - loss 0.58276000\n",
            "2019-06-18 18:40:58,849 epoch 16 - iter 66/335 - loss 0.56033001\n",
            "2019-06-18 18:41:23,141 epoch 16 - iter 99/335 - loss 0.54979284\n",
            "2019-06-18 18:41:46,110 epoch 16 - iter 132/335 - loss 0.52123576\n",
            "2019-06-18 18:42:09,221 epoch 16 - iter 165/335 - loss 0.54200585\n",
            "2019-06-18 18:42:39,337 epoch 16 - iter 198/335 - loss 0.55350052\n",
            "2019-06-18 18:43:03,936 epoch 16 - iter 231/335 - loss 0.56016448\n",
            "2019-06-18 18:43:27,089 epoch 16 - iter 264/335 - loss 0.56132982\n",
            "2019-06-18 18:43:50,350 epoch 16 - iter 297/335 - loss 0.55946245\n",
            "2019-06-18 18:44:14,857 epoch 16 - iter 330/335 - loss 0.56078981\n",
            "2019-06-18 18:44:18,843 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:44:18,844 EPOCH 16 done: loss 0.5604 - lr 0.0500 - bad epochs 0\n",
            "2019-06-18 18:44:44,846 DEV : loss 0.5997934341430664 - score 0.6892\n",
            "2019-06-18 18:46:35,261 TEST : loss 0.6835883259773254 - score 0.6625\n",
            "2019-06-18 18:46:35,262 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:46:36,795 epoch 17 - iter 0/335 - loss 0.54601294\n",
            "2019-06-18 18:47:00,798 epoch 17 - iter 33/335 - loss 0.56576762\n",
            "2019-06-18 18:47:24,756 epoch 17 - iter 66/335 - loss 0.52723316\n",
            "2019-06-18 18:47:49,601 epoch 17 - iter 99/335 - loss 0.53579678\n",
            "2019-06-18 18:48:18,396 epoch 17 - iter 132/335 - loss 0.52890204\n",
            "2019-06-18 18:48:43,649 epoch 17 - iter 165/335 - loss 0.53471991\n",
            "2019-06-18 18:49:09,322 epoch 17 - iter 198/335 - loss 0.53294952\n",
            "2019-06-18 18:49:35,604 epoch 17 - iter 231/335 - loss 0.53612954\n",
            "2019-06-18 18:49:58,656 epoch 17 - iter 264/335 - loss 0.53981383\n",
            "2019-06-18 18:50:20,075 epoch 17 - iter 297/335 - loss 0.54516233\n",
            "2019-06-18 18:50:43,729 epoch 17 - iter 330/335 - loss 0.54004277\n",
            "2019-06-18 18:50:48,251 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:50:48,253 EPOCH 17 done: loss 0.5406 - lr 0.0500 - bad epochs 1\n",
            "2019-06-18 18:51:17,146 DEV : loss 0.6132175326347351 - score 0.6879\n",
            "2019-06-18 18:53:05,630 TEST : loss 0.7099482417106628 - score 0.6734\n",
            "2019-06-18 18:53:05,632 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:53:07,010 epoch 18 - iter 0/335 - loss 0.12043932\n",
            "2019-06-18 18:53:34,359 epoch 18 - iter 33/335 - loss 0.54635239\n",
            "2019-06-18 18:54:02,707 epoch 18 - iter 66/335 - loss 0.53549190\n",
            "2019-06-18 18:54:27,850 epoch 18 - iter 99/335 - loss 0.51480047\n",
            "2019-06-18 18:54:55,265 epoch 18 - iter 132/335 - loss 0.50191549\n",
            "2019-06-18 18:55:19,972 epoch 18 - iter 165/335 - loss 0.50562098\n",
            "2019-06-18 18:55:43,236 epoch 18 - iter 198/335 - loss 0.50527103\n",
            "2019-06-18 18:56:07,420 epoch 18 - iter 231/335 - loss 0.50918706\n",
            "2019-06-18 18:56:31,181 epoch 18 - iter 264/335 - loss 0.50702267\n",
            "2019-06-18 18:56:50,669 epoch 18 - iter 297/335 - loss 0.50959459\n",
            "2019-06-18 18:57:12,981 epoch 18 - iter 330/335 - loss 0.51322182\n",
            "2019-06-18 18:57:16,172 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:57:16,174 EPOCH 18 done: loss 0.5173 - lr 0.0500 - bad epochs 2\n",
            "2019-06-18 18:57:44,764 DEV : loss 0.5963783860206604 - score 0.6771\n",
            "2019-06-18 18:59:33,679 TEST : loss 0.6904430985450745 - score 0.6601\n",
            "2019-06-18 18:59:33,681 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 18:59:35,315 epoch 19 - iter 0/335 - loss 1.13771212\n",
            "2019-06-18 18:59:58,978 epoch 19 - iter 33/335 - loss 0.65235694\n",
            "2019-06-18 19:00:26,262 epoch 19 - iter 66/335 - loss 0.57260326\n",
            "2019-06-18 19:00:52,783 epoch 19 - iter 99/335 - loss 0.53605920\n",
            "2019-06-18 19:01:21,084 epoch 19 - iter 132/335 - loss 0.52629601\n",
            "2019-06-18 19:01:49,887 epoch 19 - iter 165/335 - loss 0.52693592\n",
            "2019-06-18 19:02:15,810 epoch 19 - iter 198/335 - loss 0.52876695\n",
            "2019-06-18 19:02:37,346 epoch 19 - iter 231/335 - loss 0.51982389\n",
            "2019-06-18 19:02:58,936 epoch 19 - iter 264/335 - loss 0.51312670\n",
            "2019-06-18 19:03:23,928 epoch 19 - iter 297/335 - loss 0.51148795\n",
            "2019-06-18 19:03:45,784 epoch 19 - iter 330/335 - loss 0.50684162\n",
            "2019-06-18 19:03:49,001 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:03:49,002 EPOCH 19 done: loss 0.5064 - lr 0.0500 - bad epochs 3\n",
            "2019-06-18 19:04:15,066 DEV : loss 0.5999196767807007 - score 0.6822\n",
            "2019-06-18 19:06:05,422 TEST : loss 0.695364773273468 - score 0.6689\n",
            "Epoch    18: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-06-18 19:06:05,424 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:06:06,864 epoch 20 - iter 0/335 - loss 0.19697398\n",
            "2019-06-18 19:06:30,082 epoch 20 - iter 33/335 - loss 0.49040722\n",
            "2019-06-18 19:06:56,508 epoch 20 - iter 66/335 - loss 0.50442097\n",
            "2019-06-18 19:07:18,567 epoch 20 - iter 99/335 - loss 0.49802304\n",
            "2019-06-18 19:07:41,890 epoch 20 - iter 132/335 - loss 0.50096756\n",
            "2019-06-18 19:08:08,951 epoch 20 - iter 165/335 - loss 0.50143486\n",
            "2019-06-18 19:08:38,917 epoch 20 - iter 198/335 - loss 0.51277975\n",
            "2019-06-18 19:09:03,283 epoch 20 - iter 231/335 - loss 0.50855882\n",
            "2019-06-18 19:09:27,253 epoch 20 - iter 264/335 - loss 0.50690481\n",
            "2019-06-18 19:09:55,255 epoch 20 - iter 297/335 - loss 0.50484486\n",
            "2019-06-18 19:10:16,120 epoch 20 - iter 330/335 - loss 0.49798226\n",
            "2019-06-18 19:10:18,801 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:10:18,803 EPOCH 20 done: loss 0.4979 - lr 0.0250 - bad epochs 0\n",
            "2019-06-18 19:10:44,927 DEV : loss 0.5956677198410034 - score 0.7043\n",
            "2019-06-18 19:12:35,820 TEST : loss 0.6997414231300354 - score 0.6805\n",
            "2019-06-18 19:12:42,146 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:12:43,726 epoch 21 - iter 0/335 - loss 1.00419629\n",
            "2019-06-18 19:13:05,858 epoch 21 - iter 33/335 - loss 0.40912018\n",
            "2019-06-18 19:13:29,684 epoch 21 - iter 66/335 - loss 0.47332800\n",
            "2019-06-18 19:13:56,604 epoch 21 - iter 99/335 - loss 0.47797085\n",
            "2019-06-18 19:14:22,945 epoch 21 - iter 132/335 - loss 0.49893120\n",
            "2019-06-18 19:14:51,165 epoch 21 - iter 165/335 - loss 0.51286808\n",
            "2019-06-18 19:15:16,709 epoch 21 - iter 198/335 - loss 0.50328230\n",
            "2019-06-18 19:15:39,940 epoch 21 - iter 231/335 - loss 0.49694070\n",
            "2019-06-18 19:16:02,219 epoch 21 - iter 264/335 - loss 0.49478525\n",
            "2019-06-18 19:16:27,308 epoch 21 - iter 297/335 - loss 0.48650569\n",
            "2019-06-18 19:16:53,155 epoch 21 - iter 330/335 - loss 0.49141683\n",
            "2019-06-18 19:16:55,802 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:16:55,804 EPOCH 21 done: loss 0.4903 - lr 0.0250 - bad epochs 0\n",
            "2019-06-18 19:17:22,005 DEV : loss 0.5839762687683105 - score 0.6831\n",
            "2019-06-18 19:19:10,289 TEST : loss 0.6854583621025085 - score 0.6755\n",
            "2019-06-18 19:19:10,290 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:19:11,755 epoch 22 - iter 0/335 - loss 0.70085168\n",
            "2019-06-18 19:19:36,179 epoch 22 - iter 33/335 - loss 0.45332442\n",
            "2019-06-18 19:20:03,537 epoch 22 - iter 66/335 - loss 0.48047072\n",
            "2019-06-18 19:20:29,306 epoch 22 - iter 99/335 - loss 0.50789980\n",
            "2019-06-18 19:20:54,726 epoch 22 - iter 132/335 - loss 0.48095364\n",
            "2019-06-18 19:21:18,880 epoch 22 - iter 165/335 - loss 0.47834028\n",
            "2019-06-18 19:21:41,595 epoch 22 - iter 198/335 - loss 0.47819211\n",
            "2019-06-18 19:22:05,702 epoch 22 - iter 231/335 - loss 0.46993053\n",
            "2019-06-18 19:22:27,199 epoch 22 - iter 264/335 - loss 0.47445231\n",
            "2019-06-18 19:22:54,263 epoch 22 - iter 297/335 - loss 0.47009543\n",
            "2019-06-18 19:23:18,492 epoch 22 - iter 330/335 - loss 0.47521438\n",
            "2019-06-18 19:23:23,324 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:23:23,325 EPOCH 22 done: loss 0.4773 - lr 0.0250 - bad epochs 1\n",
            "2019-06-18 19:23:52,234 DEV : loss 0.5895816683769226 - score 0.6986\n",
            "2019-06-18 19:25:41,095 TEST : loss 0.6993544697761536 - score 0.6749\n",
            "2019-06-18 19:25:41,097 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:25:42,635 epoch 23 - iter 0/335 - loss 0.33560872\n",
            "2019-06-18 19:26:10,397 epoch 23 - iter 33/335 - loss 0.43269953\n",
            "2019-06-18 19:26:37,659 epoch 23 - iter 66/335 - loss 0.45979830\n",
            "2019-06-18 19:27:01,032 epoch 23 - iter 99/335 - loss 0.46660587\n",
            "2019-06-18 19:27:22,936 epoch 23 - iter 132/335 - loss 0.47015554\n",
            "2019-06-18 19:27:49,425 epoch 23 - iter 165/335 - loss 0.48207258\n",
            "2019-06-18 19:28:14,377 epoch 23 - iter 198/335 - loss 0.49768524\n",
            "2019-06-18 19:28:39,863 epoch 23 - iter 231/335 - loss 0.49809723\n",
            "2019-06-18 19:29:04,628 epoch 23 - iter 264/335 - loss 0.49225185\n",
            "2019-06-18 19:29:26,614 epoch 23 - iter 297/335 - loss 0.48236622\n",
            "2019-06-18 19:29:50,986 epoch 23 - iter 330/335 - loss 0.48056764\n",
            "2019-06-18 19:29:53,392 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:29:53,393 EPOCH 23 done: loss 0.4786 - lr 0.0250 - bad epochs 2\n",
            "2019-06-18 19:30:21,942 DEV : loss 0.5958923101425171 - score 0.6976\n",
            "2019-06-18 19:32:10,529 TEST : loss 0.7071793675422668 - score 0.6739\n",
            "2019-06-18 19:32:10,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:32:12,389 epoch 24 - iter 0/335 - loss 0.36528417\n",
            "2019-06-18 19:32:34,774 epoch 24 - iter 33/335 - loss 0.43431028\n",
            "2019-06-18 19:32:59,627 epoch 24 - iter 66/335 - loss 0.46096522\n",
            "2019-06-18 19:33:23,368 epoch 24 - iter 99/335 - loss 0.46973113\n",
            "2019-06-18 19:33:49,441 epoch 24 - iter 132/335 - loss 0.47081837\n",
            "2019-06-18 19:34:16,146 epoch 24 - iter 165/335 - loss 0.47339419\n",
            "2019-06-18 19:34:41,561 epoch 24 - iter 198/335 - loss 0.46542536\n",
            "2019-06-18 19:35:03,645 epoch 24 - iter 231/335 - loss 0.44865825\n",
            "2019-06-18 19:35:32,225 epoch 24 - iter 264/335 - loss 0.46085594\n",
            "2019-06-18 19:35:59,469 epoch 24 - iter 297/335 - loss 0.46557393\n",
            "2019-06-18 19:36:25,120 epoch 24 - iter 330/335 - loss 0.46450845\n",
            "2019-06-18 19:36:27,936 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:36:27,941 EPOCH 24 done: loss 0.4657 - lr 0.0250 - bad epochs 3\n",
            "2019-06-18 19:36:54,079 DEV : loss 0.584922194480896 - score 0.686\n",
            "2019-06-18 19:38:44,192 TEST : loss 0.7001388669013977 - score 0.6759\n",
            "Epoch    23: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-06-18 19:38:44,194 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:38:45,661 epoch 25 - iter 0/335 - loss 0.46685743\n",
            "2019-06-18 19:39:10,499 epoch 25 - iter 33/335 - loss 0.45716963\n",
            "2019-06-18 19:39:36,639 epoch 25 - iter 66/335 - loss 0.47129751\n",
            "2019-06-18 19:40:02,924 epoch 25 - iter 99/335 - loss 0.45440588\n",
            "2019-06-18 19:40:24,686 epoch 25 - iter 132/335 - loss 0.45158369\n",
            "2019-06-18 19:40:51,891 epoch 25 - iter 165/335 - loss 0.44812680\n",
            "2019-06-18 19:41:15,992 epoch 25 - iter 198/335 - loss 0.43989390\n",
            "2019-06-18 19:41:38,708 epoch 25 - iter 231/335 - loss 0.45119210\n",
            "2019-06-18 19:42:04,583 epoch 25 - iter 264/335 - loss 0.45795747\n",
            "2019-06-18 19:42:29,788 epoch 25 - iter 297/335 - loss 0.45566750\n",
            "2019-06-18 19:42:56,519 epoch 25 - iter 330/335 - loss 0.45362695\n",
            "2019-06-18 19:43:00,189 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:43:00,190 EPOCH 25 done: loss 0.4530 - lr 0.0125 - bad epochs 0\n",
            "2019-06-18 19:43:26,301 DEV : loss 0.5810116529464722 - score 0.7061\n",
            "2019-06-18 19:45:16,679 TEST : loss 0.7038377523422241 - score 0.677\n",
            "2019-06-18 19:45:22,904 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:45:24,744 epoch 26 - iter 0/335 - loss 0.45265403\n",
            "2019-06-18 19:45:46,884 epoch 26 - iter 33/335 - loss 0.44833291\n",
            "2019-06-18 19:46:11,339 epoch 26 - iter 66/335 - loss 0.42891842\n",
            "2019-06-18 19:46:39,377 epoch 26 - iter 99/335 - loss 0.46570837\n",
            "2019-06-18 19:47:05,093 epoch 26 - iter 132/335 - loss 0.48708792\n",
            "2019-06-18 19:47:29,551 epoch 26 - iter 165/335 - loss 0.47796081\n",
            "2019-06-18 19:47:58,401 epoch 26 - iter 198/335 - loss 0.46676931\n",
            "2019-06-18 19:48:22,517 epoch 26 - iter 231/335 - loss 0.45727433\n",
            "2019-06-18 19:48:44,049 epoch 26 - iter 264/335 - loss 0.45536526\n",
            "2019-06-18 19:49:04,390 epoch 26 - iter 297/335 - loss 0.45223884\n",
            "2019-06-18 19:49:32,141 epoch 26 - iter 330/335 - loss 0.45383693\n",
            "2019-06-18 19:49:34,443 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:49:34,444 EPOCH 26 done: loss 0.4503 - lr 0.0125 - bad epochs 0\n",
            "2019-06-18 19:50:00,384 DEV : loss 0.5788203477859497 - score 0.6931\n",
            "2019-06-18 19:51:50,499 TEST : loss 0.700673520565033 - score 0.6708\n",
            "2019-06-18 19:51:50,501 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:51:52,870 epoch 27 - iter 0/335 - loss 0.69599134\n",
            "2019-06-18 19:52:18,425 epoch 27 - iter 33/335 - loss 0.46377558\n",
            "2019-06-18 19:52:43,186 epoch 27 - iter 66/335 - loss 0.45097458\n",
            "2019-06-18 19:53:10,070 epoch 27 - iter 99/335 - loss 0.47562842\n",
            "2019-06-18 19:53:35,825 epoch 27 - iter 132/335 - loss 0.46826843\n",
            "2019-06-18 19:54:02,326 epoch 27 - iter 165/335 - loss 0.46790058\n",
            "2019-06-18 19:54:25,551 epoch 27 - iter 198/335 - loss 0.46660291\n",
            "2019-06-18 19:54:53,255 epoch 27 - iter 231/335 - loss 0.45586658\n",
            "2019-06-18 19:55:16,765 epoch 27 - iter 264/335 - loss 0.45359714\n",
            "2019-06-18 19:55:39,447 epoch 27 - iter 297/335 - loss 0.45726094\n",
            "2019-06-18 19:56:01,937 epoch 27 - iter 330/335 - loss 0.45929439\n",
            "2019-06-18 19:56:04,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:56:04,410 EPOCH 27 done: loss 0.4607 - lr 0.0125 - bad epochs 1\n",
            "2019-06-18 19:56:30,495 DEV : loss 0.5899136066436768 - score 0.6911\n",
            "2019-06-18 19:58:19,012 TEST : loss 0.6965532898902893 - score 0.6686\n",
            "2019-06-18 19:58:19,013 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 19:58:20,332 epoch 28 - iter 0/335 - loss 0.16696233\n",
            "2019-06-18 19:58:48,247 epoch 28 - iter 33/335 - loss 0.46715590\n",
            "2019-06-18 19:59:09,726 epoch 28 - iter 66/335 - loss 0.44299389\n",
            "2019-06-18 19:59:37,709 epoch 28 - iter 99/335 - loss 0.46514880\n",
            "2019-06-18 20:00:03,257 epoch 28 - iter 132/335 - loss 0.45753379\n",
            "2019-06-18 20:00:26,274 epoch 28 - iter 165/335 - loss 0.45248981\n",
            "2019-06-18 20:00:49,278 epoch 28 - iter 198/335 - loss 0.46790379\n",
            "2019-06-18 20:01:17,185 epoch 28 - iter 231/335 - loss 0.46321896\n",
            "2019-06-18 20:01:43,220 epoch 28 - iter 264/335 - loss 0.45384821\n",
            "2019-06-18 20:02:07,099 epoch 28 - iter 297/335 - loss 0.45231299\n",
            "2019-06-18 20:02:30,370 epoch 28 - iter 330/335 - loss 0.45520060\n",
            "2019-06-18 20:02:33,535 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:02:33,536 EPOCH 28 done: loss 0.4597 - lr 0.0125 - bad epochs 2\n",
            "2019-06-18 20:03:02,088 DEV : loss 0.576849102973938 - score 0.6911\n",
            "2019-06-18 20:04:50,710 TEST : loss 0.6943916082382202 - score 0.664\n",
            "2019-06-18 20:04:50,711 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:04:52,116 epoch 29 - iter 0/335 - loss 0.14186156\n",
            "2019-06-18 20:05:18,117 epoch 29 - iter 33/335 - loss 0.49866031\n",
            "2019-06-18 20:05:40,475 epoch 29 - iter 66/335 - loss 0.47036001\n",
            "2019-06-18 20:06:07,089 epoch 29 - iter 99/335 - loss 0.45915487\n",
            "2019-06-18 20:06:30,985 epoch 29 - iter 132/335 - loss 0.47156177\n",
            "2019-06-18 20:06:58,040 epoch 29 - iter 165/335 - loss 0.46662468\n",
            "2019-06-18 20:07:23,216 epoch 29 - iter 198/335 - loss 0.45845789\n",
            "2019-06-18 20:07:44,710 epoch 29 - iter 231/335 - loss 0.44471819\n",
            "2019-06-18 20:08:13,128 epoch 29 - iter 264/335 - loss 0.45493888\n",
            "2019-06-18 20:08:38,296 epoch 29 - iter 297/335 - loss 0.45269975\n",
            "2019-06-18 20:09:01,047 epoch 29 - iter 330/335 - loss 0.44911964\n",
            "2019-06-18 20:09:04,812 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:09:04,818 EPOCH 29 done: loss 0.4511 - lr 0.0125 - bad epochs 3\n",
            "2019-06-18 20:09:33,350 DEV : loss 0.5764424204826355 - score 0.703\n",
            "2019-06-18 20:11:21,738 TEST : loss 0.6980395317077637 - score 0.6668\n",
            "Epoch    28: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-06-18 20:11:21,740 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:11:23,241 epoch 30 - iter 0/335 - loss 0.64530748\n",
            "2019-06-18 20:11:46,570 epoch 30 - iter 33/335 - loss 0.46124765\n",
            "2019-06-18 20:12:15,057 epoch 30 - iter 66/335 - loss 0.46688642\n",
            "2019-06-18 20:12:39,672 epoch 30 - iter 99/335 - loss 0.47823382\n",
            "2019-06-18 20:13:05,547 epoch 30 - iter 132/335 - loss 0.47297509\n",
            "2019-06-18 20:13:30,910 epoch 30 - iter 165/335 - loss 0.45567317\n",
            "2019-06-18 20:13:55,885 epoch 30 - iter 198/335 - loss 0.45098418\n",
            "2019-06-18 20:14:17,591 epoch 30 - iter 231/335 - loss 0.45250472\n",
            "2019-06-18 20:14:43,606 epoch 30 - iter 264/335 - loss 0.45658467\n",
            "2019-06-18 20:15:10,270 epoch 30 - iter 297/335 - loss 0.44738819\n",
            "2019-06-18 20:15:32,034 epoch 30 - iter 330/335 - loss 0.44834428\n",
            "2019-06-18 20:15:34,778 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:15:34,780 EPOCH 30 done: loss 0.4463 - lr 0.0063 - bad epochs 0\n",
            "2019-06-18 20:16:00,682 DEV : loss 0.5814805030822754 - score 0.7022\n",
            "2019-06-18 20:17:51,334 TEST : loss 0.69868004322052 - score 0.6674\n",
            "2019-06-18 20:17:51,336 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:17:52,991 epoch 31 - iter 0/335 - loss 0.52973223\n",
            "2019-06-18 20:18:17,535 epoch 31 - iter 33/335 - loss 0.46964163\n",
            "2019-06-18 20:18:47,445 epoch 31 - iter 66/335 - loss 0.50471995\n",
            "2019-06-18 20:19:12,336 epoch 31 - iter 99/335 - loss 0.48725466\n",
            "2019-06-18 20:19:33,823 epoch 31 - iter 132/335 - loss 0.47481585\n",
            "2019-06-18 20:19:56,840 epoch 31 - iter 165/335 - loss 0.45162756\n",
            "2019-06-18 20:20:20,551 epoch 31 - iter 198/335 - loss 0.45115842\n",
            "2019-06-18 20:20:45,128 epoch 31 - iter 231/335 - loss 0.44305489\n",
            "2019-06-18 20:21:07,726 epoch 31 - iter 264/335 - loss 0.43634669\n",
            "2019-06-18 20:21:35,378 epoch 31 - iter 297/335 - loss 0.44272918\n",
            "2019-06-18 20:22:01,509 epoch 31 - iter 330/335 - loss 0.44434351\n",
            "2019-06-18 20:22:05,049 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:22:05,053 EPOCH 31 done: loss 0.4440 - lr 0.0063 - bad epochs 1\n",
            "2019-06-18 20:22:31,191 DEV : loss 0.5812802314758301 - score 0.7062\n",
            "2019-06-18 20:24:21,493 TEST : loss 0.70296710729599 - score 0.6732\n",
            "2019-06-18 20:24:27,594 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:24:29,856 epoch 32 - iter 0/335 - loss 0.36181867\n",
            "2019-06-18 20:24:53,564 epoch 32 - iter 33/335 - loss 0.52549471\n",
            "2019-06-18 20:25:16,551 epoch 32 - iter 66/335 - loss 0.46143876\n",
            "2019-06-18 20:25:42,426 epoch 32 - iter 99/335 - loss 0.44476810\n",
            "2019-06-18 20:26:07,738 epoch 32 - iter 132/335 - loss 0.43719513\n",
            "2019-06-18 20:26:33,476 epoch 32 - iter 165/335 - loss 0.42999419\n",
            "2019-06-18 20:26:56,320 epoch 32 - iter 198/335 - loss 0.43519345\n",
            "2019-06-18 20:27:21,130 epoch 32 - iter 231/335 - loss 0.44282254\n",
            "2019-06-18 20:27:48,028 epoch 32 - iter 264/335 - loss 0.44115959\n",
            "2019-06-18 20:28:12,833 epoch 32 - iter 297/335 - loss 0.43933764\n",
            "2019-06-18 20:28:37,365 epoch 32 - iter 330/335 - loss 0.43681175\n",
            "2019-06-18 20:28:41,450 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:28:41,452 EPOCH 32 done: loss 0.4373 - lr 0.0063 - bad epochs 0\n",
            "2019-06-18 20:29:07,577 DEV : loss 0.5808885097503662 - score 0.7044\n",
            "2019-06-18 20:30:56,003 TEST : loss 0.6996068954467773 - score 0.6672\n",
            "2019-06-18 20:30:56,004 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:30:57,857 epoch 33 - iter 0/335 - loss 0.31126606\n",
            "2019-06-18 20:31:26,344 epoch 33 - iter 33/335 - loss 0.39934655\n",
            "2019-06-18 20:31:49,179 epoch 33 - iter 66/335 - loss 0.41341036\n",
            "2019-06-18 20:32:14,316 epoch 33 - iter 99/335 - loss 0.42381797\n",
            "2019-06-18 20:32:45,436 epoch 33 - iter 132/335 - loss 0.44585331\n",
            "2019-06-18 20:33:08,318 epoch 33 - iter 165/335 - loss 0.42857788\n",
            "2019-06-18 20:33:28,892 epoch 33 - iter 198/335 - loss 0.42170042\n",
            "2019-06-18 20:33:54,311 epoch 33 - iter 231/335 - loss 0.42243633\n",
            "2019-06-18 20:34:20,061 epoch 33 - iter 264/335 - loss 0.43678387\n",
            "2019-06-18 20:34:45,020 epoch 33 - iter 297/335 - loss 0.44386628\n",
            "2019-06-18 20:35:07,719 epoch 33 - iter 330/335 - loss 0.44433061\n",
            "2019-06-18 20:35:10,815 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:35:10,818 EPOCH 33 done: loss 0.4440 - lr 0.0063 - bad epochs 1\n",
            "2019-06-18 20:35:39,349 DEV : loss 0.5790578126907349 - score 0.7082\n",
            "2019-06-18 20:37:27,873 TEST : loss 0.7004678845405579 - score 0.671\n",
            "2019-06-18 20:37:34,345 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:37:35,873 epoch 34 - iter 0/335 - loss 0.10202435\n",
            "2019-06-18 20:38:05,164 epoch 34 - iter 33/335 - loss 0.37391757\n",
            "2019-06-18 20:38:28,170 epoch 34 - iter 66/335 - loss 0.38068585\n",
            "2019-06-18 20:38:50,577 epoch 34 - iter 99/335 - loss 0.39099555\n",
            "2019-06-18 20:39:12,518 epoch 34 - iter 132/335 - loss 0.39709496\n",
            "2019-06-18 20:39:38,444 epoch 34 - iter 165/335 - loss 0.41954677\n",
            "2019-06-18 20:40:05,395 epoch 34 - iter 198/335 - loss 0.42077605\n",
            "2019-06-18 20:40:30,338 epoch 34 - iter 231/335 - loss 0.42969311\n",
            "2019-06-18 20:40:55,961 epoch 34 - iter 264/335 - loss 0.43894557\n",
            "2019-06-18 20:41:19,908 epoch 34 - iter 297/335 - loss 0.43628234\n",
            "2019-06-18 20:41:45,505 epoch 34 - iter 330/335 - loss 0.43205706\n",
            "2019-06-18 20:41:48,846 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:41:48,848 EPOCH 34 done: loss 0.4331 - lr 0.0063 - bad epochs 0\n",
            "2019-06-18 20:42:17,339 DEV : loss 0.5805988311767578 - score 0.7061\n",
            "2019-06-18 20:44:05,684 TEST : loss 0.7031828761100769 - score 0.6796\n",
            "2019-06-18 20:44:05,686 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:44:07,224 epoch 35 - iter 0/335 - loss 0.28387570\n",
            "2019-06-18 20:44:32,622 epoch 35 - iter 33/335 - loss 0.43572556\n",
            "2019-06-18 20:44:55,318 epoch 35 - iter 66/335 - loss 0.46851822\n",
            "2019-06-18 20:45:18,726 epoch 35 - iter 99/335 - loss 0.46083451\n",
            "2019-06-18 20:45:40,993 epoch 35 - iter 132/335 - loss 0.46634592\n",
            "2019-06-18 20:46:07,689 epoch 35 - iter 165/335 - loss 0.47559629\n",
            "2019-06-18 20:46:33,956 epoch 35 - iter 198/335 - loss 0.46329229\n",
            "2019-06-18 20:46:58,691 epoch 35 - iter 231/335 - loss 0.44575210\n",
            "2019-06-18 20:47:25,655 epoch 35 - iter 264/335 - loss 0.44417563\n",
            "2019-06-18 20:47:52,668 epoch 35 - iter 297/335 - loss 0.44273743\n",
            "2019-06-18 20:48:15,463 epoch 35 - iter 330/335 - loss 0.44210926\n",
            "2019-06-18 20:48:18,354 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:48:18,356 EPOCH 35 done: loss 0.4397 - lr 0.0063 - bad epochs 1\n",
            "2019-06-18 20:48:44,074 DEV : loss 0.572928249835968 - score 0.7087\n",
            "2019-06-18 20:50:34,012 TEST : loss 0.6975736021995544 - score 0.6738\n",
            "2019-06-18 20:50:39,333 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:50:40,925 epoch 36 - iter 0/335 - loss 0.47436261\n",
            "2019-06-18 20:51:05,193 epoch 36 - iter 33/335 - loss 0.40357613\n",
            "2019-06-18 20:51:32,267 epoch 36 - iter 66/335 - loss 0.43773299\n",
            "2019-06-18 20:51:58,878 epoch 36 - iter 99/335 - loss 0.44908388\n",
            "2019-06-18 20:52:21,890 epoch 36 - iter 132/335 - loss 0.45268490\n",
            "2019-06-18 20:52:45,292 epoch 36 - iter 165/335 - loss 0.45566296\n",
            "2019-06-18 20:53:11,585 epoch 36 - iter 198/335 - loss 0.45102868\n",
            "2019-06-18 20:53:33,485 epoch 36 - iter 231/335 - loss 0.44295981\n",
            "2019-06-18 20:53:56,775 epoch 36 - iter 264/335 - loss 0.43009098\n",
            "2019-06-18 20:54:21,811 epoch 36 - iter 297/335 - loss 0.42609050\n",
            "2019-06-18 20:54:49,348 epoch 36 - iter 330/335 - loss 0.43503249\n",
            "2019-06-18 20:54:52,080 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:54:52,082 EPOCH 36 done: loss 0.4344 - lr 0.0063 - bad epochs 0\n",
            "2019-06-18 20:55:17,858 DEV : loss 0.5731167197227478 - score 0.6981\n",
            "2019-06-18 20:57:07,893 TEST : loss 0.6998627185821533 - score 0.6676\n",
            "2019-06-18 20:57:07,895 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 20:57:09,658 epoch 37 - iter 0/335 - loss 0.42651582\n",
            "2019-06-18 20:57:34,895 epoch 37 - iter 33/335 - loss 0.42859083\n",
            "2019-06-18 20:58:00,408 epoch 37 - iter 66/335 - loss 0.43016837\n",
            "2019-06-18 20:58:27,955 epoch 37 - iter 99/335 - loss 0.42660750\n",
            "2019-06-18 20:58:51,350 epoch 37 - iter 132/335 - loss 0.43531942\n",
            "2019-06-18 20:59:12,286 epoch 37 - iter 165/335 - loss 0.43789170\n",
            "2019-06-18 20:59:43,144 epoch 37 - iter 198/335 - loss 0.44186156\n",
            "2019-06-18 21:00:08,783 epoch 37 - iter 231/335 - loss 0.43569581\n",
            "2019-06-18 21:00:31,937 epoch 37 - iter 264/335 - loss 0.43632475\n",
            "2019-06-18 21:00:54,295 epoch 37 - iter 297/335 - loss 0.42703901\n",
            "2019-06-18 21:01:19,402 epoch 37 - iter 330/335 - loss 0.43075598\n",
            "2019-06-18 21:01:22,066 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:01:22,069 EPOCH 37 done: loss 0.4313 - lr 0.0063 - bad epochs 1\n",
            "2019-06-18 21:01:48,037 DEV : loss 0.5720857977867126 - score 0.6995\n",
            "2019-06-18 21:03:38,105 TEST : loss 0.6960581541061401 - score 0.6701\n",
            "2019-06-18 21:03:38,107 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:03:39,543 epoch 38 - iter 0/335 - loss 0.25604767\n",
            "2019-06-18 21:04:02,743 epoch 38 - iter 33/335 - loss 0.45309206\n",
            "2019-06-18 21:04:29,212 epoch 38 - iter 66/335 - loss 0.44940030\n",
            "2019-06-18 21:04:51,489 epoch 38 - iter 99/335 - loss 0.42938964\n",
            "2019-06-18 21:05:17,333 epoch 38 - iter 132/335 - loss 0.41956547\n",
            "2019-06-18 21:05:40,761 epoch 38 - iter 165/335 - loss 0.43511636\n",
            "2019-06-18 21:06:06,123 epoch 38 - iter 198/335 - loss 0.43417559\n",
            "2019-06-18 21:06:33,459 epoch 38 - iter 231/335 - loss 0.42845380\n",
            "2019-06-18 21:06:57,652 epoch 38 - iter 264/335 - loss 0.43347666\n",
            "2019-06-18 21:07:21,311 epoch 38 - iter 297/335 - loss 0.42419582\n",
            "2019-06-18 21:07:47,183 epoch 38 - iter 330/335 - loss 0.42817034\n",
            "2019-06-18 21:07:50,160 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:07:50,161 EPOCH 38 done: loss 0.4267 - lr 0.0063 - bad epochs 2\n",
            "2019-06-18 21:08:16,015 DEV : loss 0.5801622867584229 - score 0.7032\n",
            "2019-06-18 21:10:04,116 TEST : loss 0.7046992778778076 - score 0.6742\n",
            "2019-06-18 21:10:04,117 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:10:05,819 epoch 39 - iter 0/335 - loss 0.66110682\n",
            "2019-06-18 21:10:31,831 epoch 39 - iter 33/335 - loss 0.52267239\n",
            "2019-06-18 21:10:59,093 epoch 39 - iter 66/335 - loss 0.46292042\n",
            "2019-06-18 21:11:22,210 epoch 39 - iter 99/335 - loss 0.48442456\n",
            "2019-06-18 21:11:47,805 epoch 39 - iter 132/335 - loss 0.46226415\n",
            "2019-06-18 21:12:12,208 epoch 39 - iter 165/335 - loss 0.43988918\n",
            "2019-06-18 21:12:41,489 epoch 39 - iter 198/335 - loss 0.43707758\n",
            "2019-06-18 21:13:04,738 epoch 39 - iter 231/335 - loss 0.43523349\n",
            "2019-06-18 21:13:29,333 epoch 39 - iter 264/335 - loss 0.42610553\n",
            "2019-06-18 21:13:54,519 epoch 39 - iter 297/335 - loss 0.42507096\n",
            "2019-06-18 21:14:16,828 epoch 39 - iter 330/335 - loss 0.42639180\n",
            "2019-06-18 21:14:19,238 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:14:19,239 EPOCH 39 done: loss 0.4254 - lr 0.0063 - bad epochs 3\n",
            "2019-06-18 21:14:47,746 DEV : loss 0.5762869715690613 - score 0.7015\n",
            "2019-06-18 21:16:36,150 TEST : loss 0.703637421131134 - score 0.6747\n",
            "Epoch    38: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-06-18 21:16:36,152 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:16:37,735 epoch 40 - iter 0/335 - loss 0.34759355\n",
            "2019-06-18 21:17:02,873 epoch 40 - iter 33/335 - loss 0.46460619\n",
            "2019-06-18 21:17:24,682 epoch 40 - iter 66/335 - loss 0.43472553\n",
            "2019-06-18 21:17:46,795 epoch 40 - iter 99/335 - loss 0.41918760\n",
            "2019-06-18 21:18:11,607 epoch 40 - iter 132/335 - loss 0.42533272\n",
            "2019-06-18 21:18:37,868 epoch 40 - iter 165/335 - loss 0.42494987\n",
            "2019-06-18 21:19:01,800 epoch 40 - iter 198/335 - loss 0.43759805\n",
            "2019-06-18 21:19:27,801 epoch 40 - iter 231/335 - loss 0.43871837\n",
            "2019-06-18 21:19:56,575 epoch 40 - iter 264/335 - loss 0.43773979\n",
            "2019-06-18 21:20:23,643 epoch 40 - iter 297/335 - loss 0.43426983\n",
            "2019-06-18 21:20:46,421 epoch 40 - iter 330/335 - loss 0.43568329\n",
            "2019-06-18 21:20:49,435 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:20:49,437 EPOCH 40 done: loss 0.4358 - lr 0.0031 - bad epochs 0\n",
            "2019-06-18 21:21:17,944 DEV : loss 0.5749057531356812 - score 0.7062\n",
            "2019-06-18 21:23:06,195 TEST : loss 0.7019037008285522 - score 0.6732\n",
            "2019-06-18 21:23:06,197 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:23:07,743 epoch 41 - iter 0/335 - loss 0.29317665\n",
            "2019-06-18 21:23:30,256 epoch 41 - iter 33/335 - loss 0.37560378\n",
            "2019-06-18 21:24:00,027 epoch 41 - iter 66/335 - loss 0.42201361\n",
            "2019-06-18 21:24:22,958 epoch 41 - iter 99/335 - loss 0.43490856\n",
            "2019-06-18 21:24:48,223 epoch 41 - iter 132/335 - loss 0.43570169\n",
            "2019-06-18 21:25:12,122 epoch 41 - iter 165/335 - loss 0.42111057\n",
            "2019-06-18 21:25:39,743 epoch 41 - iter 198/335 - loss 0.42356431\n",
            "2019-06-18 21:26:00,254 epoch 41 - iter 231/335 - loss 0.42682868\n",
            "2019-06-18 21:26:29,645 epoch 41 - iter 264/335 - loss 0.43076618\n",
            "2019-06-18 21:26:53,611 epoch 41 - iter 297/335 - loss 0.42279198\n",
            "2019-06-18 21:27:18,277 epoch 41 - iter 330/335 - loss 0.42695749\n",
            "2019-06-18 21:27:21,001 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:27:21,003 EPOCH 41 done: loss 0.4253 - lr 0.0031 - bad epochs 1\n",
            "2019-06-18 21:27:46,840 DEV : loss 0.5759915113449097 - score 0.7033\n",
            "2019-06-18 21:29:36,895 TEST : loss 0.7021851539611816 - score 0.6725\n",
            "2019-06-18 21:29:36,897 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:29:38,183 epoch 42 - iter 0/335 - loss 0.76970780\n",
            "2019-06-18 21:30:02,725 epoch 42 - iter 33/335 - loss 0.43723007\n",
            "2019-06-18 21:30:30,861 epoch 42 - iter 66/335 - loss 0.42882226\n",
            "2019-06-18 21:30:54,897 epoch 42 - iter 99/335 - loss 0.41500100\n",
            "2019-06-18 21:31:19,781 epoch 42 - iter 132/335 - loss 0.43544076\n",
            "2019-06-18 21:31:48,363 epoch 42 - iter 165/335 - loss 0.43656907\n",
            "2019-06-18 21:32:14,564 epoch 42 - iter 198/335 - loss 0.42571032\n",
            "2019-06-18 21:32:37,131 epoch 42 - iter 231/335 - loss 0.41985130\n",
            "2019-06-18 21:32:58,253 epoch 42 - iter 264/335 - loss 0.42365059\n",
            "2019-06-18 21:33:23,630 epoch 42 - iter 297/335 - loss 0.42247867\n",
            "2019-06-18 21:33:46,451 epoch 42 - iter 330/335 - loss 0.42222480\n",
            "2019-06-18 21:33:49,115 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:33:49,117 EPOCH 42 done: loss 0.4200 - lr 0.0031 - bad epochs 2\n",
            "2019-06-18 21:34:15,077 DEV : loss 0.5753534436225891 - score 0.6965\n",
            "2019-06-18 21:36:05,324 TEST : loss 0.7015255093574524 - score 0.6692\n",
            "2019-06-18 21:36:05,326 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:36:06,936 epoch 43 - iter 0/335 - loss 0.20282122\n",
            "2019-06-18 21:36:30,789 epoch 43 - iter 33/335 - loss 0.43717476\n",
            "2019-06-18 21:36:52,268 epoch 43 - iter 66/335 - loss 0.41152333\n",
            "2019-06-18 21:37:22,433 epoch 43 - iter 99/335 - loss 0.42736220\n",
            "2019-06-18 21:37:44,464 epoch 43 - iter 132/335 - loss 0.41828074\n",
            "2019-06-18 21:38:10,313 epoch 43 - iter 165/335 - loss 0.40508357\n",
            "2019-06-18 21:38:35,142 epoch 43 - iter 198/335 - loss 0.40794587\n",
            "2019-06-18 21:38:56,658 epoch 43 - iter 231/335 - loss 0.41351229\n",
            "2019-06-18 21:39:21,274 epoch 43 - iter 264/335 - loss 0.41579393\n",
            "2019-06-18 21:39:46,094 epoch 43 - iter 297/335 - loss 0.41182105\n",
            "2019-06-18 21:40:12,623 epoch 43 - iter 330/335 - loss 0.42095970\n",
            "2019-06-18 21:40:15,325 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:40:15,328 EPOCH 43 done: loss 0.4186 - lr 0.0031 - bad epochs 3\n",
            "2019-06-18 21:40:41,283 DEV : loss 0.5761946439743042 - score 0.7061\n",
            "2019-06-18 21:42:30,940 TEST : loss 0.7011452913284302 - score 0.672\n",
            "Epoch    42: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-06-18 21:42:30,942 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:42:32,260 epoch 44 - iter 0/335 - loss 0.21868488\n",
            "2019-06-18 21:42:55,745 epoch 44 - iter 33/335 - loss 0.33865580\n",
            "2019-06-18 21:43:18,591 epoch 44 - iter 66/335 - loss 0.38055064\n",
            "2019-06-18 21:43:45,439 epoch 44 - iter 99/335 - loss 0.38705951\n",
            "2019-06-18 21:44:10,854 epoch 44 - iter 132/335 - loss 0.40175454\n",
            "2019-06-18 21:44:34,533 epoch 44 - iter 165/335 - loss 0.40637832\n",
            "2019-06-18 21:44:57,489 epoch 44 - iter 198/335 - loss 0.41402174\n",
            "2019-06-18 21:45:22,486 epoch 44 - iter 231/335 - loss 0.41548644\n",
            "2019-06-18 21:45:47,166 epoch 44 - iter 264/335 - loss 0.42302611\n",
            "2019-06-18 21:46:09,927 epoch 44 - iter 297/335 - loss 0.41700423\n",
            "2019-06-18 21:46:40,506 epoch 44 - iter 330/335 - loss 0.41912539\n",
            "2019-06-18 21:46:43,065 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:46:43,066 EPOCH 44 done: loss 0.4201 - lr 0.0016 - bad epochs 0\n",
            "2019-06-18 21:47:08,954 DEV : loss 0.5749934315681458 - score 0.7072\n",
            "2019-06-18 21:48:56,468 TEST : loss 0.701649010181427 - score 0.6687\n",
            "2019-06-18 21:48:56,469 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:48:58,625 epoch 45 - iter 0/335 - loss 0.36268169\n",
            "2019-06-18 21:49:24,602 epoch 45 - iter 33/335 - loss 0.44934923\n",
            "2019-06-18 21:49:51,816 epoch 45 - iter 66/335 - loss 0.45713782\n",
            "2019-06-18 21:50:19,329 epoch 45 - iter 99/335 - loss 0.44964737\n",
            "2019-06-18 21:50:43,926 epoch 45 - iter 132/335 - loss 0.44126753\n",
            "2019-06-18 21:51:08,677 epoch 45 - iter 165/335 - loss 0.43494784\n",
            "2019-06-18 21:51:32,281 epoch 45 - iter 198/335 - loss 0.42011428\n",
            "2019-06-18 21:51:53,919 epoch 45 - iter 231/335 - loss 0.41404732\n",
            "2019-06-18 21:52:17,204 epoch 45 - iter 264/335 - loss 0.41979451\n",
            "2019-06-18 21:52:40,494 epoch 45 - iter 297/335 - loss 0.42050824\n",
            "2019-06-18 21:53:05,445 epoch 45 - iter 330/335 - loss 0.41696730\n",
            "2019-06-18 21:53:08,217 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:53:08,219 EPOCH 45 done: loss 0.4161 - lr 0.0016 - bad epochs 1\n",
            "2019-06-18 21:53:36,338 DEV : loss 0.5756763815879822 - score 0.7051\n",
            "2019-06-18 21:55:23,906 TEST : loss 0.7015142440795898 - score 0.6722\n",
            "2019-06-18 21:55:23,907 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:55:27,947 epoch 46 - iter 0/335 - loss 0.91934311\n",
            "2019-06-18 21:55:53,092 epoch 46 - iter 33/335 - loss 0.38544567\n",
            "2019-06-18 21:56:16,667 epoch 46 - iter 66/335 - loss 0.43661195\n",
            "2019-06-18 21:56:40,188 epoch 46 - iter 99/335 - loss 0.42754030\n",
            "2019-06-18 21:57:03,925 epoch 46 - iter 132/335 - loss 0.42060746\n",
            "2019-06-18 21:57:27,443 epoch 46 - iter 165/335 - loss 0.42149734\n",
            "2019-06-18 21:57:52,502 epoch 46 - iter 198/335 - loss 0.43636787\n",
            "2019-06-18 21:58:15,667 epoch 46 - iter 231/335 - loss 0.42287901\n",
            "2019-06-18 21:58:38,419 epoch 46 - iter 264/335 - loss 0.42691543\n",
            "2019-06-18 21:59:04,140 epoch 46 - iter 297/335 - loss 0.42168632\n",
            "2019-06-18 21:59:32,130 epoch 46 - iter 330/335 - loss 0.42955159\n",
            "2019-06-18 21:59:34,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 21:59:34,813 EPOCH 46 done: loss 0.4296 - lr 0.0016 - bad epochs 2\n",
            "2019-06-18 22:00:00,413 DEV : loss 0.574196994304657 - score 0.7063\n",
            "2019-06-18 22:01:49,562 TEST : loss 0.7004802227020264 - score 0.6704\n",
            "2019-06-18 22:01:49,564 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:01:51,053 epoch 47 - iter 0/335 - loss 0.80540109\n",
            "2019-06-18 22:02:15,238 epoch 47 - iter 33/335 - loss 0.52004805\n",
            "2019-06-18 22:02:41,430 epoch 47 - iter 66/335 - loss 0.48147539\n",
            "2019-06-18 22:03:06,699 epoch 47 - iter 99/335 - loss 0.43787889\n",
            "2019-06-18 22:03:27,772 epoch 47 - iter 132/335 - loss 0.43150806\n",
            "2019-06-18 22:03:49,566 epoch 47 - iter 165/335 - loss 0.41025473\n",
            "2019-06-18 22:04:19,007 epoch 47 - iter 198/335 - loss 0.39630008\n",
            "2019-06-18 22:04:44,586 epoch 47 - iter 231/335 - loss 0.40240735\n",
            "2019-06-18 22:05:08,131 epoch 47 - iter 264/335 - loss 0.40916763\n",
            "2019-06-18 22:05:33,795 epoch 47 - iter 297/335 - loss 0.40847215\n",
            "2019-06-18 22:05:56,021 epoch 47 - iter 330/335 - loss 0.41482077\n",
            "2019-06-18 22:05:59,108 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:05:59,110 EPOCH 47 done: loss 0.4143 - lr 0.0016 - bad epochs 3\n",
            "2019-06-18 22:06:24,806 DEV : loss 0.5747000575065613 - score 0.698\n",
            "2019-06-18 22:08:13,779 TEST : loss 0.7010377645492554 - score 0.6688\n",
            "Epoch    46: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-06-18 22:08:13,781 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:08:15,463 epoch 48 - iter 0/335 - loss 0.73287034\n",
            "2019-06-18 22:08:40,522 epoch 48 - iter 33/335 - loss 0.39880762\n",
            "2019-06-18 22:09:02,339 epoch 48 - iter 66/335 - loss 0.42256247\n",
            "2019-06-18 22:09:28,685 epoch 48 - iter 99/335 - loss 0.42504531\n",
            "2019-06-18 22:09:53,225 epoch 48 - iter 132/335 - loss 0.40300125\n",
            "2019-06-18 22:10:16,683 epoch 48 - iter 165/335 - loss 0.39810232\n",
            "2019-06-18 22:10:43,034 epoch 48 - iter 198/335 - loss 0.40432710\n",
            "2019-06-18 22:11:11,052 epoch 48 - iter 231/335 - loss 0.41810190\n",
            "2019-06-18 22:11:33,727 epoch 48 - iter 264/335 - loss 0.41206815\n",
            "2019-06-18 22:11:57,497 epoch 48 - iter 297/335 - loss 0.42169385\n",
            "2019-06-18 22:12:19,713 epoch 48 - iter 330/335 - loss 0.42320130\n",
            "2019-06-18 22:12:23,100 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:12:23,101 EPOCH 48 done: loss 0.4219 - lr 0.0008 - bad epochs 0\n",
            "2019-06-18 22:12:48,804 DEV : loss 0.5747476816177368 - score 0.698\n",
            "2019-06-18 22:14:36,303 TEST : loss 0.7012429237365723 - score 0.6694\n",
            "2019-06-18 22:14:36,304 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:14:38,073 epoch 49 - iter 0/335 - loss 0.59044361\n",
            "2019-06-18 22:15:03,764 epoch 49 - iter 33/335 - loss 0.40181883\n",
            "2019-06-18 22:15:27,188 epoch 49 - iter 66/335 - loss 0.37989514\n",
            "2019-06-18 22:15:52,061 epoch 49 - iter 99/335 - loss 0.40870249\n",
            "2019-06-18 22:16:21,088 epoch 49 - iter 132/335 - loss 0.41906355\n",
            "2019-06-18 22:16:44,642 epoch 49 - iter 165/335 - loss 0.41767785\n",
            "2019-06-18 22:17:06,234 epoch 49 - iter 198/335 - loss 0.41017819\n",
            "2019-06-18 22:17:28,358 epoch 49 - iter 231/335 - loss 0.41905277\n",
            "2019-06-18 22:17:57,879 epoch 49 - iter 264/335 - loss 0.42057850\n",
            "2019-06-18 22:18:20,612 epoch 49 - iter 297/335 - loss 0.42064150\n",
            "2019-06-18 22:18:43,644 epoch 49 - iter 330/335 - loss 0.42074444\n",
            "2019-06-18 22:18:46,302 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:18:46,304 EPOCH 49 done: loss 0.4199 - lr 0.0008 - bad epochs 1\n",
            "2019-06-18 22:19:14,505 DEV : loss 0.5753033757209778 - score 0.6975\n",
            "2019-06-18 22:21:01,750 TEST : loss 0.7013955116271973 - score 0.6668\n",
            "2019-06-18 22:21:01,751 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:21:03,188 epoch 50 - iter 0/335 - loss 0.50294793\n",
            "2019-06-18 22:21:33,468 epoch 50 - iter 33/335 - loss 0.36274255\n",
            "2019-06-18 22:21:54,680 epoch 50 - iter 66/335 - loss 0.37961649\n",
            "2019-06-18 22:22:17,228 epoch 50 - iter 99/335 - loss 0.39988549\n",
            "2019-06-18 22:22:40,215 epoch 50 - iter 132/335 - loss 0.41568619\n",
            "2019-06-18 22:23:07,118 epoch 50 - iter 165/335 - loss 0.43724471\n",
            "2019-06-18 22:23:32,862 epoch 50 - iter 198/335 - loss 0.43260414\n",
            "2019-06-18 22:23:56,568 epoch 50 - iter 231/335 - loss 0.42577191\n",
            "2019-06-18 22:24:21,670 epoch 50 - iter 264/335 - loss 0.43322824\n",
            "2019-06-18 22:24:44,906 epoch 50 - iter 297/335 - loss 0.42534514\n",
            "2019-06-18 22:25:09,517 epoch 50 - iter 330/335 - loss 0.42010319\n",
            "2019-06-18 22:25:12,604 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:25:12,606 EPOCH 50 done: loss 0.4211 - lr 0.0008 - bad epochs 2\n",
            "2019-06-18 22:25:40,649 DEV : loss 0.5744879245758057 - score 0.7061\n",
            "2019-06-18 22:27:27,906 TEST : loss 0.7015815377235413 - score 0.6676\n",
            "2019-06-18 22:27:27,907 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:27:29,323 epoch 51 - iter 0/335 - loss 0.50164676\n",
            "2019-06-18 22:27:54,484 epoch 51 - iter 33/335 - loss 0.45115780\n",
            "2019-06-18 22:28:18,540 epoch 51 - iter 66/335 - loss 0.41989837\n",
            "2019-06-18 22:28:45,527 epoch 51 - iter 99/335 - loss 0.43687035\n",
            "2019-06-18 22:29:07,334 epoch 51 - iter 132/335 - loss 0.41961026\n",
            "2019-06-18 22:29:32,812 epoch 51 - iter 165/335 - loss 0.41901255\n",
            "2019-06-18 22:29:57,658 epoch 51 - iter 198/335 - loss 0.41206875\n",
            "2019-06-18 22:30:24,523 epoch 51 - iter 231/335 - loss 0.41056889\n",
            "2019-06-18 22:30:50,526 epoch 51 - iter 264/335 - loss 0.41227957\n",
            "2019-06-18 22:31:10,185 epoch 51 - iter 297/335 - loss 0.40923132\n",
            "2019-06-18 22:31:33,140 epoch 51 - iter 330/335 - loss 0.41802952\n",
            "2019-06-18 22:31:36,269 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:31:36,270 EPOCH 51 done: loss 0.4197 - lr 0.0008 - bad epochs 3\n",
            "2019-06-18 22:32:01,855 DEV : loss 0.5737624168395996 - score 0.7061\n",
            "2019-06-18 22:33:50,802 TEST : loss 0.7012960314750671 - score 0.6682\n",
            "Epoch    50: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-06-18 22:33:50,804 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:33:52,415 epoch 52 - iter 0/335 - loss 0.25631863\n",
            "2019-06-18 22:34:17,316 epoch 52 - iter 33/335 - loss 0.39403473\n",
            "2019-06-18 22:34:43,516 epoch 52 - iter 66/335 - loss 0.38564882\n",
            "2019-06-18 22:35:05,058 epoch 52 - iter 99/335 - loss 0.38830717\n",
            "2019-06-18 22:35:32,820 epoch 52 - iter 132/335 - loss 0.38744381\n",
            "2019-06-18 22:35:57,126 epoch 52 - iter 165/335 - loss 0.39504763\n",
            "2019-06-18 22:36:22,616 epoch 52 - iter 198/335 - loss 0.38984496\n",
            "2019-06-18 22:36:47,960 epoch 52 - iter 231/335 - loss 0.39049051\n",
            "2019-06-18 22:37:06,923 epoch 52 - iter 264/335 - loss 0.40023443\n",
            "2019-06-18 22:37:34,837 epoch 52 - iter 297/335 - loss 0.39709626\n",
            "2019-06-18 22:37:59,853 epoch 52 - iter 330/335 - loss 0.40141271\n",
            "2019-06-18 22:38:04,051 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:38:04,053 EPOCH 52 done: loss 0.4052 - lr 0.0004 - bad epochs 0\n",
            "2019-06-18 22:38:29,749 DEV : loss 0.5740070939064026 - score 0.7061\n",
            "2019-06-18 22:40:18,855 TEST : loss 0.7016035914421082 - score 0.6681\n",
            "2019-06-18 22:40:18,856 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:40:20,283 epoch 53 - iter 0/335 - loss 0.15662478\n",
            "2019-06-18 22:40:42,705 epoch 53 - iter 33/335 - loss 0.36677962\n",
            "2019-06-18 22:41:06,118 epoch 53 - iter 66/335 - loss 0.40465356\n",
            "2019-06-18 22:41:37,623 epoch 53 - iter 99/335 - loss 0.41833251\n",
            "2019-06-18 22:42:03,672 epoch 53 - iter 132/335 - loss 0.42406907\n",
            "2019-06-18 22:42:24,528 epoch 53 - iter 165/335 - loss 0.42136118\n",
            "2019-06-18 22:42:52,039 epoch 53 - iter 198/335 - loss 0.42435540\n",
            "2019-06-18 22:43:14,139 epoch 53 - iter 231/335 - loss 0.42715792\n",
            "2019-06-18 22:43:38,543 epoch 53 - iter 264/335 - loss 0.42679457\n",
            "2019-06-18 22:44:00,937 epoch 53 - iter 297/335 - loss 0.42156515\n",
            "2019-06-18 22:44:27,678 epoch 53 - iter 330/335 - loss 0.41994403\n",
            "2019-06-18 22:44:30,576 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:44:30,577 EPOCH 53 done: loss 0.4214 - lr 0.0004 - bad epochs 1\n",
            "2019-06-18 22:44:56,355 DEV : loss 0.5742259621620178 - score 0.7072\n",
            "2019-06-18 22:46:45,317 TEST : loss 0.7020147442817688 - score 0.6682\n",
            "2019-06-18 22:46:45,319 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:46:46,855 epoch 54 - iter 0/335 - loss 0.77758473\n",
            "2019-06-18 22:47:13,732 epoch 54 - iter 33/335 - loss 0.47994737\n",
            "2019-06-18 22:47:41,199 epoch 54 - iter 66/335 - loss 0.47813458\n",
            "2019-06-18 22:48:05,423 epoch 54 - iter 99/335 - loss 0.44440672\n",
            "2019-06-18 22:48:27,976 epoch 54 - iter 132/335 - loss 0.42566283\n",
            "2019-06-18 22:48:49,478 epoch 54 - iter 165/335 - loss 0.43723458\n",
            "2019-06-18 22:49:14,590 epoch 54 - iter 198/335 - loss 0.43594632\n",
            "2019-06-18 22:49:40,905 epoch 54 - iter 231/335 - loss 0.41804802\n",
            "2019-06-18 22:50:05,084 epoch 54 - iter 264/335 - loss 0.41600799\n",
            "2019-06-18 22:50:28,937 epoch 54 - iter 297/335 - loss 0.41714064\n",
            "2019-06-18 22:50:52,806 epoch 54 - iter 330/335 - loss 0.41819040\n",
            "2019-06-18 22:50:55,567 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:50:55,569 EPOCH 54 done: loss 0.4179 - lr 0.0004 - bad epochs 2\n",
            "2019-06-18 22:51:21,439 DEV : loss 0.5744100213050842 - score 0.7077\n",
            "2019-06-18 22:53:08,843 TEST : loss 0.7019456624984741 - score 0.6687\n",
            "2019-06-18 22:53:08,844 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:53:10,054 epoch 55 - iter 0/335 - loss 0.49732637\n",
            "2019-06-18 22:53:37,063 epoch 55 - iter 33/335 - loss 0.42685268\n",
            "2019-06-18 22:54:02,743 epoch 55 - iter 66/335 - loss 0.40116148\n",
            "2019-06-18 22:54:26,021 epoch 55 - iter 99/335 - loss 0.38250154\n",
            "2019-06-18 22:54:53,827 epoch 55 - iter 132/335 - loss 0.40166153\n",
            "2019-06-18 22:55:17,338 epoch 55 - iter 165/335 - loss 0.39861649\n",
            "2019-06-18 22:55:42,209 epoch 55 - iter 198/335 - loss 0.39281794\n",
            "2019-06-18 22:56:06,175 epoch 55 - iter 231/335 - loss 0.39672367\n",
            "2019-06-18 22:56:31,010 epoch 55 - iter 264/335 - loss 0.40481740\n",
            "2019-06-18 22:56:55,861 epoch 55 - iter 297/335 - loss 0.40957567\n",
            "2019-06-18 22:57:17,736 epoch 55 - iter 330/335 - loss 0.41417769\n",
            "2019-06-18 22:57:20,134 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:57:20,135 EPOCH 55 done: loss 0.4136 - lr 0.0004 - bad epochs 3\n",
            "2019-06-18 22:57:48,233 DEV : loss 0.574679434299469 - score 0.7061\n",
            "2019-06-18 22:59:35,677 TEST : loss 0.7018789052963257 - score 0.6675\n",
            "Epoch    54: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2019-06-18 22:59:35,679 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 22:59:37,503 epoch 56 - iter 0/335 - loss 0.31546450\n",
            "2019-06-18 23:00:05,644 epoch 56 - iter 33/335 - loss 0.38997689\n",
            "2019-06-18 23:00:34,300 epoch 56 - iter 66/335 - loss 0.36731472\n",
            "2019-06-18 23:00:59,048 epoch 56 - iter 99/335 - loss 0.38889458\n",
            "2019-06-18 23:01:22,818 epoch 56 - iter 132/335 - loss 0.40485409\n",
            "2019-06-18 23:01:46,571 epoch 56 - iter 165/335 - loss 0.40618451\n",
            "2019-06-18 23:02:10,399 epoch 56 - iter 198/335 - loss 0.41068263\n",
            "2019-06-18 23:02:34,337 epoch 56 - iter 231/335 - loss 0.42123053\n",
            "2019-06-18 23:02:59,924 epoch 56 - iter 264/335 - loss 0.41780459\n",
            "2019-06-18 23:03:19,785 epoch 56 - iter 297/335 - loss 0.42005718\n",
            "2019-06-18 23:03:42,111 epoch 56 - iter 330/335 - loss 0.41993036\n",
            "2019-06-18 23:03:44,854 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:03:44,856 EPOCH 56 done: loss 0.4175 - lr 0.0002 - bad epochs 0\n",
            "2019-06-18 23:04:13,009 DEV : loss 0.5744687914848328 - score 0.6975\n",
            "2019-06-18 23:06:00,399 TEST : loss 0.7016944885253906 - score 0.6675\n",
            "2019-06-18 23:06:00,400 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:06:01,825 epoch 57 - iter 0/335 - loss 0.71077782\n",
            "2019-06-18 23:06:29,236 epoch 57 - iter 33/335 - loss 0.43024948\n",
            "2019-06-18 23:06:55,299 epoch 57 - iter 66/335 - loss 0.39532700\n",
            "2019-06-18 23:07:19,862 epoch 57 - iter 99/335 - loss 0.40456422\n",
            "2019-06-18 23:07:40,379 epoch 57 - iter 132/335 - loss 0.40868521\n",
            "2019-06-18 23:08:03,316 epoch 57 - iter 165/335 - loss 0.41982746\n",
            "2019-06-18 23:08:29,344 epoch 57 - iter 198/335 - loss 0.41682868\n",
            "2019-06-18 23:08:51,754 epoch 57 - iter 231/335 - loss 0.41098025\n",
            "2019-06-18 23:09:15,574 epoch 57 - iter 264/335 - loss 0.41233412\n",
            "2019-06-18 23:09:39,733 epoch 57 - iter 297/335 - loss 0.41589137\n",
            "2019-06-18 23:10:05,176 epoch 57 - iter 330/335 - loss 0.41610725\n",
            "2019-06-18 23:10:08,041 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:10:08,043 EPOCH 57 done: loss 0.4152 - lr 0.0002 - bad epochs 1\n",
            "2019-06-18 23:10:33,762 DEV : loss 0.5744485855102539 - score 0.7072\n",
            "2019-06-18 23:12:22,558 TEST : loss 0.7019341588020325 - score 0.6675\n",
            "2019-06-18 23:12:22,560 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:12:23,905 epoch 58 - iter 0/335 - loss 0.24147210\n",
            "2019-06-18 23:12:47,109 epoch 58 - iter 33/335 - loss 0.43034514\n",
            "2019-06-18 23:13:14,667 epoch 58 - iter 66/335 - loss 0.41873368\n",
            "2019-06-18 23:13:40,321 epoch 58 - iter 99/335 - loss 0.42665079\n",
            "2019-06-18 23:14:04,266 epoch 58 - iter 132/335 - loss 0.42249748\n",
            "2019-06-18 23:14:26,167 epoch 58 - iter 165/335 - loss 0.42802166\n",
            "2019-06-18 23:14:55,244 epoch 58 - iter 198/335 - loss 0.42633709\n",
            "2019-06-18 23:15:19,669 epoch 58 - iter 231/335 - loss 0.43779571\n",
            "2019-06-18 23:15:41,856 epoch 58 - iter 264/335 - loss 0.44037043\n",
            "2019-06-18 23:16:06,186 epoch 58 - iter 297/335 - loss 0.43883860\n",
            "2019-06-18 23:16:31,775 epoch 58 - iter 330/335 - loss 0.43597369\n",
            "2019-06-18 23:16:34,624 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:16:34,626 EPOCH 58 done: loss 0.4355 - lr 0.0002 - bad epochs 2\n",
            "2019-06-18 23:17:00,314 DEV : loss 0.5744732618331909 - score 0.6975\n",
            "2019-06-18 23:18:49,197 TEST : loss 0.7016875743865967 - score 0.6678\n",
            "2019-06-18 23:18:49,198 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:18:50,613 epoch 59 - iter 0/335 - loss 0.14928554\n",
            "2019-06-18 23:19:14,883 epoch 59 - iter 33/335 - loss 0.39899549\n",
            "2019-06-18 23:19:40,362 epoch 59 - iter 66/335 - loss 0.41762755\n",
            "2019-06-18 23:20:03,162 epoch 59 - iter 99/335 - loss 0.40829427\n",
            "2019-06-18 23:20:28,263 epoch 59 - iter 132/335 - loss 0.40469832\n",
            "2019-06-18 23:20:51,517 epoch 59 - iter 165/335 - loss 0.38829482\n",
            "2019-06-18 23:21:13,535 epoch 59 - iter 198/335 - loss 0.40306361\n",
            "2019-06-18 23:21:38,633 epoch 59 - iter 231/335 - loss 0.42123324\n",
            "2019-06-18 23:22:02,495 epoch 59 - iter 264/335 - loss 0.42343585\n",
            "2019-06-18 23:22:28,908 epoch 59 - iter 297/335 - loss 0.42128324\n",
            "2019-06-18 23:22:52,840 epoch 59 - iter 330/335 - loss 0.41839183\n",
            "2019-06-18 23:22:57,212 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:22:57,213 EPOCH 59 done: loss 0.4165 - lr 0.0002 - bad epochs 3\n",
            "2019-06-18 23:23:22,930 DEV : loss 0.5746923089027405 - score 0.6975\n",
            "2019-06-18 23:25:09,991 TEST : loss 0.7017108798027039 - score 0.6675\n",
            "Epoch    58: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2019-06-18 23:25:09,993 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:25:09,999 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:25:09,999 learning rate too small - quitting training!\n",
            "2019-06-18 23:25:10,000 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:25:15,137 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-18 23:25:15,231 Testing using best model ...\n",
            "2019-06-18 23:25:15,239 loading file resources/taggers/resume-ner-2f1w/best-model.pt\n",
            "2019-06-18 23:27:05,384 0.723\t0.6309\t0.6738\n",
            "2019-06-18 23:27:05,387 \n",
            "MICRO_AVG: acc 0.5081 - f1-score 0.6738\n",
            "MACRO_AVG: acc 0.4418 - f1-score 0.5749749999999999\n",
            "\"B-Companies tp: 262 - fp: 85 - fn: 95 - tn: 262 - precision: 0.7550 - recall: 0.7339 - accuracy: 0.5928 - f1-score: 0.7443\n",
            "\"I-Companies tp: 409 - fp: 80 - fn: 111 - tn: 409 - precision: 0.8364 - recall: 0.7865 - accuracy: 0.6817 - f1-score: 0.8107\n",
            "\"L-Companies tp: 274 - fp: 71 - fn: 87 - tn: 274 - precision: 0.7942 - recall: 0.7590 - accuracy: 0.6343 - f1-score: 0.7762\n",
            "\"U-Companies tp: 48 - fp: 59 - fn: 72 - tn: 48 - precision: 0.4486 - recall: 0.4000 - accuracy: 0.2682 - f1-score: 0.4229\n",
            "-          tp: 32 - fp: 101 - fn: 350 - tn: 32 - precision: 0.2406 - recall: 0.0838 - accuracy: 0.0663 - f1-score: 0.1243\n",
            "Degree     tp: 73 - fp: 38 - fn: 31 - tn: 73 - precision: 0.6577 - recall: 0.7019 - accuracy: 0.5141 - f1-score: 0.6791\n",
            "Designation tp: 279 - fp: 107 - fn: 128 - tn: 279 - precision: 0.7228 - recall: 0.6855 - accuracy: 0.5428 - f1-score: 0.7037\n",
            "L-Degree   tp: 74 - fp: 33 - fn: 26 - tn: 74 - precision: 0.6916 - recall: 0.7400 - accuracy: 0.5564 - f1-score: 0.7150\n",
            "L-Designation tp: 294 - fp: 92 - fn: 110 - tn: 294 - precision: 0.7617 - recall: 0.7277 - accuracy: 0.5927 - f1-score: 0.7443\n",
            "U-Degree   tp: 30 - fp: 12 - fn: 14 - tn: 30 - precision: 0.7143 - recall: 0.6818 - accuracy: 0.5357 - f1-score: 0.6977\n",
            "U-Designation tp: 13 - fp: 7 - fn: 21 - tn: 13 - precision: 0.6500 - recall: 0.3824 - accuracy: 0.3171 - f1-score: 0.4815\n",
            "ner        tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "2019-06-18 23:27:05,392 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(1.3985, device='cuda:0'),\n",
              "  tensor(1.1085, device='cuda:0'),\n",
              "  tensor(0.9526, device='cuda:0'),\n",
              "  tensor(0.8610, device='cuda:0'),\n",
              "  tensor(0.7792, device='cuda:0'),\n",
              "  tensor(0.8186, device='cuda:0'),\n",
              "  tensor(0.7638, device='cuda:0'),\n",
              "  tensor(0.7127, device='cuda:0'),\n",
              "  tensor(0.7031, device='cuda:0'),\n",
              "  tensor(0.6892, device='cuda:0'),\n",
              "  tensor(0.6875, device='cuda:0'),\n",
              "  tensor(0.6779, device='cuda:0'),\n",
              "  tensor(0.6618, device='cuda:0'),\n",
              "  tensor(0.6535, device='cuda:0'),\n",
              "  tensor(0.6242, device='cuda:0'),\n",
              "  tensor(0.5998, device='cuda:0'),\n",
              "  tensor(0.6132, device='cuda:0'),\n",
              "  tensor(0.5964, device='cuda:0'),\n",
              "  tensor(0.5999, device='cuda:0'),\n",
              "  tensor(0.5957, device='cuda:0'),\n",
              "  tensor(0.5840, device='cuda:0'),\n",
              "  tensor(0.5896, device='cuda:0'),\n",
              "  tensor(0.5959, device='cuda:0'),\n",
              "  tensor(0.5849, device='cuda:0'),\n",
              "  tensor(0.5810, device='cuda:0'),\n",
              "  tensor(0.5788, device='cuda:0'),\n",
              "  tensor(0.5899, device='cuda:0'),\n",
              "  tensor(0.5768, device='cuda:0'),\n",
              "  tensor(0.5764, device='cuda:0'),\n",
              "  tensor(0.5815, device='cuda:0'),\n",
              "  tensor(0.5813, device='cuda:0'),\n",
              "  tensor(0.5809, device='cuda:0'),\n",
              "  tensor(0.5791, device='cuda:0'),\n",
              "  tensor(0.5806, device='cuda:0'),\n",
              "  tensor(0.5729, device='cuda:0'),\n",
              "  tensor(0.5731, device='cuda:0'),\n",
              "  tensor(0.5721, device='cuda:0'),\n",
              "  tensor(0.5802, device='cuda:0'),\n",
              "  tensor(0.5763, device='cuda:0'),\n",
              "  tensor(0.5749, device='cuda:0'),\n",
              "  tensor(0.5760, device='cuda:0'),\n",
              "  tensor(0.5754, device='cuda:0'),\n",
              "  tensor(0.5762, device='cuda:0'),\n",
              "  tensor(0.5750, device='cuda:0'),\n",
              "  tensor(0.5757, device='cuda:0'),\n",
              "  tensor(0.5742, device='cuda:0'),\n",
              "  tensor(0.5747, device='cuda:0'),\n",
              "  tensor(0.5747, device='cuda:0'),\n",
              "  tensor(0.5753, device='cuda:0'),\n",
              "  tensor(0.5745, device='cuda:0'),\n",
              "  tensor(0.5738, device='cuda:0'),\n",
              "  tensor(0.5740, device='cuda:0'),\n",
              "  tensor(0.5742, device='cuda:0'),\n",
              "  tensor(0.5744, device='cuda:0'),\n",
              "  tensor(0.5747, device='cuda:0'),\n",
              "  tensor(0.5745, device='cuda:0'),\n",
              "  tensor(0.5744, device='cuda:0'),\n",
              "  tensor(0.5745, device='cuda:0'),\n",
              "  tensor(0.5747, device='cuda:0')],\n",
              " 'dev_score_history': [0.525,\n",
              "  0.5693,\n",
              "  0.5637,\n",
              "  0.6575,\n",
              "  0.6712,\n",
              "  0.6636,\n",
              "  0.6565,\n",
              "  0.6681,\n",
              "  0.6746,\n",
              "  0.6803,\n",
              "  0.6569,\n",
              "  0.6695,\n",
              "  0.652,\n",
              "  0.674,\n",
              "  0.6936,\n",
              "  0.6892,\n",
              "  0.6879,\n",
              "  0.6771,\n",
              "  0.6822,\n",
              "  0.7043,\n",
              "  0.6831,\n",
              "  0.6986,\n",
              "  0.6976,\n",
              "  0.686,\n",
              "  0.7061,\n",
              "  0.6931,\n",
              "  0.6911,\n",
              "  0.6911,\n",
              "  0.703,\n",
              "  0.7022,\n",
              "  0.7062,\n",
              "  0.7044,\n",
              "  0.7082,\n",
              "  0.7061,\n",
              "  0.7087,\n",
              "  0.6981,\n",
              "  0.6995,\n",
              "  0.7032,\n",
              "  0.7015,\n",
              "  0.7062,\n",
              "  0.7033,\n",
              "  0.6965,\n",
              "  0.7061,\n",
              "  0.7072,\n",
              "  0.7051,\n",
              "  0.7063,\n",
              "  0.698,\n",
              "  0.698,\n",
              "  0.6975,\n",
              "  0.7061,\n",
              "  0.7061,\n",
              "  0.7061,\n",
              "  0.7072,\n",
              "  0.7077,\n",
              "  0.7061,\n",
              "  0.6975,\n",
              "  0.7072,\n",
              "  0.6975,\n",
              "  0.6975],\n",
              " 'test_score': 0.6738,\n",
              " 'train_loss_history': [2.8747727696575334,\n",
              "  1.470117330862515,\n",
              "  1.1862666220362508,\n",
              "  1.0209374927317918,\n",
              "  0.909868173056574,\n",
              "  0.8499341082661899,\n",
              "  0.8036280513699375,\n",
              "  0.7727582190018981,\n",
              "  0.7333571249424522,\n",
              "  0.7119610314048938,\n",
              "  0.6759352958914059,\n",
              "  0.652169790997434,\n",
              "  0.6324060498333689,\n",
              "  0.6154121229452874,\n",
              "  0.585497889856794,\n",
              "  0.5603777415716826,\n",
              "  0.5406471821354396,\n",
              "  0.5172961261735034,\n",
              "  0.5064414313480036,\n",
              "  0.4978769978035742,\n",
              "  0.4902871247547776,\n",
              "  0.47731040956369086,\n",
              "  0.4786223279006446,\n",
              "  0.4657006029762439,\n",
              "  0.4530117221287827,\n",
              "  0.4502693327950008,\n",
              "  0.46067912456259796,\n",
              "  0.45974398557819535,\n",
              "  0.45107016465557154,\n",
              "  0.44631639863572903,\n",
              "  0.44397733638535686,\n",
              "  0.4373283040612491,\n",
              "  0.4439778263444331,\n",
              "  0.4330990723264751,\n",
              "  0.4397343780567397,\n",
              "  0.4344432396452818,\n",
              "  0.4313023929720494,\n",
              "  0.42669026833861623,\n",
              "  0.4253879036921174,\n",
              "  0.4357614542566129,\n",
              "  0.4253380202535373,\n",
              "  0.4199820010186131,\n",
              "  0.4185955317496364,\n",
              "  0.42006906804753774,\n",
              "  0.416091843594366,\n",
              "  0.42958114809954345,\n",
              "  0.41430048644542694,\n",
              "  0.4218545348786596,\n",
              "  0.41987091809955995,\n",
              "  0.4211078251920529,\n",
              "  0.41966512621338686,\n",
              "  0.40523605506811566,\n",
              "  0.421366588348773,\n",
              "  0.41788615210732416,\n",
              "  0.4136173143315671,\n",
              "  0.4174565641737696,\n",
              "  0.41515390588276424,\n",
              "  0.4355478063003341,\n",
              "  0.4164965722987901]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeLu1-UNkwBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Bash commands can be run by prefixing the command with ‘!’.\n",
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOGC1kSYk1Xd",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}
